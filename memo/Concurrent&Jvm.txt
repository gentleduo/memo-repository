//Java轻量级锁原理
http://blog.csdn.net/guomei/article/details/17210139 
http://blog.csdn.net/zhoufanyang_china/article/details/54601311 
http://blog.csdn.net/choukekai/article/details/63688332 
http://blog.csdn.net/zero__007/article/details/49587319
http://blog.sina.com.cn/s/blog_c038e9930102v2ht.html

//Java Class的文件结构
http://www.cnblogs.com/01picker/p/4592245.html
http://blog.csdn.net/luanlouis/article/details/39960815
http://blog.csdn.net/silentbalanceyh/article/details/42640739

//基于栈的字节码解释执行引擎
http://hllvm.group.iteye.com/group/topic/25858
http://xtu-tja-163-com.iteye.com/blog/775987
http://blog.csdn.net/a616413086/article/details/51272309
http://www.thinksaas.cn/topics/0/439/439410.html
http://www.aiuxian.com/article/p-3181761.html

//HotSpot虚拟机解释器与编译器并存
http://blog.csdn.net/sunxianghuang/article/details/52094859

//JVM的Server与Client运行模式区别与切换
http://blog.csdn.net/rainnnbow/article/details/52228773

//jdk分析工具:jmap和jhat
http://www.cnblogs.com/ggjucheng/archive/2013/04/16/3024986.html

//JAR
http://jingyan.baidu.com/article/219f4bf7d0ef87de442d3820.html
http://www.2cto.com/kf/201305/208332.html

//classloader
http://blog.chinaunix.net/uid-21227800-id-65879.html

###################################################基本概念###################################################
程序、进程、线程、纤程/协程
程序
可执行文件

进程
操作系统进行资源分配的基本单位，进程是静态的概念(静态资源:CPU,内存,外部设备等)

线程
线程是调度执行的基本单位，多个线程共享同一个进程里面的所有的资源，线程是动态的概率
一个程序在运行的时候会产生不同的执行路径(同时在运行的多条路径)就叫多线程
双击可执行文件后会进入内存，变成一个进程，进程是如何执行的呢？(程序是如何执行的)真正开始执行是以线程为单位来执行，操作系统会找到主线程，然后将主线程的代码一条一条交给CPU来执行。如果主线程运行中开启了其他线程，再来线程之间的来回切换。
线程切换(Context Switch)
CPU的组成包括如下几个部分：
ALU:计算单元
Registers:寄存器组,用于存储数据
PC:程序计数器（Program Counter）也是一种寄存器，保存了将要取出的下一条指令的内存地址，指令取出后，就会更新该寄存器指向下一条指令
Cache:
程序执行过程：指令放PC，数据放Registers，然后ALU进行计算；线程切换则是将PC和Registers中正在执行的线程的数据保存到Cache中，然后将另一个线程的数据load到CPU的PC和Registers中来。
CPU只负责计算，操作系统负责具体指令和数据是属于哪个线程的。
设置线程数量的一般计算公式
N_threads = N_cpu * U_cpu * (1 + W/C)
其中：
N_cpu是处理器的核的数目，可以通过Runtime.getRuntime().availableProcessors()得到
U_cpu是期望的CPU利用率(该值应该介于0到1之间)
W/C是等待时间与计算时间的比率

纤程/协程
绿色线程，用户管理的(而不是OS管理的)线程

同步（synchronous）和异步（asynchronous）

并发(Concurrent)
当有多个线程在操作时,如果系统只有一个CPU,则它根本不可能真正同时进行一个以上的线程,它只能把CPU运行时间划分成若干个时间段,再将时间段分配给各个线程执行,在一个时间段的线程代码运行时,其它线程处于挂起状态.这种方式我们称之为并发(Concurrent).

并行(Parallel)
当系统有一个以上CPU时,则线程的操作有可能非并发.当一个CPU执行一个线程时,另一个CPU可以执行另一个线程,两个线程互不抢占CPU资源,可以同时进行,这种方式我们称之为并行(Parallel)

临界区
C临界区用来表示一种公共资源或者说是共享数据，可以被多个线程使用。但是每一次，只能有一个线程使用它，一旦临界区资源被占用，其他线程要想使用这个资源，就必须等待。
临界区在多线程环境下是需要被控制的区域

阻塞（Blocking）和非阻塞（Non-Blocking）
C阻塞和非阻塞通常用来形容多线程间的相互影响。比如一个线程占用了临界区资源，那么其它所有需要这个资源的线程就必须在这个临界区中进行等待，等待会导致线程挂起。这种情况就是阻塞。此时，如果占用资源的线程一直不愿意释放资源，那么其它所有阻塞在这个临界区上的线程都不能工作。
C非阻塞允许多个线程同时进入临界区

死锁（Deadlock）、饥饿（Starvation）和活锁（Livelock）

并发级别
阻塞
C当一个线程进入临界区后，其他线程必须等待
非阻塞
无障碍（Obstruction-Free） 其实就是排他，先拿一个更新日期，然后在有限次数内完成更新，因为次数限定所以不保证一定能更新成功
C无障碍是一种最弱的非阻塞调度
C自由出入临界区
C无竞争时，有限步内完成操作
C有竞争时，回滚数据
无锁（Lock-Free）
C是无障碍的
C保证有一个线程可以胜出
while (!atomicVar.compareAndSet(localVar, localVar+1)) { localVar = atomicVar.get(); }
无等待（Wait-Free） 典型的案例就是读写锁中的读锁
C无锁的
C要求所有的线程都必须在有限步内完成
C无饥饿的
###################################################基本概念###################################################

###################################################多线程-线程不安全案例###################################################
public class BootStrap {

	public static void main(String[] args) {
		TicketClient wb = new TicketClient();
		new Thread(wb, "a").start();
		new Thread(wb, "b").start();
		new Thread(wb, "c").start();
	}
}
public class TicketClient implements Runnable {

	int num = 10;
	private boolean flag = true;

	@Override
	public void run() {
		while (flag) {
			// 加上synchronized之后便是线程安全的了
			// synchronized (this) {
			test();
			// }
		}
	}

	public void test() {
		if (num == 0) {
			flag = false;
			return;
		}
		try {
			Thread.sleep(200);
		} catch (InterruptedException e) {
			e.printStackTrace();
		}
		System.out.println(Thread.currentThread().getName() + "-->" + num--);
		// 线程不安全，可能都都是同一张票，可能票是负数
		// 负数:当还有1张票时，三个线程同时进入，都等待后，有两个线程为负数
		// 相同票:线程有自己的工作台，多个线程几乎同时到达，拷贝数据
	}

}
###################################################多线程-线程不安全案例###################################################

###################################################cpu缓存与多线程###################################################
==========================>CPU缓存
硬件内存架构
计算机在执行程序的时候，每条指令都是在CPU中执行的，而执行的时候，又免不了要和数据打交道。而计算机上面的数据，是存放在主存当中的，也就是计算机的物理内存。以多核CPU为例，每个CPU核都包含一组「CPU寄存器」，这些寄存器本质上是在CPU内存中。CPU在这些寄存器上执行操作的速度要比在主内存(RAM)中执行的速度快得多。因为CPU速率高，内存速率慢，为了让存储体系可以跟上CPU的速度，所以中间又加上Cache层，就是我们说的「CPU高速缓存」。

CPU多级缓存
由于CPU的运算速度远远超越了1级缓存的数据I\O能力，CPU厂商又引入了多级的缓存结构。通常L1、L2是每个CPU核有一个，L3是多个核共用一个。
1.各种寄存器，用来存储本地变量和函数参数，访问一次需要1cycle，耗时小于1ns；
2.L1 Cache，一级缓存，本地core的缓存，分成32K的数据缓存L1d和32k指令缓存L1i，访问L1需要3cycles，耗时大约1ns；
3.L2 Cache，二级缓存，本地core的缓存，被设计为L1缓存与共享的L3缓存之间的缓冲，大小为256K，访问L2需要12cycles，耗时大约3ns；
4.L3 Cache，三级缓存，在同插槽的所有core共享L3缓存，分为多个2M的段，访问L3需要38cycles，耗时大约12ns；
大致可以得出结论，缓存层级越接近于CPUcore，容量越小，速度越快，同时，没有披露的一点是其造价也更贵。所以为了支撑更多的热点数据，同时追求最高的性价比，多级缓存架构应运而生。

CacheLine
Cache又是由很多个「缓存行」(CacheLine)组成的。CacheLine是Cache和RAM交换数据的最小单位。Cache存储数据是固定大小为单位的，称为一个CacheEntry，这个单位称为CacheLine或CacheBlock。给定Cache容量大小和cache-line-size的情况下，它能存储的条目个数(number-of-cache-entries)就是固定的。因为Cache是固定大小的，所以它从主内存获取数据也是固定大小。对于X86来讲，是64Bytes。对于ARM来讲，较旧的架构的CacheLine是32Bytes，但一次内存访存只访问一半的数据也不太合适，所以它经常是一次填两个CacheLine，叫做DoubleFill。
试想一下你正在遍历一个长度为16的long数组data[16]，原始数据自然存在于主内存中，访问过程描述如下
1.访问data[0]，CPUcore尝试访问CPUCache，未命中。
2.尝试访问主内存，操作系统一次访问的单位是一个CacheLine的大小―64字节，这意味着：既从主内存中获取到了data[0]的值，同时将data[0]~data[7]加入到了CPUCache之中，forfree~
3.访问data[1]~data[7]，CPUcore尝试访问CPUCache，命中直接返回。
4.访问data[8]，CPUcore尝试访问CPUCache，未命中。
5.尝试访问主内存。重复步骤2

缓存的工作原理
这里的缓存的工作原理和我们项目中用memcached、redis做常用数据的缓存层是一个道理。当CPU要读取一个数据时，首先从缓存中查找，如果找到就立即读取并送给CPU处理；如果没有找到，就去内存中读取并送给CPU处理，同时把这个数据所在的数据块（就是我们上边说的CacheBlock）调入缓存中，即把临近的共64Byte的数据也一同载入，因为临近的数据在将来被访问的可能性更大，可以使得以后对整块数据的读取都从缓存中进行，不必再调用内存。这就增加了CPU读取缓存的命中率（CacheHit）了。

伪共享：伪共享指的是多个线程同时读写同一个缓存行的不同变量时导致的CPU缓存失效。尽管这些变量之间没有任何关系，但由于在主内存中邻近，存在于同一个缓存行之中，它们的相互覆盖会导致频繁的缓存未命中，需要重新刷缓存，引发性能下降。
假设有一个变量i=3（应该是包括变量i的缓存块，块大小为缓存行大小）；已经加载到多核（a,b,c）的缓存中，此时该缓存行的状态为S；此时其中的一个核a改变了变量i的值，那么在核a中的当前缓存行的状态将变为M，b,c核中的当前缓存行状态将变为I。如下图：
| Core A        |     | Core B        |     | Core C        |
| CacheLine X=3 |     | CacheLine X=3 |     | CacheLine X=3 |
| Status: S     |     | Status: S     |     | Status: S     |
                              |
							  |
							  ∨
| Core A        |     | Core B        |     | Core C        |
| CacheLine X=4 |     | CacheLine X=3 |     | CacheLine X=3 |
| Status: M     |     | Status: I     |     | Status: I     |

伪共享指的是多个线程同时读写同一个缓存行的不同变量时导致的CPU缓存失效。尽管这些变量之间没有任何关系，但由于在主内存中邻近，存在于同一个缓存行之中，它们的相互覆盖会导致频繁的缓存未命中，引发性能下降。伪共享问题难以被定位，如果系统设计者不理解CPU缓存架构，甚至永远无法发现―原来我的程序还可以更快。
例如：如果多个线程的变量共享了同一个CacheLine，任意一方的修改操作都会使得整个CacheLine失效（因为CacheLine是CPU缓存的最小单位），也就意味着，频繁的多线程操作，CPU缓存将会彻底失效，降级为CPUcore和主内存的直接交互。
|A|B| | | | | | |
伪共享问题的解决方法便是字节填充。
|A| | | | | | | |
|B| | | | | | | |
我们只需要保证不同线程的变量存在于不同的CacheLine即可，使用多余的字节来填充可以做点这一点，这样就不会出现伪共享问题。

缓存的意义
1 时间局限性：如果某个数据被访问，那么它在不久的将来有可能被在次访问
2 空间局限性：如果某个缓存行的数据被访问，那么与之相邻的缓存行很快可能被访问到

首先我们来看一个Java的例子:
public class MainClass {

	static long[][] arr;
	
	public static void main(String[] args) {
		arr = new long[1024 * 1024][8];
		long sum = 0;
		// 横向遍历
		long marked = System.currentTimeMillis();
		for (int i = 0; i < 1024 * 1024; i += 1) {
			for (int j = 0; j < 8; j++) {
				sum += arr[i][j];
			}
		}
		System.out.println("Loop times:" + (System.currentTimeMillis() - marked) + "ms");
		sum = 0;
		marked = System.currentTimeMillis();
		// 纵向遍历
		for (int i = 0; i < 8; i += 1) {
			for (int j = 0; j < 1024 * 1024; j++) {
				sum += arr[j][i];
			}
		}
		System.out.println("Loop times:" + (System.currentTimeMillis() - marked) + "ms");
	}
}
使用了横向遍历和纵向遍历两种顺序对这个二位数组进行遍历，遍历总次数相同，只不过循环的方向不同，观察他们的耗时。
在我的机器上多次运行后可以发现：横向遍历的耗时大约为15ms，纵向遍历的耗时大约为40ms，前者比后者快了1倍有余。
上述现象出现的原因就是CPU Cache&Cache Line。因为横向遍历arr= new long[1024 * 1024][8] 每次内层寻访中的数据都存储在连续内存地址中，所以一次访问会将剩下7个数据一起加入CPUCache中，而纵向访问内存循环的数据不是在连续地址中所以每一次都要从内存中取。

缓存带来的问题
缓存的加入是为了解决CPU运算能力和内存读写能力的不匹配问题，简单来说就是为了提升资源利用率。那么在多CPU（一个CPU对应一个或者多个核心）或者多核心下，每个核心都会有一个一级缓存或者二级缓存，也就是说一二级缓存是核心独占的（类似JMM模型，线程的工作内存是线程独占的，主内存是共享的）而三级缓存和主内存是共享的，这样就将导致CPU缓存一致性问题。为了解决这种不一致，大名鼎鼎的MESI协议随之而来。

==========================>MESI缓存一致性协议
现代计算机都是多核cpu，cpu需要和内存交互，但内存相对cpu的速度实在太慢，于是cpu和内存之间还有cache层，每个cpu都有属于自己的cache，cache由CacheLine组成，每个CacheLine64位（根据不同架构，也可能是32位或128位），每个CacheLine知道自己对应什么范围的物理内存地址，当cpu需要读取某一个内存地址的值时，它会把内存地址传递给一级cache，一级cache会检查它是否有这个内存地址对应的CacheLine。如果没有，它会以CacheLine为单位从内存加载数据，是的，一次加载整个CacheLine，这是基于这样一个假设：内存访问倾向于本地化（localized），如果我们当前需要某个地址的数据，那么很可能我们马上要访问它的邻近地址。由于每个cpu独立工作，那就会有一个显著的问题：多个cache与内存之间的数据同步该怎么做？缓存一致性协议就是要解决这个问题，协议有多种，可以分为两类："窥探（snooping）"协议和"基于目录的（directory-based）"协议，MESI协议属于一种"窥探协议"。窥探协议的基本思想所有cache与内存，cache与cache（是的，cache之间也会有数据传输）之间的传输都发生在一条共享的总线上，而所有的cpu都能看到这条总线，同一个指令周期中，只有一个cache可以读写内存，所有的内存访问都要经过仲裁（arbitrate）。窥探协议的思想是，cahce不但与内存通信时和总线打交道，而且它会不停地窥探总线上发生的数据交换，跟踪其他cache在做什么。所以当一个cache代表它所属的cpu去读写内存时，其它cpu都会得到通知，它们以此来使自己的cache保持同步。

MESI协议缓存状态(硬件层面)
多核(Core)CPU都有自己的专有缓存（一般为L1，L2），以及同一个CPU插槽(Socket)之间的核共享的缓存（一般为L3）。不同核心的CPU缓存中难免会加载同样的数据，那么如何保证数据的一致性呢，就是MESI协议了。
在MESI协议中，每个Cache line有4个状态，可用2个bit表示，它们分别是：
M(Modified)：
描述：该CacheLine有效，数据被修改了，和内存中的数据不一致，数据只存在于本Cache中。CacheLine只有处于Exclusive状态才能被修改。此外，已修改CacheLine如果被丢弃或标记为Invalid，那么先要把它的内容回写到内存中。
监听任务：缓存行必须时刻监听所有试图读该缓存行的操作，这种操作必须在CPU将该缓存行写回主存并将状态变成S（共享）状态之前被延迟执行。
E(Exclusive)：
描述：该CacheLine有效，数据和内存中的数据一致，数据只存在于本Cache中。独占该内存地址，其他处理器的CacheLine不能同时持有它，如果其他处理器原本也持有同一CacheLine，那么它会马上变成"Invalid"状态
监听任务：缓存行也必须监听其它缓存读主存中该缓存行的操作，一旦有这种操作，该缓存行需要变成S（共享）状态。
S(Shared)：
描述：该Cache line有效，数据和内存中的数据一致，数据存在于很多Cache中。处于该状态下的cache line只能被cpu读取，不能写入，因为此时还没有独占。
监听任务：缓存行也必须监听其它缓存使该缓存行无效或者独享该缓存行的请求，并将该缓存行变成无效（Invalid）。
I(Invalid)：
描述：该Cache line无效。
监听任务：无
line如果被丢弃或标记为Invalid，那么先要把它的内容回写到内存中。
cpu有读取数据的动作，有独占的动作，有独占后更新数据的动作，有更新数据之后回写内存的动作，根据"窥探协议"的规范，每个动作都需要通知到其他cpu，于是有以下的消息机制：
Read，cpu发起读取数据请求，请求中包含需要读取的数据地址。
Read Response，作为Read消息的响应，该消息可能是内存响应的，也可能是某cpu响应的(比如该地址在某cpu cache Line中为Modified状态，则该cpu必须返回该地址的最新数据)。
Invalidate，cpu发起”我要独占一个cache line，其他cpu请失效对应的cache line“的消息，消息中包含了内存地址，所有的其它cpu需要将对应cache line置为Invalid状态。
Invalidate ACK，收到Invalidate消息的cpu在将对应cache line置为Invalid后，返回Invalid ACK。
Read Invalidate，相当于Read消息+Invalidate消息，即取得数据并且独占它，将收到一个Read Response和所有其它cpu的Invalidate ACK。
Write back，写回消息，即将状态为Modified的cache line写回到内存，通常在该行将被替换时使用。现代cpu cache基本都采用”写回(Write Back)”而非”直写(Write Through)”的方式。

						 cup0		 cup1		 cup2		 cup3		main memory
                         cacheline   cacheline   cacheline   cacheline  0x0    0x8
cpu0:read from 0x0       0/shared                                       latest latest
cpu3:read from 0x0       0/shared                            0/shared   latest latest
cpu0:read from 0x8       8/shared                            0/shared   latest latest
cpu2:exclusive 0x0       8/shared                0/exclusive            latest latest
cpu2:modified 0x0        8/shared                0/modified             expire latest
cpu1:atomic inc in 0x0   8/shared    0/modified                         expire latest 
cpu1:read from 0x8       8/shared    8/shared                           latest latest

cache line时序变化图 
    初始状态，4个cpu的cache line都为Invalid状态（黑色表示Invalid）。
    cpu0发送Read消息，加载0x0的数据，数据从内存返回，cache line状态变为Shared。
    cpu3发送Read消息，加载0x0的数据，数据从内存返回，cache line状态变为Shared。
    cpu0发送Read消息，加载0x8的数据，导致cache line被替换，由于之前状态为Shared，即与内存中数据一致，可直接覆盖，而无需回写。
    cpu2发送Read Invalidate消息，从内存返回最新数据，cpu3返回Invalidate ACK，并将状态变为Invalid，cpu2获得独占权，状态变为Exclusive。
    cpu2修改cache line中的数据，cache line状态为Modified，同时内存中0x0的数据过期。
    cpu1 对地址0x0的数据执行原子(atomic)递增操作，发出Read Invalidate消息，cpu2将返回Read Response(而不是内存)，包含最新数据，并返回Invalidate ACK，同时cache line状态变为Invalid。最后cpu1获得独占权，cache line状态变为Modified，数据为递增后的数据，而内存中的数据仍然为过期状态。
    cpu1 加载0x8的数据，此时cache line将被替换，由于之前状态为Modified，因此需要先执行写回操作，此时内存中0x0的数据得以更新。

总结
这就是缓存一致性协议，一个状态机，仅此而已。因为该协议的存在，每个cpu就可以放心操作属于自己的cache，而不需要担心本地cache中的数据会不会已经被其他cpu修改。但在缓存一致性协议的框架下工作性能不高，但这并不是协议的问题，协议本身逻辑很严谨。性能差在哪里？假如某数据存在于其他cpu的cache中，那自己每次需要修改数据时，都需要发送ReadInvalidate消息，除了等待最新数据的返回，还需要等待其他cpu的InvalidateACK才能继续执行其他指令，这是一种同步行为，于是便有了cpu的优化：处理器指令重排(指令还未结束便去执行其它指令的行为称之为，指令重排)

======================>处理器指令重排
指令重排的实现:硬件层面的优化――Store Buffer, Invalid Queue，以及软件层面的优化――内存屏障指令。
Store Buffer---存储缓存
StoreBuffer即存储缓存。位于内核和缓存之间。当处理器需要处理将计算结果写入在缓存中处于shared状态的数据时，需要通知其他内核将该缓存置为 Invalid（无效），引入StoreBuffer后将不再需要处理器去等待其他内核的响应结果，只需要把修改的数据写到StoreBuffer，通知其他内核，然后当前内核即可去执行其它指令。当收到其他内核的响应结果后，再把StoreBuffer中的数据写回缓存，并修改状态为M。（很类似分布式中，数据一致性保障的异步确认）

Invalidate Queues---失效队列
简单说处理器修改数据时，需要通知其它内核将该缓存中的数据置为Invalid（失效），我们将该数据放到了Store Bufferes处理。那收到失效指令的这些内核会立即处理这种失效消息吗？答案是不会的，因为就算是一个内核缓存了该数据并不意味着马上要用，这些内核会将失效通知放到InvalidateQueues，然后快速返回InvalidateAcknowledge消息（意思就是尽量不耽误正在用这个数据的内核正常工作）。后续收到失效通知的内核将会从该queues中逐个处理该命令。（意思就是我也不着急用，所以我也不着急处理）。

指令重排带来的问题---可见性问题
指令重排或者说StoreBuffer或者InvalidteQueues带来的问题就是可见性问题，通过以上分析，我们不难发现这其实是保障了数据的最终一致性。因为在处理器对数据的修改不是立即对其他内核可见的，因为修改了的数据被放在了StoreBuffer中，通知其他内核的数据修改也不是达到其他内核并被立即处理的。其实有点异步处理的意思。假设core1对数据A的修改通知没有被core2立即处理（因为在InvalidteQueues中），core2紧接着又修改了数据A，是不是就造成了数据的不一致。其它内核对数据的修改对本内核是不可见的。为了提升性能引入了指令重排，而然指令重排可能会导致数据的不一致，为解决数据不一致的问题需要在软件层面使用内存屏蔽

内存屏障
CPU就给我们提供了一种通过软件告知CPU什么指令不能重排，什么指令能重排的机制就是内存屏障。
两个指令：
load：将内存中的数据拷贝到内核的缓存中。
store：将内核缓存的数据刷新到内存中。
内存屏障：Memory Barrier。
LoadLoad Barriers（读屏障），StoreStore Barriers（写屏障），LoadStore Barriers，StoreLoad Barriers
不同的CPU架构对内存屏障的实现是不尽相同的，我们这里讨论流行的X86架构。
X86中有三种内存屏障：
Store-Memory-Barrier：写屏障，等同于前文的StoreStore-Barriers告诉处理器在执行这之后的指令之前，执行所有已经在存储缓存（StoreBuffer）中的修改（M）指令。即：所有StoreBarrier之前的修改（M）指令都是对之后的指令可见。
Load-Memory-Barrier：读屏障，等同于前文的LoadLoadBarriers告诉处理器在执行任何的加载前，执行所有已经在失效队列（InvalidteQueues）中的失效（I）指令。即：所有LoadBarrier之前的store指令对之后（本核心和其他核心）的指令都是可见的。
Full-Barrier：万能屏障，即FullBarrier作用等同于以上二者之和。即所有StoreBarrier之前的store指令对之后的指令都是可见的，之后（本核心和其他核心）的指令也都是可见的，完全保证了数据的强一致性。

内存屏障的问题
CPU知道什么时候需要加入内存屏障，什么时候不需要吗？CPU将这个加入内存屏障的时机交给了程序员。在java中这个加入内存屏障的命令就是volatile关键字。澄清一点，volatile并不是仅仅加入内存屏障这么简单，加入内存屏障只是volatile内核指令级别的内存语义。除此之外：volatile还可以禁止编译器的指令重排，因为JVM为了优化性能并且不违反happens-before原则的前提下也会进行指令重排。

======================>Store Buffer、Invalid Queue会提高CPU性能但是会造成可见性问题，例如：
Store Buffer
当cpu需要的数据在其他cpu的cache内时，需要请求，并且等待响应，这显然是一个同步行为，优化的方案也很明显，采用异步。思路大概是在cpu和cache之间加一个StoreBuffer，cpu可以先将数据写到StoreBuffer，同时给其他cpu发送消息，然后继续做其它事情，等到收到其它cpu发过来的响应消息，再将数据从StoreBuffer移到CacheLine。
StoreBuffer带来的问题，例如有如下代码：
a = 1;
b = a + 1;
assert(b == 2);
初始状态下，假设a，b值都为0，并且a存在cpu1的cache line中(Shared状态)，可能出现如下操作序列:
    cpu0 要写入a，将a=1写入store buffer，并发出Read Invalidate消息，继续其他指令。
    cpu1 收到Read Invalidate，返回Read Response(包含a=0的cache line)和Invalidate ACK，cpu0 收到Read Response，更新cache line(a=0)。
    cpu0 开始执行b=a+1，此时cache line中还没有加载b，于是发出Read Invalidate消息，从内存加载b=0，同时cache line中已有a=0，于是得到b=1，状态为Modified状态。
    cpu0 得到 b=1，断言失败。
    cpu0 将store buffer中的a=1推送到cache line，然而为时已晚。
造成这个问题的根源在于对同一个cpu存在对a的两份拷贝，一份在cache，一份在store buffer，而cpu计算b=a+1时，a和b的值都来自cache。

Store Forwarding
StoreBuffer可能导致破坏程序顺序的问题，硬件工程师在StoreBuffer的基础上，又实现了”StoreForwarding”技术:cpu可以直接从StoreBuffer中加载数据，即支持将cpu存入StoreBuffer的数据传递(forwarding)给后续的加载操作，而不经由cache。虽然解决了同一个cpu读写数据的问题，但是在并发程序中还是会有问题。例如有如下代码：
void foo() {
    a = 1;
    b = 1;
}
void bar() {
    while (b == 0) continue;
    assert(a == 1)
}
初始状态下，假设a，b值都为0，a存在于cpu1的cache中，b存在于cpu0的cache中，均为Exclusive状态，cpu0执行foo函数，cpu1执行bar函数，上面代码的预期断言为真。那么来看下执行序列:
    cpu1执行while(b == 0)，由于cpu1的Cache中没有b，发出Read b消息
    cpu0执行a=1，由于cpu0的cache中没有a，因此它将a(当前值1)写入到store buffer并发出Read Invalidate a消息
    cpu0执行b=1，由于b已经存在在cache中，且为Exclusive状态，因此可直接执行写入
    cpu0收到Read b消息，将cache中的b(当前值1)返回给cpu1，将b写回到内存，并将cache Line状态改为Shared
    cpu1收到包含b的cache line，结束while (b == 0)循环
    cpu1执行assert(a == 1)，由于此时cpu1 cache line中的a仍然为0并且有效(Exclusive)，断言失败
    cpu1收到Read Invalidate a消息，返回包含a的cache line，并将本地包含a的cache line置为Invalid，然而已经为时已晚。
    cpu0收到cpu1传过来的cache line，然后将store buffer中的a(当前值1)刷新到cache line
出现这个问题的原因在于cpu不知道a,b之间的数据依赖，cpu0对a的写入需要和其他cpu通信，因此有延迟，而对b的写入直接修改本地cache就行，因此b比a先在cache中生效，导致cpu1读到b=1时，a还存在于store buffer中。

Invalidate Queues
引入了StoreBuffer，再辅以StoreForwarding，写屏障，看起来好像可以自洽了，然而还有一个问题没有考虑:StoreBuffer的大小是有限的，所有的写入操作发生CacheMissing（数据不再本地）都会使用StoreBuffer，特别是出现内存屏障时，后续的所有写入操作(不管是否CacheMissing)都会挤压在StoreBuffer中(直到StoreBuffer中屏障前的条目处理完)，因此StoreBuffer很容易会满，当StoreBuffer满了之后，cpu还是会卡在等对应的InvalidateACK以处理StoreBuffer中的条目。因此还是要回到InvalidateACK中来，InvalidateACK耗时的主要原因是cpu要先将对应的CacheLine置为Invalid后再返回InvalidateACK，一个很忙的cpu可能会导致其它cpu都在等它回InvalidateACK。解决思路还是化同步为异步:cpu不必要处理了CacheLine之后才回InvalidateACK，而是可以先将Invalid消息放到某个请求队列InvalidQueue，然后就返回InvalidateACK。CPU可以后续再处理InvalidQueue中的消息，大幅度降低InvalidateACK响应时间，即CPU的空等现象就减少了，但是也带来了新的可见性问题。
void foo() {
    a = 1;
    smp_wmb()
    b = 1;
}
void bar() {
    while (b == 0) continue;
    assert(a == 1)
}
假设a, b的初始值为0，a在cpu0，cpu1中均为Shared状态，b在cpu0独占(Exclusive状态)，cpu0执行foo，cpu1执行bar:
    cpu0执行a=1，由于其有包含a的cache line，将a写入store buffer，并发出Invalidate a消息。
    cpu1执行while(b == 0)，它没有b的cache，发出Read b消息。
    cpu1收到cpu0的Invalidate a消息，将其放入Invalidate Queue，返回Invalidate ACK。
    cpu0收到Invalidate ACK，将store buffer中的a=1刷新到cache line，标记为Modified。
    cpu0看到smp_wmb()内存屏障，但是由于其store buffer为空，因此它可以直接跳过该语句。
    cpu0执行b=1，由于其cache独占b，因此直接执行写入，cache line标记为Modified。
    cpu0收到cpu1发的Read b消息，将包含b的cache line写回内存并返回该cache line，本地的cache line标记为Shared。
    cpu1收到包含b(当前值1)的cache line，结束while循环。
    cpu1执行assert(a == 1)，由于其本地有包含a旧值的cache line，读到a初始值0，断言失败。
    cpu1这时才处理Invalid Queue中的消息，将包含a旧值的cache line置为Invalid。
问题在于第9步中cpu1在读取a的cache line时，没有先处理Invalid Queue中该cache line的Invalid操作

======================>CPU内存屏蔽指令通过牺牲CPU性能去获得内存可见性以及禁止乱序执行的特性，例如
写屏障指令
到目前为止，我们发现了”指令重排“的其中一个本质，cpu为了优化指令的执行效率，引入了StoreBuffer（forwarding），而又因此导致了指令执行顺序的变化。要保证这种顺序一致性，靠硬件是优化不了了，需要在软件层面支持，没错，cpu提供了写屏障（write-memory-barrier）指令，Linux操作系统将写屏障指令封装成了smp_wmb()函数，cpu执行smp_mb()的思路是，会先把当前StoreBuffer中的数据刷到cache之后，再执行屏障后的“写入操作”，该思路有两种实现方式:一是简单地刷StoreBuffer，但如果此时远程CacheLine没有返回，则需要等待，二是将当前StoreBuffer中的条目打标，然后将屏障后的“写入操作”也写到StoreBuffer中，cpu继续干其他的事，当被打标的条目全部刷到CacheLine，之后再刷后面的条目（具体实现非本文目标），以第二种实现逻辑为例，看看以下代码执行过程：
void foo() {
    a = 1;
    smp_wmb()
    b = 1;
}
void bar() {
    while (b == 0) continue;
    assert(a == 1)
}
初始状态下，假设a，b值都为0，a存在于cpu1的cache中，b存在于cpu0的cache中，均为Exclusive状态，cpu0执行foo函数，cpu1执行bar函数，上面代码的预期断言为真。那么来看下执行序列:
    cpu1执行while(b == 0)，由于cpu1的cache中没有b，发出Read b消息。
    cpu0执行a=1，由于cpu0的cache中没有a，因此它将a(当前值1)写入到store buffer并发出Read Invalidate a消息。
    cpu0看到smp_wmb()内存屏障，它会标记当前store buffer中的所有条目(即a=1被标记)。
    cpu0执行b=1，尽管b已经存在在cache中(Exclusive)，但是由于store buffer中还存在被标记的条目，因此b不能直接写入，只能先写入store buffer中。
    cpu0收到Read b消息，将cache中的b(当前值0)返回给cpu1，将b写回到内存，并将cache line状态改为Shared。
    cpu1收到包含b的cache line，继续while (b == 0)循环。
    cpu1收到Read Invalidate a消息，返回包含a的cache line，并将本地的cache line置为Invalid。
    cpu0收到cpu1传过来的包含a的cache line，然后将store buffer中的a(当前值1)刷新到cache line，并且将cache line状态置为Modified。
    由于cpu0的store buffer中被标记的条目已经全部刷新到cache，此时cpu0可以尝试将store buffer中的b=1刷新到cache，但是由于包含B的cache line已经不是Exclusive而是Shared，因此需要先发Invalidate b消息。
    cpu1收到Invalidate b消息，将包含b的cache line置为Invalid，返回Invalidate ACK。
    cpu1继续执行while(b == 0)，此时b已经不在cache中，因此发出Read消息。
    cpu0收到Invalidate ACK，将store buffer中的b=1写入Cache。
    cpu0收到Read消息，返回包含b新值的cache line。
    cpu1收到包含b的cache line，可以继续执行while(b == 0)，终止循环，然后执行assert(a == 1)，此时a不在其cache中，因此发出Read消息。
    cpu0收到Read消息，返回包含a新值的cache line。
    cpu1收到包含a的cache line，断言为真。

读屏障指令
读屏障指令，Linux将其封装成smp_rmb()函数，和smp_wmb()类似，cpu执行smp_rmb()的时，会先把当前InvalidateQueue中的数据处理掉之后，再执行屏障后的“读取操作”，就像这样：
void foo() {
    a = 1;
    smp_wmb()
    b = 1;
}
void bar() {
    while (b == 0) continue;
    smp_rmb()
    assert(a == 1)
}
###################################################cpu缓存与多线程###################################################

###################################################原子性，可见性，有序性###################################################
内存  ======> 高速缓存(java的话个人理解就是线程栈) ======> CPU寄存器
个人理解原子性是针对高速缓存到CPU寄存器，可见性是针对内存到高速缓存。Java工作内存WorkMemory其实就是对CPU寄存器和高速缓存的抽象，或者说每个线程的工作内存也可以简单理解为CPU寄存器和高速缓存。。

原子性
原子性是指一个操作是不可中断的。即使是在多个线程一起执行的时候，一个操作一旦开始，就不会被其它线程干扰。

有序性
一条指令的执行是可以分为很多步骤的
C 取指 IF                  //(InstrucTIon Fetch)从内存中取出指令  
C 译码和取寄存器操作数 ID  //(InstrucTIon Decode)把指令送到指令译码器进行译码，产生相应控制信号
C 执行或者有效地址计算 EX  //(InstrucTIon Execute)指令执行，在执行阶段的最常见部件为算术逻辑部件运算器(ArithmeTIc Logical Unit，ALU)
C 存储器访问 MEM           //访存（Memory Access）是指存储器访问指令将数据从存储器中读出，或者写入存储器的过程
C 写回 WB                  // 写回（Write-Back）是指将指令执行的结果写回通用寄存器组的过程

单周期处理器(时钟周期1000ps)
IF ID EX MEM WB
               IF ID EX MEM WB
			                  IF ID EX MEM WB
流水线处理器(时钟周期200ps)
IF ID EX MEM WB
   IF ID EX  MEM WB
      IF ID  EX  MEM WB
指令不是一步可以执行完毕的，每个步骤涉及的硬件可能不同，指令的某一步骤在执行的时候，只会占用某个类型的硬件，例如：当A指令在取指的时候，B指令是可以进行译码、执行或者写回等操作的。所以可以使用流水线技术来执行指令。可以看到，当第2条指令执行时，第1条指令只是完成了取值操作。假如每个步骤需要1毫秒，那么如果指令2等待指令1执行完再执行，就需要等待5毫秒。而使用流水线后，只需要等待1毫秒。

例如：A = B + C的处理
LW  R1,B     IF ID EX MEM WB                     //LW表示load，把B的值加载到R1寄存器中
LW  R2,C        IF ID EX  MEM WB                 //LW表示load，把C的值加载到R2寄存器中
ADD R3,R1,R2       IF ID  X   EX MEM WB          //ADD是加法，把R1、R2的值相加，并存放到R3中
SW  A,R3              IF  X   ID EX  MEM WB      //SW表示store存储，将R3寄存器的值保存到变量A中
在ADD指令上的大叉表示一个中断，也就是在这里停顿了一下，因为R2中的数据还没准备好。由于ADD的延迟，后面的指令都要慢一个节拍。
再看复杂一点的情况
A = B + C 
D = E + F
LW  R1,B     IF ID EX MEM WB                     
LW  R2,C        IF ID EX  MEM WB                 
ADD R3,R1,R2       IF ID  X   EX MEM WB          
SW  A,R3              IF  X   ID EX  MEM WB      
LW  R4,E                  X   IF ID  EX  MEM WB 
LW  R5,F                         IF  ID  EX  MEM WB
ADD R6,R4,R5                         IF  ID  X   EX  MEM WB
SW  D,R6                                 IF  X   ID  EX  MEM WB
可见上图中有不少停顿。为了减少停顿，我们只需要将LW R4,E和LW R5,F移动到前面执行。
LW  R1,B     IF ID EX MEM WB                     
LW  R2,C        IF ID EX  MEM WB
LW  R4,E           IF ID  EX  MEM WB                
ADD R3,R1,R2          IF  ID  EX  MEM WB
LW  R5,F                  IF  ID  EX  MEM WB       
SW  A,R3                      IF  ID  EX  MEM WB      
ADD R6,R4,R5                      IF  ID  EX  MEM WB
SW  D,R6                              IF  ID  EX  MEM WB
可见指令重排序对提高CPU性能十分必要，但是要遵循happens-before规则
Happen-Before规则
? 程序顺序原则：一个线程内保证语义的串行性(比如a=1;b=a+1;)
? volatile规则：volatile变量的写，先发生于读，这保证了volatile变量的可见性
? 锁规则：解锁（unlock）必然发生在随后的加锁（lock）前
? 传递性：A先于B，B先于C，那么A必然先于C
? 线程的start()方法先于它的每一个动作
? 线程的所有操作先于线程的终结（Thread.join()）
? 线程的中断（interrupt()）先于被中断线程的代码
? 对象的构造函数执行结束先于finalize()方法

可见性
可见性是指当一个线程修改了某一个共享变量的值，其他线程是否能够立即知道这个修改。
C 编译器优化
C 硬件优化（如写吸收，批操作）

例1：
public class Test {

    public volatile int inc = 0;
    public void increase() {
        inc++;
    }
    public static void main(String[] args) {
        final Test test = new Test();
        for(int i=0;i<10;i++){
            new Thread(){
                public void run() {
                    for(int j=0;j<1000;j++)
                        test.increase();
                };
            }.start();
        }
        while(Thread.activeCount()>1)  //保证前面的线程都执行完
            Thread.yield();
        System.out.println(test.inc);
    }
}
大家想一下这段程序的输出结果是多少？也许有些朋友认为是10000。但是事实上运行它会发现每次运行结果都不一致，都是一个小于10000的数字。
这里面就有一个误区了，volatile关键字能保证可见性没有错，但是上面的程序错在没能保证原子性。可见性只能保证每次读取的是最新的值，但是volatile没办法保证对变量的操作的原子性。
这个例子的说明有点问题：
重点在自增操作并非是原子性的，分3步
1.从线程的工作内存中读取inc到寄存器
2.执行i++
3.再把寄存器的i复制回工作内存
所以在线程1在读取inc的为10后，执行自增操作的第一步或者第二步，此时被堵塞了(在发生线程切换的时候，该线程使用的CPU内部寄存器会被作为现场进行保存)。所以工作内存的inc仍然为10在线程2读取inc的时候，值也是为10，但线程2的自增操作执行完了3步，所以工作内存的inc会被修改为11，由于inc是volatile类型因此你主存的inc也被立刻修改为11，从而所有线程的工作内存里的inc也为11（准确的说是其他线程中，已经缓存该共享变量的CPUCacheLine被设为失效，当其他线程再次读取inc的时候就会从内存中重新读取，但是由于线程1已经将inc读取出来放入CPU寄存器中了，所以在接下来会根据寄存器中的值进行自增，直到下一次再读取inc的值的时候才会重新从内存中读取）。但是由于此时线程1的自增操作是基于寄存器里的i（仍为10），所以才会出现这种情况。所以，volatile是把所有线程的工作内存的变量捆绑在一起，它保证了所有线程的变量是一致的。但它却并不是线程安全的。

例2：
public class VisibilityTest extends Thread {
    private boolean stop;
    public void run() {
        int i = 0;
        while(!stop) {
            i++;
        }
        System.out.println("finish loop,i=" + i);
    }
    public void stopIt() {
        stop = true;
    }
    public boolean getStop(){
        return stop;
    }
    public static void main(String[] args) throws Exception {
        VisibilityTest v = new VisibilityTest();
        v.start();
        Thread.sleep(1000);
        v.stopIt();
        Thread.sleep(2000);
        System.out.println("finish main");
        System.out.println(v.getStop());
    }
}
Java虚拟机层面的可见性
上面代码在不加volatile时，生成的汇编代码如下，stop变量只在0x0193bf99的时候执行一次，进入循环后就不会再从内存中读取stop变量的值：
Java HotSpot(TM) Server VM warning: PrintAssembly is enabled; turning on DebugNonSafepoints to gain additional output
CompilerOracle: dontinline *VisibilityTest.run
CompilerOracle: compileonly *VisibilityTest.run
Loaded disassembler from D:\Dev\Java\jdk1.7.0_25\jre\bin\server\hsdis-i386.dll
Decoding compiled method 0x0193be88:
Code:
Argument 0 is unknown.RIP: 0x193bf80 Code size: 0x00000050
[Disassembling for mach='i386']
[Entry Point]
[Constants]
  # {method} 'run' '()V' in 'edu/hushi/jvm/VisibilityTest'
  #           [sp+0x10]  (sp of caller)
  0x0193bf80: cmp     eax,dword ptr [ecx+4h]
  0x0193bf83: jne     191d100h          ;   {runtime_call}
  0x0193bf89: nop
[Verified Entry Point]
  0x0193bf8c: mov     dword ptr [esp+0ffffc000h],eax
  0x0193bf93: push    ebp
  0x0193bf94: sub     esp,8h            ;*synchronization entry
                                        ; - edu.hushi.jvm.VisibilityTest::run@-1 (line 13)
  0x0193bf97: mov     ebp,ecx
  0x0193bf99: movzx   eax,byte ptr [ecx+64h]  ;*getfield stop
                                        ; - edu.hushi.jvm.VisibilityTest::run@9 (line 14)
  0x0193bf9d: test    eax,eax
  0x0193bf9f: jne     193bfafh          ;*ifeq
                                        ; - edu.hushi.jvm.VisibilityTest::run@12 (line 14)
  0x0193bfa1: mov     ebx,1h            ; OopMap{ebp=Oop off=38}
                                        ;*ifeq
                                        ; - edu.hushi.jvm.VisibilityTest::run@12 (line 14)
  0x0193bfa6: test    dword ptr [0a0000h],edi  ;*ifeq
                                        ; - edu.hushi.jvm.VisibilityTest::run@12 (line 14)
                                        ;   {poll}
  0x0193bfac: inc     ebx               ;*iinc
                                        ; - edu.hushi.jvm.VisibilityTest::run@5 (line 15)
  0x0193bfad: jmp     193bfa6h
  0x0193bfaf: mov     ecx,14h
  0x0193bfb4: nop
  0x0193bfb7: call    191dd00h          ; OopMap{ebp=Oop off=60}
                                        ;*getstatic out
                                        ; - edu.hushi.jvm.VisibilityTest::run@15 (line 17)
                                        ;   {runtime_call}
  0x0193bfbc: int3                      ;*iinc
                                        ; - edu.hushi.jvm.VisibilityTest::run@5 (line 15)
  0x0193bfbd: int3
  0x0193bfbe: hlt
  0x0193bfbf: hlt
[Exception Handler]
[Stub Code]
  0x0193bfc0: jmp     1938780h          ;   {no_reloc}
[Deopt Handler Code]
  0x0193bfc5: push    193bfc5h          ;   {section_word}
  0x0193bfca: jmp     191e280h          ;   {runtime_call}
  0x0193bfcf: hlt
finish main
true

上面代码在加volatile时，生成的汇编代码如下，stop变量会在0x01c7c797和0x01c7c7a1两个地方分别从内存中读取，即每次循环判断之前都会重新从内存中读取stop变量的值：
Java HotSpot(TM) Server VM warning: PrintAssembly is enabled; turning on DebugNonSafepoints to gain additional output
CompilerOracle: dontinline *VisibilityTest.run
CompilerOracle: compileonly *VisibilityTest.run
Loaded disassembler from D:\Dev\Java\jdk1.7.0_25\jre\bin\server\hsdis-i386.dll
Decoding compiled method 0x01c7c688:
Code:
Argument 0 is unknown.RIP: 0x1c7c780 Code size: 0x00000050
[Disassembling for mach='i386']
[Entry Point]
[Constants]
  # {method} 'run' '()V' in 'edu/hushi/jvm/VisibilityTest'
  #           [sp+0x10]  (sp of caller)
  0x01c7c780: cmp     eax,dword ptr [ecx+4h]
  0x01c7c783: jne     1c5d100h          ;   {runtime_call}
  0x01c7c789: nop
[Verified Entry Point]
  0x01c7c78c: mov     dword ptr [esp+0ffffc000h],eax
  0x01c7c793: push    ebp
  0x01c7c794: sub     esp,8h            ;*synchronization entry
                                        ; - edu.hushi.jvm.VisibilityTest::run@-1 (line 13)
  0x01c7c797: movzx   eax,byte ptr [ecx+64h]  ;*getfield stop
                                        ; - edu.hushi.jvm.VisibilityTest::run@9 (line 14)
  0x01c7c79b: xor     ebp,ebp
  0x01c7c79d: test    eax,eax
  0x01c7c79f: jne     1c7c7b0h          ;*iinc
                                        ; - edu.hushi.jvm.VisibilityTest::run@5 (line 15)
  0x01c7c7a1: movzx   ebx,byte ptr [ecx+64h]  ;*getfield stop
                                        ; - edu.hushi.jvm.VisibilityTest::run@9 (line 14)
  0x01c7c7a5: inc     ebp               ; OopMap{ecx=Oop off=38}
                                        ;*ifeq
                                        ; - edu.hushi.jvm.VisibilityTest::run@12 (line 14)
  0x01c7c7a6: test    dword ptr [350000h],edi  ;   {poll}
  0x01c7c7ac: test    ebx,ebx
  0x01c7c7ae: je      1c7c7a1h          ;*getstatic out
                                        ; - edu.hushi.jvm.VisibilityTest::run@15 (line 17)
  0x01c7c7b0: mov     ecx,14h
  0x01c7c7b5: nop
  0x01c7c7b7: call    1c5dd00h          ; OopMap{off=60}
                                        ;*getstatic out
                                        ; - edu.hushi.jvm.VisibilityTest::run@15 (line 17)
                                        ;   {runtime_call}
  0x01c7c7bc: int3                      ;*getstatic out
                                        ; - edu.hushi.jvm.VisibilityTest::run@15 (line 17)
  0x01c7c7bd: hlt
  0x01c7c7be: hlt
  0x01c7c7bf: hlt
[Exception Handler]
[Stub Code]
  0x01c7c7c0: jmp     1c78f80h          ;   {no_reloc}
[Deopt Handler Code]
  0x01c7c7c5: push    1c7c7c5h          ;   {section_word}
  0x01c7c7ca: jmp     1c5e280h          ;   {runtime_call}
  0x01c7c7cf: hlt
finish loop,i=1109307815
finish main
true

查看class字节码文件
javap -verbose java thread.pack.VolatileExample

代码转换为汇编指令:
下载hsdis工具，链接如下；
https://sourceforge.net/projects/fcml/files/fcml-1.1.1/hsdis-1.1.1-win32-amd64.zip/download
下载完毕之后解压，将hsdis-amd64.dll与hsdis-amd64.lib两个文件放在%JAVA_HOME%\jre\bin\server路径下即可
跑main函数之前，加入如下虚拟机参数：
-server
-Xcomp
-XX:+UnlockDiagnosticVMOptions
-XX:CompileCommand=dontinline,*VisibilityTest.run
-XX:CompileCommand=compileonly,*VisibilityTest.run
-XX:+PrintAssembly
注意上面的VisibilityTest.run，它表示将VisibilityTest类中的run方法转换为汇编指令

比如：
public class LazySingleton {
	private static volatile LazySingleton instance = null;
	public static LazySingleton getInstance() {
		if (instance == null) {
			instance = new LazySingleton();
		}
		return instance;
	}
	public static void main(String[] args) {
		LazySingleton.getInstance();
	}
}
跑main函数之前，加入如下虚拟机参数：
-server
-Xcomp
-XX:+UnlockDiagnosticVMOptions
-XX:+PrintAssembly
-XX:CompileCommand=compileonly,*LazySingleton.getInstance
表示它表示将LazySingleton类中的getInstance方法转换为汇编指令
CompilerOracle: compileonly *LazySingleton.getInstance
Loaded disassembler from hsdis-amd64.dll
Decoding compiled method 0x00000000034323d0:
Code:
Argument 0 is unknown.RIP: 0x3432540 Code size: 0x00000248
[Disassembling for mach='amd64']
[Entry Point]
[Verified Entry Point]
[Constants]
  # {method} {0x000000001c380350} 'getInstance' '()Lthread/pack/LazySingleton;' in 'thread/pack/LazySingleton'
  #           [sp+0x40]  (sp of caller)
  0x0000000003432540: mov     dword ptr [rsp+0ffffffffffffa000h],eax
  0x0000000003432547: push    rbp
  0x0000000003432548: sub     rsp,30h
  0x000000000343254c: mov     rdx,1c380548h     ;   {metadata(method data for {method} {0x000000001c380350} 'getInstance' '()Lthread/pack/LazySingleton;' in 'thread/pack/LazySingleton')}
  0x0000000003432556: mov     esi,dword ptr [rdx+0dch]
  0x000000000343255c: add     esi,8h
  0x000000000343255f: mov     dword ptr [rdx+0dch],esi
  0x0000000003432565: mov     rdx,1c380348h     ;   {metadata({method} {0x000000001c380350} 'getInstance' '()Lthread/pack/LazySingleton;' in 'thread/pack/LazySingleton')}
  0x000000000343256f: and     esi,0h
  0x0000000003432572: cmp     esi,0h
  0x0000000003432575: je      343267ah
  0x000000000343257b: mov     rdx,76b3b71a0h    ;   {oop(a 'java/lang/Class' = 'thread/pack/LazySingleton')}
  0x0000000003432585: mov     edx,dword ptr [rdx+68h]
  0x0000000003432588: shl     rdx,3h            ;*getstatic instance
                                                ; - thread.pack.LazySingleton::getInstance@0 (line 6)

  0x000000000343258c: cmp     rdx,0h
  0x0000000003432590: mov     rdx,1c380548h     ;   {metadata(method data for {method} {0x000000001c380350} 'getInstance' '()Lthread/pack/LazySingleton;' in 'thread/pack/LazySingleton')}
  0x000000000343259a: mov     rsi,108h
  0x00000000034325a4: jne     34325b4h
  0x00000000034325aa: mov     rsi,118h
  0x00000000034325b4: mov     rdi,qword ptr [rdx+rsi]
  0x00000000034325b8: lea     rdi,[rdi+1h]
  0x00000000034325bc: mov     qword ptr [rdx+rsi],rdi
  0x00000000034325c0: jne     343265dh          ;*ifnonnull
                                                ; - thread.pack.LazySingleton::getInstance@3 (line 6)

  0x00000000034325c6: mov     rdx,7c0060028h    ;   {metadata('thread/pack/LazySingleton')}
  0x00000000034325d0: mov     rax,qword ptr [r15+60h]
  0x00000000034325d4: lea     rdi,[rax+10h]
  0x00000000034325d8: cmp     rdi,qword ptr [r15+70h]
  0x00000000034325dc: jnbe    3432691h
  0x00000000034325e2: mov     qword ptr [r15+60h],rdi
  0x00000000034325e6: mov     rcx,qword ptr [rdx+0a8h]
  0x00000000034325ed: mov     qword ptr [rax],rcx
  0x00000000034325f0: mov     rcx,rdx
  0x00000000034325f3: shr     rcx,3h
  0x00000000034325f7: mov     dword ptr [rax+8h],ecx
  0x00000000034325fa: xor     rcx,rcx
  0x00000000034325fd: mov     dword ptr [rax+0ch],ecx
  0x0000000003432600: xor     rcx,rcx           ;*new  ; - thread.pack.LazySingleton::getInstance@6 (line 7)

  0x0000000003432603: mov     rdx,rax
  0x0000000003432606: mov     rsi,1c380548h     ;   {metadata(method data for {method} {0x000000001c380350} 'getInstance' '()Lthread/pack/LazySingleton;' in 'thread/pack/LazySingleton')}
  0x0000000003432610: add     qword ptr [rsi+128h],1h
  0x0000000003432618: mov     rdx,rax           ;*invokespecial <init>
                                                ; - thread.pack.LazySingleton::getInstance@10 (line 7)

  0x000000000343261b: mov     qword ptr [rsp+20h],rax
  0x0000000003432620: nop
  0x0000000003432621: nop
  0x0000000003432622: nop
  0x0000000003432623: nop
  0x0000000003432624: nop
  0x0000000003432625: nop
  0x0000000003432626: nop
  0x0000000003432627: call    33761a0h          ; OopMap{[32]=Oop off=236}
                                                ;*invokespecial <init>
                                                ; - thread.pack.LazySingleton::getInstance@10 (line 7)
                                                ;   {optimized virtual_call}
  0x000000000343262c: mov     rax,76b3b71a0h    ;   {oop(a 'java/lang/Class' = 'thread/pack/LazySingleton')}
  0x0000000003432636: mov     rsi,qword ptr [rsp+20h]
  0x000000000343263b: mov     r10,rsi
  0x000000000343263e: shr     r10,3h
  0x0000000003432642: mov     dword ptr [rax+68h],r10d
  0x0000000003432646: shr     rax,9h
  0x000000000343264a: mov     rsi,0f0e4000h
  0x0000000003432654: mov     byte ptr [rax+rsi],0h
  0x0000000003432658: lock add dword ptr [rsp],0h  ;*putstatic instance
                                                ; - thread.pack.LazySingleton::getInstance@13 (line 7)

  0x000000000343265d: mov     rax,76b3b71a0h    ;   {oop(a 'java/lang/Class' = 'thread/pack/LazySingleton')}
  0x0000000003432667: mov     eax,dword ptr [rax+68h]
  0x000000000343266a: shl     rax,3h            ;*getstatic instance
                                                ; - thread.pack.LazySingleton::getInstance@16 (line 9)

  0x000000000343266e: add     rsp,30h
  0x0000000003432672: pop     rbp
  0x0000000003432673: test    dword ptr [1470100h],eax
                                                ;   {poll_return}
  0x0000000003432679: ret
  0x000000000343267a: mov     qword ptr [rsp+8h],rdx
  0x000000000343267f: mov     qword ptr [rsp],0ffffffffffffffffh
  0x0000000003432687: call    342f1e0h          ; OopMap{off=332}
                                                ;*synchronization entry
                                                ; - thread.pack.LazySingleton::getInstance@-1 (line 6)
                                                ;   {runtime_call}
  0x000000000343268c: jmp     343257bh
  0x0000000003432691: mov     rdx,rdx
  0x0000000003432694: call    342b280h          ; OopMap{off=345}
                                                ;*new  ; - thread.pack.LazySingleton::getInstance@6 (line 7)
                                                ;   {runtime_call}
  0x0000000003432699: jmp     3432603h
  0x000000000343269e: nop
  0x000000000343269f: nop
  0x00000000034326a0: mov     rax,qword ptr [r15+2a8h]
  0x00000000034326a7: mov     r10,0h
  0x00000000034326b1: mov     qword ptr [r15+2a8h],r10
  0x00000000034326b8: mov     r10,0h
  0x00000000034326c2: mov     qword ptr [r15+2b0h],r10
  0x00000000034326c9: add     rsp,30h
  0x00000000034326cd: pop     rbp
  0x00000000034326ce: jmp     339d520h          ;   {runtime_call}
  0x00000000034326d3: hlt
  0x00000000034326d4: hlt
  0x00000000034326d5: hlt
  0x00000000034326d6: hlt
  0x00000000034326d7: hlt
  0x00000000034326d8: hlt
  0x00000000034326d9: hlt
  0x00000000034326da: hlt
  0x00000000034326db: hlt
  0x00000000034326dc: hlt
  0x00000000034326dd: hlt
  0x00000000034326de: hlt
  0x00000000034326df: hlt
[Stub Code]
  0x00000000034326e0: nop                       ;   {no_reloc}
  0x00000000034326e1: nop
  0x00000000034326e2: nop
  0x00000000034326e3: nop
  0x00000000034326e4: nop
  0x00000000034326e5: mov     rbx,0h            ;   {static_stub}
  0x00000000034326ef: jmp     34326efh          ;   {runtime_call}
[Exception Handler]
  0x00000000034326f4: call    342c9a0h          ;   {runtime_call}
  0x00000000034326f9: mov     qword ptr [rsp+0ffffffffffffffd8h],rsp
  0x00000000034326fe: sub     rsp,80h
  0x0000000003432705: mov     qword ptr [rsp+78h],rax
  0x000000000343270a: mov     qword ptr [rsp+70h],rcx
  0x000000000343270f: mov     qword ptr [rsp+68h],rdx
  0x0000000003432714: mov     qword ptr [rsp+60h],rbx
  0x0000000003432719: mov     qword ptr [rsp+50h],rbp
  0x000000000343271e: mov     qword ptr [rsp+48h],rsi
  0x0000000003432723: mov     qword ptr [rsp+40h],rdi
  0x0000000003432728: mov     qword ptr [rsp+38h],r8
  0x000000000343272d: mov     qword ptr [rsp+30h],r9
  0x0000000003432732: mov     qword ptr [rsp+28h],r10
  0x0000000003432737: mov     qword ptr [rsp+20h],r11
  0x000000000343273c: mov     qword ptr [rsp+18h],r12
  0x0000000003432741: mov     qword ptr [rsp+10h],r13
  0x0000000003432746: mov     qword ptr [rsp+8h],r14
  0x000000000343274b: mov     qword ptr [rsp],r15
  0x000000000343274f: mov     rcx,6e959e40h     ;   {external_word}
  0x0000000003432759: mov     rdx,34326f9h      ;   {internal_word}
  0x0000000003432763: mov     r8,rsp
  0x0000000003432766: and     rsp,0fffffffffffffff0h
  0x000000000343276a: call    6e613cf0h         ;   {runtime_call}
  0x000000000343276f: hlt
[Deopt Handler Code]
  0x0000000003432770: mov     r10,3432770h      ;   {section_word}
  0x000000000343277a: push    r10
  0x000000000343277c: jmp     3377600h          ;   {runtime_call}
  0x0000000003432781: hlt
  0x0000000003432782: hlt
  0x0000000003432783: hlt
  0x0000000003432784: hlt
  0x0000000003432785: hlt
  0x0000000003432786: hlt
  0x0000000003432787: hlt
注意上面汇编指令中的：
lock add dword ptr [rsp],0h  ;*putstatic instance; - thread.pack.LazySingleton::getInstance@13 (line 7)
由于变量instance加了volatile关键字修饰，所以转换成汇编指令后会在add前面增加lock指令以保证内存可见性

例3：
public class DoubleCheckLock {
    private static DoubleCheckLock instance;
    private DoubleCheckLock(){}
    public static DoubleCheckLock getInstance(){
        //第一次检测
        if (instance==null){
            //同步
            synchronized (DoubleCheckLock.class){
                if (instance == null){
                    //多线程环境下可能会出现问题的地方
                    instance = new DoubleCheckLock();
                }
            }
        }
        return instance;
    }
}
上述代码一个经典的单例的双重检测的代码，这段代码在单线程环境下并没有什么问题，但如果在多线程环境下就可以出现线程安全问题。原因在于某一个线程执行到第一次检测，读取到的instance不为null时，instance的引用对象可能没有完成初始化。
因为instance = new DoubleCheckLock();可以分为以下3步完成(伪代码)
memory = allocate(); //1.分配对象内存空间
instance(memory);    //2.初始化对象
instance = memory;   //3.设置instance指向刚分配的内存地址，此时instance！=null
由于步骤1和步骤2间可能会重排序，如下：
memory = allocate(); //1.分配对象内存空间
instance = memory;   //3.设置instance指向刚分配的内存地址，此时instance！=null，但是对象还没有初始化完成！
instance(memory);    //2.初始化对象
由于步骤2和步骤3不存在数据依赖关系，而且无论重排前还是重排后程序的执行结果在单线程中并没有改变，因此这种重排优化是允许的。但是指令重排只会保证串行语义的执行的一致性(单线程)，但并不会关心多线程间的语义一致性。所以当一条线程访问instance不为null时，由于instance实例未必已初始化完成，也就造成了线程安全问题。那么该如何解决呢，很简单，我们使用volatile禁止instance变量被执行指令重排优化即可。
//禁止指令重排优化
 private volatile static DoubleCheckLock instance;
###################################################原子性，可见性，有序性###################################################

###################################################Thread、Runnable###################################################
1.Thread和Runnable都可以实现多线程（废话）
2.Thread是类，而Runnable是接口，这就是类和接口区别，类只能继承一次，而接口可以实现多个接口。
3.Thread实现Runnable接口，这个可以查看Thread的源代码。
4.最重要的分享资源功能，一般我们使用多线程就是快速解决资源问题。Runnable可以实现资源分享，类实现Runnable并不具备线程功能，必须通过new Thread(Runnable子类)调用start()启动线程，所以我们通常new一个Runnable的子类，启动多个线程解决资源问题。很多人说的Thread类不能共享资源，其实并不是不能，只是不适合。我们从Thread源码中也可以看到，当以Thread方式去实现资源共享时，实际上源码内部是将thread向下转型为了Runnable，实际上内部依然是以Runnable形式去实现的资源共享
5.通过以上建议最好实现Runnable接口 实现多线程。

Thread的启动线程的流程：Thread.start() --> navite start0() --> {Runnable.run() or Thread.run()};
Thread有两大类构造函数：
1、public Thread(String name)
2、public Thread(Runnable target)
通过start()启动线程的时候会调用run()，run里会判断new Thread时是否传入了参数Runnable target，如果传入则调用Runnable里面的run方法
以继承Thread的方式启动线程时，子类必须Override掉Thread类中的run方法，由于没有传入Runnable，然后start调用的就是子类中的run方法。

/**
 * Thread 实现资源共享
 * @author itbird
 *
 */
public class Test2 {

    public static void main(String[] args) {
        MyThread t1 = new MyThread();
        new Thread(t1, "线程1").start();
        new Thread(t1, "线程2").start();
    }

    public static class MyThread extends Thread {
        private int total = 10;

        @Override
        public void run() {
            for (int i = 0; i < 10; i++) {
                synchronized (this) {
                    if (total > 0) {
                        try {
                            Thread.sleep(100);
                            System.out.println(Thread.currentThread().getName() + "卖票---->" + (this.total--));
                        } catch (InterruptedException e) {
                            e.printStackTrace();
                        }
                    }
                }
            }
        }
    }
}

###################################################Thread、Runnable###################################################

###################################################Thread的中断机制###################################################
线程的thread.interrupt()方法是中断线程，将会设置该线程的中断状态位，即设置为true，中断的结果线程是死亡、还是等待新的任务或是继续运行至下一步，就取决于这个程序本身。它并不像stop方法那样会中断一个正在运行的线程。

public static boolean interrupted     判断某个线程是否已被发送过中断请求。（该方法调用后会将中断标示位清除，即重新设置为false）
public boolean isInterrupted()        判断某个线程是否已被发送过中断请求。（线程的中断状态不受该方法的影响）
public void interrupt()               中断线程，将会设置该线程的中断状态位，即设置为true，     
Java的中断是一种协作机制。也就是说调用线程对象的interrupt方法并不一定就中断了正在运行的线程，它只是要求线程自己在合适的时机中断自己。每个线程都有一个boolean的中断状态（这个状态不在Thread的属性上），interrupt方法仅仅只是将该状态置为true。对正常运行的线程调用interrupt()并不能终止他，只是改变了interrupt标示符。
一般说来，如果一个方法声明抛出InterruptedException，表示该方法是可中断的,比如wait,sleep,join，也就是说可中断方法会对interrupt调用做出响应（例如sleep响应interrupt的操作包括清除中断状态，抛出InterruptedException）,异常都是由可中断方法自己抛出来的，并不是直接由interrupt方法直接引起的。
Object.wait,Thread.sleep等方法会不断的轮询监听interrupted标志位，发现其设置为true后，会停止阻塞并抛出InterruptedException异常。
一、没有任何语言方面的需求一个被中断的线程应该终止。中断一个线程只是为了引起该线程的注意，被中断线程可以决定如何应对中断。
二、对于处于sleep，join等操作的线程，如果被调用interrupt()后，会抛出InterruptedException，然后线程的中断标志位会由true重置为false，因为线程为了处理异常已经重新处于就绪状态。
三、不可中断的操作，包括进入synchronized段以及Lock.lock()，inputSteam.read()等，调用interrupt()对于这几个问题无效，因为它们都不抛出中断异常。如果拿不到资源，它们会无限期阻塞下去。
对于Lock.lock()，可以改用Lock.lockInterruptibly()，可被中断的加锁操作，它可以抛出中断异常。等同于等待时间无限长的Lock.tryLock(long time, TimeUnit unit)。
对于inputStream等资源，有些(实现了interruptibleChannel接口)可以通过close()方法将资源关闭，对应的阻塞也会被放开。

总之线程的thread.interrupt()是设置一个中断状态位，至于中不中断由线程自己决定，
例如：使用中断信号量中断非阻塞状态的线程
class InterruptActiveThread extends Thread {
    public static void main(String args[]) throws Exception {
        InterruptActiveThread thread = new InterruptActiveThread();
        System.out.println("Starting thread...");
        thread.start();
        Thread.sleep(3000);
        System.out.println("Asking thread to stop...");
        // 发出中断请求
        thread.interrupt();
        Thread.sleep(3000);
        System.out.println("Stopping application...");
    }

    public void run() {
        // 每隔一秒检测是否设置了中断标示
        while (!Thread.currentThread().isInterrupted()) {
            System.out.println("Thread is running...");
            long time = System.currentTimeMillis();
            // 使用while循环模拟 sleep
            while ((System.currentTimeMillis() - time < 1000) ) {
            }
        }
        System.out.println("Thread exiting under request...");
    }
}

使用thread.interrupt()中断阻塞状态线程
public class InterruptBlockThread extends Thread {

	public static void main(String[] args) throws InterruptedException {

		InterruptBlockThread thread = new InterruptBlockThread();
		System.out.println("Starting thread...");
		thread.start();
		Thread.sleep(3000);
		System.out.println("Asking thread to stop...");
		thread.interrupt();// 等中断信号量设置后再调用
		Thread.sleep(3000);
		System.out.println("Stopping application...");

	}

	public void run() {
		while (!Thread.currentThread().isInterrupted()) {
			System.out.println("Thread running...");
			try {
				/*
				 * 如果线程阻塞，将不会去检查中断信号量stop变量，所 以thread.interrupt()
				 * 会使阻塞线程从阻塞的地方抛出异常，让阻塞线程从阻塞状态逃离出来，并 进行异常块进行 相应的处理
				 */
				Thread.sleep(1000);// 线程阻塞，如果线程收到中断操作信号将抛出异常
			} catch (InterruptedException e) {
				System.out.println("Thread interrupted...");
				/*
				 * 如果线程在调用 Object.wait()方法，或者该类的 join() 、sleep()方法 过程中受阻，则其中断状态将被清除
				 */
				System.out.println(this.isInterrupted());// false

				// 中不中断由自己决定，如果需要真正中断线程，则需要重新设置中断位，如果
				// 不需要，则不用调用
				Thread.currentThread().interrupt();
			}
		}
		System.out.println("Thread exiting under request...");
	}
}

###################################################Thread的中断机制###################################################

############################################Java线程的5种状态及切换############################################
Thread.class中可以找到这个枚举，它定义了线程的相关状态:
public enum State {
    NEW,
    RUNNABLE,
    BLOCKED,
    WAITING,
    TIMED_WAITING,
    TERMINATED;
}
1.NEW=>新建状态，线程创建且没有执行start方法时的状态
2.RUNNABLE=>可运行状态，线程已经启动，但是等待相应的资源（比如IO或者时间片切换）才能开始执行
3.BLOCKED=>阻塞状态，当遇到synchronized或者lock且没有取得相应的锁，就会进入这个状态
4.WAITING=>等待状态，当调用Object.wait或者Thread.join()且没有设置时间，在或者LockSupport.park时，都会进入等待状态。
5.TIMED_WAITING=>计时等待，当调用Thread.sleep()或者Object.wait(xx)或者Thread.join(xx)或者LockSupport.parkNanos或者LockSupport.partUntil时，进入该状态
6.TERMINATED=>终止状态，线程中断或者运行结束的状态
############################################Java线程的5种状态及切换############################################

############################################Thread sleep,yield,wait############################################
1.sleep()方法
sleep()是Thread类中的方法
在指定时间内让当前正在执行的线程暂停执行，让出cpu给其他线程，但不会释放“锁标志”。当指定的时间到了又会自动恢复运行状态。
sleep()使当前线程进入阻塞状态，在指定时间内不会执行。sleep可使优先级低的线程得到执行的机会，当然也可以让同优先级和高优先级的线程有执行的机会
sleep是静态方法，是谁掉的谁去睡觉，就算是在main线程里调用了线程b的sleep方法，实际上还是main去睡觉，想让线程b去睡觉要在b的代码中掉sleep。

2.yield()方法
只是使当前线程重新回到可执行状态（yield()将导致线程从运行状态转到可运行状态），所以执行yield()线程有可能在进入到可执行状态后马上又被执行. 只能使同优先级的线程有执行的机会。同样, yield()也不会释放锁资源.
sleep和yield的区别在于, sleep可以使优先级低的线程得到执行的机会,  而yield只能使同优先级的线程有执行的机会.

3.wait()方法
wait()是object类中的方法，当调用时会释放对象锁，进入等待队列，待调用notify()和notifyAll()唤醒指定线程或者所有线程。
在其他线程调用对象的notify或notifyAll方法前，导致当前线程等待。线程会释放掉它所占有的“锁标志”，从而使别的线程有机会抢占该锁。
当前线程必须拥有当前对象锁。如果当前线程不是此锁的拥有者，会抛出IllegalMonitorStateException异常。
唤醒当前对象锁的等待线程使用notify或notifyAll方法，也必须拥有相同的对象锁，否则也会抛出IllegalMonitorStateException异常。
waite()和notify()必须在synchronized函数或synchronized　block中进行调用。如果在non-synchronized函数或non-synchronized　block中进行调用，虽然能编译通过，但在运行时会发生IllegalMonitorStateException的异常。

sleep(100L)表示:调用sleep后线程进入计时等待状态(TIMED_WAITING)，让出cpu给其他线程；100毫秒后回到可运行状态(RUNNABLE)，虽然sleep没有释放锁，但是在指定的sleep时间后，也许另外一个线程正在使用CPU，那么这时候操作系统是不会重新分配CPU的，直到那个线程挂起或结束；即使这个时候恰巧轮到操作系统进行CPU分配，那么当前线程也不一定就是总优先级最高的那个，CPU还是可能被其他线程抢占去。即Thread.sleep(2000)，2000ms后线程进入就绪状态,如果很长时间都没有获得CPU的执行权，有可能导致睡了大于2000ms。
wait(100L)表示:调用wait后线程进入计时等待状态(TIMED_WAITING)，100毫秒如果锁没有被其他线程占用，则再次得到锁，然后回到可运行状态(RUNNABLE)，但是如果锁被其他线程占用，则进入阻塞状态(BLOCKED)等待os调用分配资源;
Thread.sleep(0)的作用，就是触发操作系统立刻重新进行一次CPU竞争，重新计算优先级。竞争的结果也许是当前线程仍然获得CPU控制权，也许会换成别的线程获得CPU控制权。这也是我们在大循环里面经常会写一句Thread.sleep(0)，因为这样就给了其他线程比如Paint线程获得CPU控制权的权利，这样界面就不会假死在哪里。

############################################Thread sleep,yield,wait############################################

#################################################Thread.join#################################################
    /** 
     * Waits at most {@code millis} milliseconds for this thread to 
     * die. A timeout of {@code 0} means to wait forever. 
     * 
     * <p> This implementation uses a loop of {@code this.wait} calls 
     * conditioned on {@code this.isAlive}. As a thread terminates the 
     * {@code this.notifyAll} method is invoked. It is recommended that 
     * applications not use {@code wait}, {@code notify}, or 
     * {@code notifyAll} on {@code Thread} instances. 
     * 
     * @param  millis 
     *         the time to wait in milliseconds 
     * 
     * @throws  IllegalArgumentException 
     *          if the value of {@code millis} is negative 
     * 
     * @throws  InterruptedException 
     *          if any thread has interrupted the current thread. The 
     *          <i>interrupted status</i> of the current thread is 
     *          cleared when this exception is thrown. 
     */  
    public final synchronized void join(long millis)  
    throws InterruptedException {  
        long base = System.currentTimeMillis();  
        long now = 0;  
      
        if (millis < 0) {  
            throw new IllegalArgumentException("timeout value is negative");  
        }  
      
        if (millis == 0) {  
            while (isAlive()) {  
                wait(0);  
            }  
        } else {  
            while (isAlive()) {  
                long delay = millis - now;  
                if (delay <= 0) {  
                    break;  
                }  
                wait(delay);  
                now = System.currentTimeMillis() - base;  
            }  
        }  
    }
Join方法实现是通过wait（小提示：Object 提供的方法）。 当main线程调用t.join时候，main线程会获得线程对象t的锁（wait 意味着拿到该对象的锁),
调用该对象的wait(等待时间)，直到该对象唤醒main线程，比如退出后。
1) main线程中调用子线程的join()方法,join()方法中的isAlive()应该是判断"子线程"是不是Alive状态
而wait()的作用是让"当前线程"等待,而这里的"当前线程"是指当前在CPU上运行的线程.所以,虽然是调用子线程的wait()方法,但是它是通过"主线程"去调用的:
所以,休眠的是主线程,而不是"子线程"!
即:A线程调用B线程的时候,可以把B线程看成是一个对象,当在一个线程中调用一个对象的wait()方法时候会导致当前线程阻塞.
Object中wait()方法的定义:导致当前的线程等待,直到其他线程调用此对象的notify()方法或notifyAll()方法,或者超过指定的时间量. 
2) 线程执行完毕后系统会调用notifyAll(),唤醒等待在该线程对象上的其他线程.（这个调用是虚拟机层面的调用不在Thread类中）
#################################################Thread.join#################################################

########################################Java中synchronized同步锁四种用法及作用范围//########################################
Java中的对象锁和类锁：java的对象锁和类锁在锁的概念上基本上和内置锁是一致的，但是，两个锁实际是有很大的区别的，对象锁是用于对象实例方法，或者一个对象实例上的，类锁是用于类的静态方法或者一个类的class对象上的。我们知道，类的对象实例可以有很多个，但是每个类只有一个class对象，所以不同对象实例的对象锁是互不干扰的，但是每个类只有一个类锁。但是有一点必须注意的是，其实类锁只是一个概念上的东西，并不是真实存在的，它只是用来帮助我们理解锁定实例方法和静态方法的区别的。

synchronized 关键字主要有以下几种用法： 
- 非静态方法的同步； 
- 静态方法的同步； 
- 代码块。

下面分对象锁和类锁来分别说明 synchronized 用法：
对象锁
非静态方法使用 synchronized 修饰的写法，修饰实例方法时，锁定的是当前对象：
    public synchronized void test(){
        // TODO
    }
代码块使用 synchronized 修饰的写法，使用代码块，如果传入的参数是 this，那么锁定的也是当前的对象：
    public void test(){
        synchronized (this) {
            // TODO
        }
    }
对象锁的范围：对象的某个同步方法被一个线程访问后，其他线程能不能访问该对象的其他同步方法，但是另一个线程还是可以访问没有进行同步的方法或者代码。进行了同步的方法（加锁方法）和没有进行同步的方法（普通方法）是互不影响的，一个线程进入了同步方法，得到了对象锁，其他线程还是可以访问那些没有同步的方法（普通方法）。
类锁
类锁需要 synchronized 来修饰静态 static 方法，写法如下：
    public static synchronized void test(){
        // TODO
    }
或者使用代码块，需引用当前的类：
    public static void test(){
        synchronized (TestSynchronized.class) {
            // TODO
        }
    }
类锁和对象锁其实是一样的，由于静态方法是类所有对象共用的，所以进行同步后，该静态方法的锁也是所有对象唯一的。每次只能有一个线程来访问对象的该静态同步方法。
注意：类锁和对象锁是不一样的锁，是互相独立的。
总结
A.无论synchronized关键字加在方法上还是对象上，如果它作用的对象是非静态的，则它取得的锁是对象；如果synchronized作用的对象是一个静态方法或一个类，则它取得的锁是对类，该类所有的对象同一把锁。 
B.每个对象只有一个锁（lock）与之相关联，谁拿到这个锁谁就可以运行它所控制的那段代码。 
C.实现同步是要很大的系统开销作为代价的，甚至可能造成死锁，所以尽量避免无谓的同步控制。
########################################Java中synchronized同步锁四种用法及作用范围########################################

#################################################JDK 并发包#################################################
1.1. ReentrantLock
1.1.1. 可重入
单线程可以重复进入，但要重复退出
1.1.2. 可中断
lockInterruptibly()
1.1.3. 可限时
超时不能获得锁，就返回false，不会永久等待构成死锁
1.1.4. 公平锁
先来先得
public ReentrantLock(boolean fair)
public static ReentrantLock fairLock = new ReentrantLock(true);

1.2. Condition
1.2.1. 概述
类似于 Object.wait()和Object.notify()
与ReentrantLock结合使用
1.2.2. 主要接口
void await() throws InterruptedException;
void awaitUninterruptibly();
long awaitNanos(long nanosTimeout) throws InterruptedException;
boolean await(long time, TimeUnit unit) throws InterruptedException;
boolean awaitUntil(Date deadline) throws InterruptedException;
void signal();
void signalAll();
1.2.3. API详解
await()方法会使当前线程等待，同时释放当前锁，当其他线程中使用signal()时或者signalAll()方法时，线程会重新获得锁并继续执行。或者当线程被中断时，也能跳出等待。这和Object.wait()方法很相似。awaitUninterruptibly()方法与await()方法基本相同，但是它并不会再等待过程中响应中断。singal()方法用于唤醒一个在等待中的线程。相对的singalAll()方法会唤醒所有在等待中的线程。这和Obejct.notify()方法很类似。

1.3.Semaphore
1.3.1. 概述
共享锁
允许多个线程同时进入临界区
1.3.2. 主要接口
public void acquire()
public void acquireUninterruptibly()
public boolean tryAcquire()
public boolean tryAcquire(long timeout, TimeUnit unit)
public void release()

1.4.ReadWriteLock
1.4.1. 概述
ReadWriteLock是JDK5中提供的读写分离锁
1.4.2. 访问情况
读-读不互斥：读读之间不阻塞。
读-写互斥：读阻塞写，写也会阻塞读。
写-写互斥：写写阻塞。
1.4.3. 主要接口
private static ReentrantReadWriteLock readWriteLock=new ReentrantReadWriteLock();
private static Lock readLock = readWriteLock.readLock();
private static Lock writeLock = readWriteLock.writeLock();

1.5.CountDownLatch
1.5.1. 概述
倒数计时器
一种典型的场景就是火箭发射。在火箭发射前，为了保证万无一失，往往还要进行各项设备、仪器的检查。只有等所有检查完毕后，引擎才能点火。这种场景就非常适合使用CountDownLatch。它可以使得点火线程，等待所有检查线程全部完工后，再执行
1.5.2. 主要接口
static final CountDownLatch end = new CountDownLatch(10);
end.countDown();
end.await();

1.6. CyclicBarrier
1.6.1. 概述
循环栅栏
Cyclic意为循环，也就是说这个计数器可以反复使用。比如，假设我们将计数器设置为10。那么凑齐第一批10个线程后，计数器就会归零，然后接着凑齐下一批10个线程
1.6.2. 主要接口
public CyclicBarrier(int parties, Runnable barrierAction)
barrierAction就是当计数器一次计数完成后，系统会执行的动作
await()

1.7. LockSupport
1.7.1. 概述
提供线程阻塞原语
1.7.2. 主要接口
LockSupport.park();
LockSupport.unpark(t1);
1.7.3. 与suspend()比较
不容易引起线程冻结
1.7.4. 中断响应
能够响应中断，但不抛出异常。中断响应的结果是，park()函数的返回，可以从Thread.interrupted()得到中断标志

1.8. ReentrantLock 的实现
1.8.1. CAS状态
1.8.2. 等待队列
1.8.3. park()
#################################################JDK 并发包#################################################

#################################################JVM Server与Client运行模式#################################################
JVM Server与Client运行模式 
JVM Server模式与client模式启动，最主要的差别在于：-Server模式启动时，速度较慢，但是一旦运行起来后，性能将会有很大的提升.原因是:
当虚拟机运行在-client模式的时候,使用的是一个代号为C1的轻量级编译器, 而-server模式启动的虚拟机采用相对重量级,代号为C2的编译器. C2比C1编译器编译的相对彻底,,服务起来之后,性能更高.
Java -version 可以直接查看出你使用的是client还是 server
Jvm client代码:
    C:\Documents and Settings\Administrator>java -version  
    java version "1.6.0_21"  
    Java(TM) SE Runtime Environment (build 1.6.0_21-b06)  
    Java HotSpot(TM) Client VM (build 17.0-b16, mixed mode, sharing) 
Jvm server代码:
    [root@kaifa02 ~]# java -version  
    java version "1.6.0_06"  
    Java(TM) SE Runtime Environment (build 1.6.0_06-b02)  
    Java HotSpot(TM) Server VM (build 10.0-b22, mixed mode)

两种模式的切换可以通过更改配置(jvm.cfg配置文件)来实现:
32位的虚拟机在目录JAVA_HOME/jre/lib/i386/jvm.cfg,
64位的在JAVA_HOME/jre/lib/amd64/jvm.cfg, 目前64位只支持server模式,  配置内容大致如下
    -server KNOWN  
    -client KNOWN  
    -hotspot ALIASED_TO -client  
    -classic WARN  
    -native ERROR  
    -green ERROR  
一般只要变更 -server KNOWN 与 -client KNOWN 两个配置位置先后顺序即可,前提是JAVA_HOME/jre/bin 目录下同时存在 server 与client两个文件夹,分别对应着各自的jvm.
缺少其中一个,切换模式就会报错.类似下图:

Java虚拟机层面的可见性
public class VisibilityTest extends Thread { 
	private boolean stop;

	public void run() {
		int i = 0;
		while (!stop) {
			i++;
		}
		System.out.println("finish loop,i=" + i);
	}

	public void stopIt() {
		stop = true;
	}

	public boolean getStop() {
		return stop;
	}
	public static void main(String[] args) throws Exception {
		VisibilityTest v = new VisibilityTest();
		v.start();
		Thread.sleep(1000);
		v.stopIt();
		Thread.sleep(2000);
		System.out.println("finish main");
		System.out.println(v.getStop());
	}
}
-server模式运行上述代码，永远不会停止
#################################################JVM Server与Client运行模式#################################################

#################################################锁的优化#################################################

Java对象头与Monitor
java对象头是实现synchronized的锁对象的基础，synchronized使用的锁对象是存储在Java对象头里的。
对象头包含两部分：Mark Word 和 Class Metadata Address
虚拟机位数 头对象结构              说明
32/64bit   Mark Word               存储对象的hashCode,锁信息或分代年龄或GC标志等信息
32/64bit   Class MetaData Address  类型指针指向对象的类元数据，JVM通过这个指针确定该对象是哪个类的实例。
其中Mark Word在默认情况下存储着对象的HashCode、分代年龄、锁标记位等以下是32位JVM的Mark Word默认存储结构
锁状态   25bit         4bit           1bit是否偏向锁 2bit锁标志位
无锁状态 对象hashCode  对象分代年龄   0              01
轻量级锁 指向栈中锁记录的指针                        00
重量级锁 指向互斥量(重量级锁)的指针                  10   
GC标记   空                                          11
偏向锁   线程ID Epoch  对象分代年龄   1              01

重量级锁synchronized的实现
重量级锁也就是通常说synchronized的对象锁，锁标识位为10，其中指针指向的是monitor对象（也称为管程或监视器锁）的起始地址。每个对象都存在着一个monitor与之关联，对象与其monitor之间的关系有存在多种实现方式，如monitor可以与对象一起创建销毁或当线程试图获取对象锁时自动生成，但当一个monitor被某个线程持有后，它便处于锁定状态。当多个线程同时访问一段同步代码时，首先会进入EntrySet当线程获取到对象的monitor后进入TheOwner区域并把monitor中的owner变量设置为当前线程，同时monitor中的计数器count加1，若线程调用wait()方法，将释放当前持有的monitor，owner变量恢复为null，count自减1，同时该线程进入WaitSet集合中等待被唤醒。若当前线程执行完毕也将释放monitor(锁)并复位变量的值，以便其他线程进入获取monitor(锁)。由此看来，monitor对象存在于每个Java对象的对象头中(存储的指针的指向)，synchronized锁便是通过这种方式获取锁的，也是为什么Java中任意对象可以作为锁的原因，同时也是notify/notifyAll/wait等方法存在于顶级对象Object中的原因。

自旋锁与自适应自旋
Java的线程是映射到操作系统的原生线程之上的，如果要阻塞或唤醒一个线程，都需要操作系统来帮忙完成，这就需要从用户态转换到内核态中，因此状态转换需要耗费很多的处理器时间，对于代码简单的同步块（如被synchronized修饰的getter()和setter()方法），状态转换消耗的时间有可能比用户代码执行的时间还要长。 
虚拟机的开发团队注意到在许多应用上，共享数据的锁定状态只会持续很短的一段时间，为了这段时间去挂起和恢复线程并不值得。如果物理机器有一个以上的处理器，能让两个或以上的线程同时并行执行，我们就可以让后面请求锁的那个线程“稍等一下“，但不放弃处理器的执行时间，看看持有锁的线程是否很快就会释放锁。为了让线程等待，我们只需让线程执行一个忙循环（自旋），这项技术就是所谓的自旋锁。
自旋锁在JDK1.4.2中引入，使用-XX:+UseSpinning来开启。JDK1.6中已经变为默认开。自旋等待不能代替阻塞。自旋等待本身虽然避免了线程切换的开销，但它是要占用处理器时间的，因此，如果锁被占用的时间很短，自旋等待的效果就会非常好，反之，如果锁被占用的时间很长，那么自旋的线程只会浪费处理器资源。因此，自旋等待的时间必须要有一定的限度，如果自旋超过了限定次数（默认是10次，可以使用-XX:PreBlockSpin来更改）没有成功获得锁，就应当使用传统的方式去挂起线程了。
JDK1.6中引入自适应的自旋锁，自适应意味着自旋的时间不再固定。而是有虚拟机对程序锁的监控与预测来设置自旋的次数。
自旋是在轻量级锁中使用的

轻量级锁
轻量级锁提升程序同步性能的依据是：对于绝大部分的锁，在整个同步周期内都是不存在竞争的（区别于偏向锁）。这是一个经验数据。如果没有竞争，轻量级锁使用CAS操作避免了使用互斥量的开销，但如果存在锁竞争，除了互斥量的开销外，还额外发生了CAS操作，因此在有竞争的情况下，轻量级锁比传统的重量级锁更慢
轻量级锁的加锁过程：
1)在代码进入同步块的时候，如果同步对象锁状态为无锁状态（锁标志位为“01”状态，是否为偏向锁为“0”），虚拟机首先将在当前线程的栈帧中建立一个名为锁记录（LockRecord）的空间，用于存储锁对象目前的MarkWord的拷贝，官方称之为DisplacedMarkWord。
2)拷贝对象头中的MarkWord复制到锁记录（LockRecord）中；
3)拷贝成功后，虚拟机将使用CAS操作尝试将锁对象的MarkWord更新为指向LockRecord的指针，并将线程栈帧中的LockRecord里的owner指针指向Object的MarkWord。
4)如果这个更新动作成功了，那么这个线程就拥有了该对象的锁，并且对象MarkWord的锁标志位设置为“00”，即表示此对象处于轻量级锁定状态，这时候线程堆栈与对象头的状态如图所示。
5)如果这个更新操作失败了，虚拟机首先会检查对象的MarkWord是否指向当前线程的栈帧，如果是就说明当前线程已经拥有了这个对象的锁，那就可以直接进入同步块继续执行。否则说明多个线程竞争锁，轻量级锁就要膨胀为重量级锁，锁标志的状态值变为“10”，MarkWord中存储的就是指向重量级锁（互斥量）的指针，后面等待锁的线程也要进入阻塞状态。

偏向锁
偏向锁是JDK6中引入的一项锁优化，它的目的是消除数据在无竞争情况下的同步原语，进一步提高程序的运行性能。
偏向锁会偏向于第一个获得它的线程，如果在接下来的执行过程中，该锁没有被其他的线程获取，则持有偏向锁的线程将永远不需要同步。大多数情况下，锁不仅不存在多线程竞争，而且总是由同一线程多次获得，为了让线程获得锁的代价更低而引入了偏向锁。
当锁对象第一次被线程获取的时候，线程使用CAS操作把这个线程的ID记录在对象MarkWord之中，同时置偏向标志位1。以后该线程在进入和退出同步块时不需要进行CAS操作来加锁和解锁，只需要简单地测试一下对象头的MarkWord里是否存储着指向当前线程的ID。如果测试成功，表示线程已经获得了锁。
当有另外一个线程去尝试获取这个锁时，偏向模式就宣告结束。根据锁对象目前是否处于被锁定的状态，撤销偏向后恢复到未锁定或轻量级锁定状态。

偏向所锁，轻量级锁及重量级锁
偏向所锁，轻量级锁都是乐观锁，重量级锁是悲观锁。
一个对象刚开始实例化的时候，没有任何线程来访问它的时候。它是可偏向的，意味着，它现在认为只可能有一个线程来访问它，所以当第一个
线程来访问它的时候，它会偏向这个线程，此时，对象持有偏向锁。偏向第一个线程，这个线程在修改对象头成为偏向锁的时候使用CAS操作，并将对象头中的ThreadID改成自己的ID，之后再次访问这个对象时，只需要对比ID，不需要再使用CAS在进行操作。
一旦有第二个线程访问这个对象，因为偏向锁不会主动释放，所以第二个线程可以看到对象时偏向状态，这时表明在这个对象上已经存在竞争了，检查原来持有该对象锁的线程是否依然存活，如果挂了，则可以将对象变为无锁状态，然后重新偏向新的线程，如果原来的线程依然存活，则马上执行那个线程的操作栈，检查该对象的使用情况，如果仍然需要持有偏向锁，则偏向锁升级为轻量级锁，（偏向锁就是这个时候升级为轻量级锁的）。如果不存在使用了，则可以将对象回复成无锁状态，然后重新偏向。
轻量级锁认为竞争存在，但是竞争的程度很轻，一般两个线程对于同一个锁的操作都会错开，或者说稍微等待一下（自旋），另一个线程就会释放锁。但是当自旋超过一定的次数，或者一个线程在持有锁，一个在自旋，又有第三个来访时，轻量级锁膨胀为重量级锁，重量级锁使除了拥有锁的线程以外的线程都阻塞，防止CPU空转。

锁消除 在即时编译器时，如果发现不可能被共享的对象，则可以消除这些对象的锁操作

	public static void main(String args[]) throws InterruptedException {
		long start = System.currentTimeMillis();
		for (int i = 0; i < CIRCLE; i++) {
			craeteStringBuffer("JVM", "Diagnosis");
		}
		long bufferCost = System.currentTimeMillis() - start;
		System.out.println("craeteStringBuffer: " + bufferCost + " ms");
	}

	public static String craeteStringBuffer(String s1, String s2) {
		StringBuffer sb = new StringBuffer();
		sb.append(s1);// 同步操作
		sb.append(s2);
		return sb.toString();
	}

CIRCLE= 2000000

//开启锁消除
-server -XX:+DoEscapeAnalysis -XX:+EliminateLocks

//不开启锁消除
-server -XX:+DoEscapeAnalysis -XX:-EliminateLocks

虚拟机内的锁优化
?偏向锁
?轻量级锁
?自旋锁

对象头Mark
?Mark Word，对象头的标记，32位
?描述对象的hash、锁信息，垃圾回收标记，年龄
C指向锁记录的指针
C指向monitor的指针
CGC标记
C偏向锁线程ID

偏向锁
?大部分情况是没有竞争的，所以可以通过偏向来提高性能
?所谓的偏向，就是偏心，即锁会偏向于当前已经占有锁的线程
?将对象头Mark的标记设置为偏向，并将线程ID写入对象头Mark
?只要没有竞争，获得偏向锁的线程，在将来进入同步块，不需要做同步
?当其他线程请求相同的锁时，偏向模式结束
?-XX:+UseBiasedLocking
    C默认启用
?在竞争激烈的场合，偏向锁会增加系统负担

	public static List<Integer> numberList = new Vector<Integer>();

	public static void main(String[] args) throws InterruptedException {
		long begin = System.currentTimeMillis();
		int count = 0;
		int startnum = 0;
		while (count < 10000000) {
			numberList.add(startnum);
			startnum += 2;
			count++;
		}
		long end = System.currentTimeMillis();
		System.out.println(end - begin);
	}

//启用偏向锁（JVM启动马上启用偏向锁模式：-XX:BiasedLockingStartupDelay=0）
-XX:+UseBiasedLocking -XX:BiasedLockingStartupDelay=0
//禁用偏向锁
-XX:-UseBiasedLocking

本例中，使用偏向锁，可以获得5%以上的性能提升

轻量级锁
?BasicObjectLock
    C嵌入在线程栈中的对象
?普通的锁处理性能不够理想，轻量级锁是一种快速的锁定方法。
?如果对象没有被锁定
    C将对象头的Mark指针保存到锁对象中
    C将对象头设置为指向锁的指针（在线程栈空间中）
?如果轻量级锁失败，表示存在竞争，升级为重量级锁（常规锁）
?在没有锁竞争的前提下，减少传统锁使用OS互斥量产生的性能损耗
?在竞争激烈时，轻量级锁会多做很多额外操作，导致性能下降

自旋锁
?当竞争存在时，如果线程可以很快获得锁，那么可以不在OS层挂起线程，让线程做几个空操作（自旋）
?JDK1.6中-XX:+UseSpinning开启
?JDK1.7中，去掉此参数，改为内置实现
?如果同步块很长，自旋失败，会降低系统性能
?如果同步块很短，自旋成功，节省线程挂起切换时间，提升系统性能

偏向锁，轻量级锁，自旋锁总结
不是Java语言层面的锁优化方法
内置于JVM中的获取锁的优化方法和获取锁的步骤
C偏向锁可用会先尝试偏向锁
C轻量级锁可用会先尝试轻量级锁
C以上都失败，尝试自旋锁
C再失败，尝试普通锁，使用OS互斥量在操作系统层挂起
#################################################锁的优化#################################################

JDK8对并发的新支持
- LongAdder
- CompletableFuture
- StampedLock


#############################################JVM诊断之查看JVM参数及值的命令行工具#############################################
系统性能监控- linux
uptime
系统时间
运行时间
    例子中为7分钟
连接数
    每一个终端算一个连接
1,5,15分钟内的系统平均负载
    运行队列中的平均进程数

top
同uptime
CPU内存
每个进程占CPU的情况

vmstat
可以统计系统的CPU，内存，swap，io等情况

pidstat
细致观察进程
需要安装
    sudo apt-get install sysstat
监控CPU
监控IO
监控内存

Java自带的工具
jps
列出java进程，类似于ps命令
参数-q可以指定jps只输出进程ID ，不输出类的短名称
参数-m可以用于输出传递给Java进程（主函数）的参数
参数-l可以用于输出主函数的完整路径
参数-v可以显示传递给JVM的参数


问题描述
为了分析和定位一个Java线上系统问题，我们需要查看JVM启动时的一些参数设置，例如：垃圾回收算法、堆大小等等。这些参数可能在启动脚本中明确指明，也可能采用默认值。在系统运行过程中其他人也许动态调整了系统参数。 如何实时查看正在运行的JVM的参数呢？

解决方案
可以采用jcmd来查看正在运行的JVM的参数。jcmd从JDK 7开始引入的一个JVM诊断命令行工具，可以向运行中的JVM发送诊断命令。
查看JVM进程的PID
$ jcmd -l
27940 sun.tools.jcmd.JCmd -l
24684 org.codehaus.plexus.classworlds.launcher.Launcher -Prun 
23839 com.intellij.idea.Main
23951 org.jetbrains.idea.maven.server.RemoteMavenServer

查看进程24684的参数
jcmd 24684 VM.flags
24684:
-XX:InitialHeapSize=98566144 -XX:MaxHeapSize=1547698176 -XX:MaxNewSize=515899392 -XX:MinHeapDeltaBytes=524288 -XX:NewSize=1572864 -XX:OldSize=96993280 -XX:+UseCompressedClassPointers -XX:+UseCompressedOops -XX:+UseParallelGC 
堆大小设置，垃圾回收算法等一目了然。

1.-XX:+PrintFlagsInitial参数(java -XX:+PrintFlagsInitial)
显示所有可设置参数及默认值，可结合-XX:+PrintFlagsInitial与-XX:+PrintFlagsFinal对比设置前、设置后的差异，方便知道对那些参数做了调整。

2.-XX:+PrintFlagsFinal参数(java -XX:+PrintFlagsFinal)
可以获取到所有可设置参数及值(手动设置之后的值)，这个参数只能使用在Jdk6 update 21以上版本(包括该版本)。-XX:+PrintFlagsFinal参数的使用 与上面-XX:+PrintFlagsInitial 参数使用相同  Java -XX:+PrintFlagsFinal

3.使用 jinfo 命令 查看或设置某个参数的值, 
jinfo命令格式：
jinfo [option] <pid>
pid虚拟机进程id  可以通过  jps命令查看
例子：查询MaxPermSize 参数的值
jinfo -flag MaxPermSize <pid>
或直接使用 jinfo -flags pid 查看vm的所有设置参数
jinfo -flag [+/-][flagName] [pid] #启用/禁止某个参数
jinfo -flag [flagName=value] [pid] #设置某个参数

4. -XX:+PrintCommandLineFlags参数(java -XX:+PrintCommandLineFlags)
显示出JVM初始化完毕后所有跟最初的默认值不同的参数及它们的值。

eclipse启动时，由于安装了两种版本的jdk，Eclipse启动失败解决方法： ， 
需要在eclipse.ini中参数：-startup plugins/org.eclipse.equinox.launcher_1.3.0.v20140415-2008.jar的后面指定jdk的路径。
-vm 
E:\Program Files\Java\jdk1.8.0_51\bin\javaw.exe**

例：
-startup
plugins/org.eclipse.equinox.launcher_1.3.0.v20140415-2008.jar
-vm
E:\Program Files\Java\jdk1.8.0_51\bin\javaw.exe

eclipse堆栈分析插件
Memory Analyzer

jstack
打印线程dump
-l 打印锁信息
-m 打印java和native的帧信息
-F 强制dump，当jstack没有响应时使用

jmap
打印出某个java进程（使用pid）内存内的，所有‘对象’的情况（如：产生那些对象，及其数量）。
可以输出所有内存中对象的工具，甚至可以将VM 中的heap，以二进制输出成文本。使用方法 jmap -histo pid。如果连用SHELL jmap -histo pid>a.log可以将其保存到文本中去，在一段时间后，使用文本对比工具，可以对比出GC回收了哪些对象。jmap -dump:format=b,file=outfile 3024可以将3024进程的内存heap输出出来到outfile文件里，再配合MAT（内存分析工具(Memory Analysis Tool）或与jhat (Java Heap Analysis Tool)一起使用，能够以图像的形式直观的展示当前内存是否有问题。

例：
jmap -F -dump:format=b,file=tomcat.bin 9142

jhat

hat是一个Java堆复制浏览器。这个工具分析Java堆复制文件（例如，由上面的"jmap-dump"所产生的）。Jhat启动一个允许堆中的对象在web浏览器中进行分析的web服务器。这个工具并不是想用于应用系统中而是用于"离线"分析。"jhat工具是平台独立的"，其意思是，它可以被用来观察在任何平台上所产生的堆复制。例如，我们有可能在Linux系统上使用jhat来观察一个 在Solaris OS上所产生的堆复制。
把本机的java内存映像导出到heap.dmp中,其中PID为java进程的ID号。
jmap -dump:live,format=b,file=heap.dmp PID 导出后的映像文件可以用jhat来进行分析，-J是向java虚拟机传一个参数，如-mx768m是指定虚拟机可用最大的内存为768M。如果映像文件很大，你要指定一个很大的值，否则在分析过程中就会有OutOfMemeryError的错误。
jhat -J-mx768m -port <端口号:默认为7000> heap.dmp
执行后等待console 中输入start HTTP server on port 7000 即可使用浏览器访问 IP：7000

例：
jhat tomcat.bin

#############################################JVM诊断之查看JVM参数及值的命令行工具#############################################

#################################################Java栈 C 栈上分配#################################################
Java栈
线程私有
栈由一系列帧组成（因此Java栈也叫做帧栈）
帧保存一个方法的局部变量、操作数栈、常量池指针
每一次方法调用创建一个帧，并压栈

public class OnStackTest {
    public static void alloc(){
        byte[] b=new byte[2];
        b[0]=1;
    }
    public static void main(String[] args) {
        long b=System.currentTimeMillis();
        for(int i=0;i<100000000;i++){
            alloc();
        }
        long e=System.currentTimeMillis();
        System.out.println(e-b);
    }
}

-server -Xmx10m -Xms10m
-XX:+DoEscapeAnalysis -XX:+PrintGC

输出结果 5

-server -Xmx10m -Xms10m  
-XX:-DoEscapeAnalysis -XX:+PrintGC

[GC 3550K->478K(10240K), 0.0000977 secs]
[GC 3550K->478K(10240K), 0.0001361 secs]
[GC 3550K->478K(10240K), 0.0000963 secs]
564

Java栈 C 栈上分配
小对象（一般几十个bytes），在没有逃逸的情况下，可以直接分配在栈上
直接分配在栈上，可以自动回收，减轻GC压力
大对象或者逃逸对象无法栈上分配

解释运行
    解释执行以解释方式运行字节码
    解释执行的意思是：读一句执行一句
编译运行（JIT）
    将字节码编译成机器码
    直接执行机器码
    运行时编译
    编译后性能有数量级的提升
	编译的时间开销

解释器的执行，抽象的看是这样的：
输入的代码 -> [ 解释器 解释执行 ] -> 执行结果
而要JIT编译然后再执行的话，抽象的看则是：
输入的代码 -> [ 编译器 编译 ] -> 编译后的代码 -> [ 执行 ] -> 执行结果
说JIT比解释快，其实说的是“执行编译后的代码”比“解释器解释执行”要快，并不是说“编译”这个动作比“解释”这个动作快。
JIT编译再怎么快，至少也比解释执行一次略慢一些，而要得到最后的执行结果还得再经过一个“执行编译后的代码”的过程。
所以，对“只执行一次”的代码而言，解释执行其实总是比JIT编译执行要快。
怎么算是“只执行一次的代码”呢？粗略说，下面两个条件同时满足时就是严格的“只执行一次”
1、只被调用一次，例如类的构造器（class initializer，<clinit>()）
2、没有循环
对只执行一次的代码做JIT编译再执行，可以说是得不偿失。
对只执行少量次数的代码，JIT编译带来的执行速度的提升也未必能抵消掉最初编译带来的开销。
只有对频繁执行的代码，JIT编译才能保证有正面的收益。
#################################################Java栈 C 栈上分配#################################################

#################################################常用JVM配置参数#################################################
Trace跟踪参数
-verbose:gc
-XX:+printGC
可以打印GC的简要信息
-XX:+PrintGCDetails(只有在程序结束后会把堆的使用状况打印出来)
打印GC详细信息
-XX:+PrintGCTimeStamps
打印GC发生的时间戳

默认打印的GC信息是输出在控制台，但是可以通过如下的配置指定GC log的位置
-Xloggc:log/gc.log
指定GC log的位置，以文件输出
帮助开发人员分析问题

-XX:+PrintHeapAtGC(每次发生GC都会打印出堆目前的使用状况)
每次一次GC后，都打印堆信息

-XX:+TraceClassLoading
监控类的加载

-XX:+PrintClassHistogram
按下Ctrl+Break后，打印类的信息：

堆的分配参数
-Xmx CXms
指定最大堆和最小堆
-Xmx20m -Xms5m  运行代码：
System.out.print("Xmx=");
System.out.println(Runtime.getRuntime().maxMemory()/1024.0/1024+"M");
System.out.print("free mem=");
System.out.println(Runtime.getRuntime().freeMemory()/1024.0/1024+"M");
System.out.print("total mem=");
System.out.println(Runtime.getRuntime().totalMemory()/1024.0/1024+"M");

-Xmn
    设置新生代大小
-XX:NewRatio
    新生代（eden+2*s）和老年代（不包含永久区）的比值
    4 表示 新生代:老年代=1:4，即年轻代占堆的1/5
-XX:SurvivorRatio （即from，to）
    设置两个Survivor区和eden的比
    8表示 两个Survivor :eden=2:8，即一个Survivor占年轻代的1/10

例：
public static void main(String[] args) {
   byte[] b=null;
   for(int i=0;i<10;i++)
       b=new byte[1*1024*1024];
}

分别以不同的参数运行，将输出不同的GC信息：
-Xmx20m -Xms20m -Xmn1m -XX:+PrintGCDetails 
没有触发GC
全部分配在老年代

-Xmx20m -Xms20m -Xmn15m -XX:+PrintGCDetails
没有触发GC
全部分配在eden
老年代没有使用

-Xmx20m -Xms20m -Xmn7m -XX:+PrintGCDetails 
1.进行了2次新生代GC
2.s0 s1 太小需要老年代担保
因为如果是新生代的大小是7m的话from和to的空间比较小（小于1M）所以无法进行新生代的GC回收，因此部分对象会放在老年代
eden space 5760K
from space 704K
to   space 704K

-Xmx20m -Xms20m -Xmn7m -XX:SurvivorRatio=2 -XX:+PrintGCDetails
1.进行了3次新生代GC
2.s0 s1 增大

-Xmx20m -Xms20m -XX:NewRatio=1 -XX:SurvivorRatio=2 -XX:+PrintGCDetails
比例分配，新生代 老年代对半开
对象全部留在新生代

-Xmx20m -Xms20m -XX:NewRatio=1 -XX:SurvivorRatio=3 -XX:+PrintGCDetails
减少了s0 s1 GC数量变少，老年代未使用 空间使用率更高

-XX:+HeapDumpOnOutOfMemoryError
    OOM时导出堆到文件
-XX:+HeapDumpPath
    导出OOM的路径
例：
-Xmx20m -Xms5m -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=d:/a.dump

-XX:OnOutOfMemoryError
在OOM时，执行一个脚本
"-XX:OnOutOfMemoryError=D:/tools/jdk1.7_40/bin/printstack.bat %p“ 当程序OOM时，在D:/a.txt中将会生成线程的dump
可以在OOM时，发送邮件，甚至是重启程序
printstack.bat里面的内容
D:/tools/jdk1.7_40/bin/jstack -F %1 > D:/a.txt

根据实际事情调整新生代和幸存代的大小
官方推荐新生代占堆的3/8
幸存代占新生代的1/10
在OOM时，记得Dump出堆，确保可以排查现场问题

永久区分配参数
-XX:PermSize  -XX:MaxPermSize
    设置永久区的初始空间和最大空间
    他们表示，一个系统可以容纳多少个类型

栈大小分配
-Xss
    通常只有几百K
    决定了函数调用的深度
    每个线程都有独立的栈空间
    局部变量、参数 分配在栈上

例：
public class TestStackDeep {
	private static int count=0;
	public static void recursion(long a,long b,long c){
		long e=1,f=2,g=3,h=4,i=5,k=6,q=7,x=8,y=9,z=10;
		count++;
		recursion(a,b,c);
	}
	public static void main(String args[]){
		try{
			recursion(0L,0L,0L);
		}catch(Throwable e){
			System.out.println("deep of calling = "+count);
			e.printStackTrace();
		}
	}
}

递归调用
-Xss128K
deep of calling = 701
java.lang.StackOverflowError
-Xss256K
deep of calling = 1817
java.lang.StackOverflowError

#################################################常用JVM配置参数#################################################

#################################################Garbage Collection 垃圾收集#################################################
GC算法
引用计数法（没有被Java采用）
标记清除
标记压缩
复制算法

引用计数法
引用计数器的实现很简单，对于一个对象A，只要有任何一个对象引用了A，则A的引用计数器就加1，当引用失效时，引用计数器就减1。只要对象A的引用计数器的值为0，则对象A就不可能再被使用。
引用计数法的问题
引用和去引用伴随加法和减法，影响性能
很难处理循环引用

标记-清除
标记-清除算法是现代垃圾回收算法的思想基础。标记-清除算法将垃圾回收分为两个阶段：标记阶段和清除阶段。一种可行的实现是，在标记阶段，首先通过根节点，标记所有从根节点开始的可达对象。因此，未被标记的对象就是未被引用的垃圾对象。然后，在清除阶段，清除所有未被标记的对象。

标记-压缩
标记-压缩算法适合用于存活对象较多的场合，如老年代。它在标记-清除算法的基础上做了一些优化。和标记-清除算法一样，标记-压缩算法也首先需要从根节点开始，对所有可达对象做一次标记。但之后，它并不简单的清理未标记的对象，而是将所有的存活对象压缩到内存的一端。之后，清理边界外所有的空间。

复制算法
与标记-清除算法相比，复制算法是一种相对高效的回收方法
不适用于存活对象较多的场合 如老年代
将原有的内存空间分为两块，每次只使用其中一块，在垃圾回收时，将正在使用的内存中的存活对象复制到未使用的内存块中，之后，清除正在使用的内存块中的所有对象，交换两个内存的角色，完成垃圾回收
复制算法的最大问题是：空间浪费 整合标记清理思想

分代思想
依据对象的存活周期进行分类，短命对象归为新生代，长命对象归为老年代。
根据不同代的特点，选取合适的收集算法
少量对象存活，适合复制算法
大量对象存活，适合标记清理或者标记压缩

可触及性

可触及的
    从根节点可以触及到这个对象
可复活的
    一旦所有引用被释放，就是可复活状态
    因为在finalize()中可能复活该对象
不可触及的
    在finalize()后，可能会进入不可触及状态
    不可触及的对象不可能复活
    可以回收

垃圾回收器要回收对象的时候，首先要调用这个类的finalize方法(你可以 写程序验证这个结论)，一般的纯Java编写的Class不需要重新覆盖这个方法，因为Object已经实现了一个默认的，除非我们要实现特殊的功能(这 里面涉及到很多东西，比如对象空间树等内容)。
不过用Java以外的代码编写的Class(比如JNI，C++的new方法分配的内存)，垃圾回收器并不能对这些部分进行正确的回收，这时就需要我们覆盖默认的方法来实现对这部分内存的正确释放和回收(比如C++需要delete)。
总之，finalize相当于析构函数，他是垃圾回收器回收一个对象的时候第一个要调用的方法。不过由于Java的垃圾回收机制能自动为我们做这些事情，所以我们在一般情况下是不需要自己来手工释放的。

垃圾收集器在进行垃圾收集的时候会自动呼叫对象的finalize方法，用来进行一些用户自定义的非内存清理工作，因为垃圾收集器不会处理内存以外的东西。所以，有的时候用户需要定义一些清理的方法，比如说处理文件和端口之类的非内存资源。

finalize()在什么时候被调用?
有三种情况
1.所有对象被Garbage Collection时自动调用,比如运行System.gc()的时候.
2.程序退出时为每个对象调用一次finalize方法。
3.显式的调用finalize方法

public class CanReliveObj {

	public static CanReliveObj obj;

	@Override
	protected void finalize() throws Throwable {
		super.finalize();
		System.out.println("CanReliveObj finalize called");
		obj = this;
	}

	@Override
	public String toString() {
		return "I am CanReliveObj";
	}

	public static void main(String[] args) throws InterruptedException {
		obj = new CanReliveObj();
		System.out.println("第一次gc");
		obj = null; // 可复活
		System.gc();
		Thread.sleep(1000);
		if (obj == null) {
			System.out.println("obj 是 null");
		} else {
			System.out.println("obj 可用");
		}
		System.out.println("第二次gc");
		obj = null; // 不可复活
		System.gc();
		Thread.sleep(1000);
		if (obj == null) {
			System.out.println("obj 是 null");
		} else {
			System.out.println("obj 可用");
		}
	}
}
注意
    1) finalize()只会被调用一次
    2) 如果在第一次发生GC的时候在finalize方法中将对象复活，然后没有将调用该对象的引用赋值为null
即上面的obj = null没有被执行，那么有可能这个对象永远没有办法被回收。
	
经验：避免使用finalize()，操作不慎可能导致错误。
优先级低，何时被调用， 不确定
    何时发生GC不确定
可以使用try-catch-finally来替代它

根
    栈中引用的对象
    方法区中静态成员或者常量引用的对象（全局对象）
    JNI方法栈中引用对象

Stop-The-World
    Java中一种全局暂停的现象
    全局停顿，所有Java代码停止，native代码可以执行，但不能和JVM交互
    多半由于GC引起
        Dump线程
        死锁检查
        堆Dump
		
GC时为什么会有全局停顿？
    类比在聚会时打扫房间，聚会时很乱，又有新的垃圾产生，房间永远打扫不干净，只有让大家停止活动了，才能将房间打扫干净。
危害
    长时间服务停止，没有响应
    遇到HA系统，可能引起主备切换，严重危害生产环境。

GC参数 - 串行收集器
最古老，最稳定
效率高
可能会产生较长的停顿
-XX:+UseSerialGC
    新生代、老年代使用串行回收
    新生代复制算法
    老年代标记-压缩
新生代：（GC）
0.844: [GC 0.844: [DefNew: 17472K->2176K(19648K), 0.0188339 secs] 17472K->2375K(63360K), 0.0189186 secs] [Times: user=0.01 sys=0.00, real=0.02 secs]
老年代：（Full GC）
8.259: [Full GC 8.259: [Tenured: 43711K->40302K(43712K), 0.2960477 secs] 63350K->40302K(63360K), [Perm : 17836K->17836K(32768K)], 0.2961554 secs] [Times: user=0.28 sys=0.02, real=0.30 secs]

GC参数 - 并行收集器
ParNew
-XX:+UseParNewGC
    新生代并行
    老年代串行
Serial收集器新生代的并行版本
复制算法
多线程，需要多核支持
-XX:ParallelGCThreads 限制线程数量
新生代：并行（ParNew）
0.834: [GC 0.834: [ParNew: 13184K->1600K(14784K), 0.0092203 secs] 13184K->1921K(63936K), 0.0093401 secs] [Times: user=0.00 sys=0.00, real=0.00 secs]

GC参数 -并行收集器
Parallel收集器
类似ParNew
新生代复制算法
老年代 标记-压缩
更加关注吞吐量
-XX:+UseParallelGC
    使用Parallel收集器+ 老年代串行
-XX:+UseParallelOldGC
    使用Parallel收集器+ 并行老年代
1.500: [Full GC [PSYoungGen: 2682K->0K(19136K)] [ParOldGen: 28035K->30437K(43712K)] 30717K->30437K(62848K) [PSPermGen: 10943K->10928K(32768K)], 0.2902791 secs] [Times: user=1.44 sys=0.03, real=0.30 secs]

GC参数
-XX:MaxGCPauseMills
    最大停顿时间，单位毫秒
    GC尽力保证回收时间不超过设定值
-XX:GCTimeRatio
    0-100的取值范围
    垃圾收集时间占总时间的比
    默认99，即最大允许1%时间做GC
这两个参数是矛盾的。因为停顿时间和吞吐量不可能同时调优

GC参数 C CMS收集器
CMS收集器（CMS收集器使用的是标记清除算法）
    Concurrent Mark Sweep 并发标记清除
    标记-清除算法
    与标记-压缩相比
    并发阶段会降低吞吐量
    老年代收集器（新生代使用ParNew）
    -XX:+UseConcMarkSweepGC
CMS运行过程比较复杂，着重实现了标记的过程，可分为
    初始标记
        根可以直接关联到的对象
        速度快
    并发标记（和用户线程一起）
        主要标记过程，标记全部对象
    重新标记
        由于并发标记时，用户线程依然运行，因此在正式清理前，再做修正
    并发清除（和用户线程一起）
        基于标记结果，直接清理对象
特点
    尽可能降低停顿
    会影响系统整体吞吐量和性能
        比如，在用户线程运行过程中，分一半CPU去做GC，系统性能在GC阶段，反应速度就下降一半
    清理不彻底
        因为在清理阶段，用户线程还在运行，会产生新的垃圾，无法清理
    因为和用户线程一起运行，不能在空间快满时再清理
        -XX:CMSInitiatingOccupancyFraction设置触发GC的阈值
        如果不幸内存预留空间不够，就会引起concurrent mode failure

有关碎片
    标记-清除（有可能产生碎片）和标记-压缩
由于CMS收集器使用的是标记清除算法所以会产生碎片，因此在用CMS收集器进行完垃圾回收后必须进行碎片整理
-XX:+ UseCMSCompactAtFullCollection Full GC后，进行一次整理
    整理过程是独占的，会引起停顿时间变长
-XX:+CMSFullGCsBeforeCompaction 
    设置进行几次Full GC后，进行一次碎片整理
-XX:ParallelCMSThreads
    设定CMS的线程数量

GC参数整理
-XX:+UseSerialGC：在新生代和老年代使用串行收集器
-XX:SurvivorRatio：设置eden区大小和survivior区大小的比例
-XX:NewRatio:新生代和老年代的比
-XX:+UseParNewGC：在新生代使用并行收集器
-XX:+UseParallelGC ：新生代使用并行回收收集器
-XX:+UseParallelOldGC：老年代使用并行回收收集器
-XX:ParallelGCThreads：设置用于垃圾回收的线程数
-XX:+UseConcMarkSweepGC：新生代使用并行收集器，老年代使用CMS+串行收集器
-XX:ParallelCMSThreads：设定CMS的线程数量
-XX:CMSInitiatingOccupancyFraction：设置CMS收集器在老年代空间被使用多少后触发
-XX:+UseCMSCompactAtFullCollection：设置CMS收集器在完成垃圾收集后是否要进行一次内存碎片的整理
-XX:CMSFullGCsBeforeCompaction：设定进行多少次CMS垃圾回收后，进行一次内存压缩
-XX:+CMSClassUnloadingEnabled：允许对类元数据进行回收
-XX:CMSInitiatingPermOccupancyFraction：当永久区占用率达到这一百分比时，启动CMS回收
-XX:UseCMSInitiatingOccupancyOnly：表示只在到达阀值的时候，才进行CMS回收

#################################################Garbage Collection 垃圾收集#################################################

#################################################ClassLoader类加载#################################################
http://blog.chinaunix.net/uid-21227800-id-65879.html
ClassLoader
当JVM（Java虚拟机）启动时，会形成由三个类加载器组成的初始类加载器层次结构：
bootstrap classloader
|
extension classloader
|
system classloader

bootstrap classloader
－引导（也称为原始）类加载器，它负责加载Java的核心类。在Sun的JVM中，在执行java的命令中使用-Xbootclasspath选项或使用 -D选项指定sun.boot.class.path系统属性值可以指定附加的类。这个加载器的是非常特殊的，它实际上不是 java.lang.ClassLoader的子类，而是由JVM自身实现的。大家可以通过执行以下代码来获得bootstrap classloader加载了那些核心类库：
//URL[] urls=sun.misc.Launcher.getBootstrapClassPath().getURLs();
//for (int i = 0; i < urls.length; i++) {
//  System.out.println(urls.toExternalForm());
//}
System.out.println("bootstrap classloader －引导（也称为原始）类加载器:");
String[] classpaths = System.getProperty("sun.boot.class.path").split(";");
for (String path : classpaths) {
System.out.println(path);
}

extension classloader －扩展类加载器，它负责加载JRE的扩展目录（JAVA_HOME/jre/lib/ext或者由java.ext.dirs系统属性指定的）中JAR的类包。这为引入除Java核心类以外的新功能提供了一个标准机制。因为默认的扩展目录对所有从同一个JRE中启动的JVM都是通用的，所以放入这个目录的 JAR类包对所有的JVM和system classloader都是可见的。在这个实例上调用方法getParent()总是返回空值null，因为引导加载器bootstrap classloader不是一个真正的ClassLoader实例。所以当大家执行以下代码时：
System.out.println("extension classloader －扩展类加载器:");
classpaths = System.getProperty("java.ext.dirs").split(";");
for (String path : classpaths) {
System.out.println(path);
}
ClassLoader extensionClassloader=ClassLoader.getSystemClassLoader().getParent();
System.out.println("the parent of extension classloader : "+extensionClassloader.getParent());
extension classloader是system classloader的parent，而bootstrap classloader是extension classloader的parent，但它不是一个实际的classloader，所以为null。

system classloader
－系统（也称为应用）类加载器，它负责在JVM被启动时，加载来自在命令java中的-classpath或者java.class.path系统属性或者 CLASSPATH操作系统属性所指定的JAR类包和类路径。总能通过静态方法ClassLoader.getSystemClassLoader()找到该类加载器。如果没有特别指定，则用户自定义的任何类加载器都将该类加载器作为它的父加载器。执行以下代码即可获得：
System.out.println("system classloader －系统（也称为应用）类加载器:");
classpaths = System.getProperty("java.class.path").split(";");
for (String path : classpaths) {
System.out.println(path);
}
输出结果则为用户在系统属性里面设置的CLASSPATH。
classloader 加载类用的是全盘负责委托机制。所谓全盘负责，即是当一个classloader加载一个Class的时候，这个Class所依赖的和引用的所有 Class也由这个classloader负责载入，除非是显式的使用另外一个classloader载入；委托机制则是先让parent（父）类加载器 (而不是super，它与parent classloader类不是继承关系)寻找，只有在parent找不到的时候才从自己的类路径中去寻找。此外类加载还采用了cache机制，也就是如果 cache中保存了这个Class就直接返回它，如果没有才从文件中读取和转换成Class，并存入cache，这就是为什么我们修改了Class但是必须重新启动JVM才能生效的原因。

下面就让我们来看看JVM是如何来为我们来建立类加载器的结构的：
sun.misc.Launcher，顾名思义，当你执行java命令的时候，JVM会先使用bootstrap classloader载入并初始化一个Launcher，执行下来代码：
   System.out.println("the Launcher's classloader is "+sun.misc.Launcher.getLauncher().getClass().getClassLoader());
结果为：
   the Launcher's classloader is null (因为是用bootstrap classloader加载,所以class loader为null)
Launcher 会根据系统和命令设定初始化好class loader结构，JVM就用它来获得extension classloader和system classloader,并载入所有的需要载入的Class，最后执行java命令指定的带有静态的main方法的Class。extension classloader实际上是sun.misc.Launcher$ExtClassLoader类的一个实例，system classloader实际上是sun.misc.Launcher$AppClassLoader类的一个实例。并且都是 java.net.URLClassLoader的子类。

extension classloader是使用系统属性“java.ext.dirs”设置类搜索路径的，并且没有parent。system classloader是使用系统属性“java.class.path”设置类搜索路径的，并且有一个parent classloader。Launcher初始化extension classloader，system classloader，并将system classloader设置成为context classloader，但是仅仅返回system classloader给JVM。
这里怎么又出来一个context classloader呢？它有什么用呢？我们在建立一个线程Thread的时候，可以为这个线程通过setContextClassLoader方法来指定一个合适的classloader作为这个线程的context classloader，当此线程运行的时候，我们可以通过getContextClassLoader方法来获得此context classloader，就可以用它来载入我们所需要的Class。默认的是system classloader。利用这个特性，我们可以“打破”classloader委托机制了，父classloader可以获得当前线程的context classloader，而这个context classloader可以是它的子classloader或者其他的classloader，那么父classloader就可以从其获得所需的 Class，这就打破了只能向父classloader请求的限制了。这个机制可以满足当我们的classpath是在运行时才确定,并由定制的 classloader加载的时候,由system classloader(即在jvm classpath中)加载的class可以通过context classloader获得定制的classloader并加载入特定的class(通常是抽象类和接口,定制的classloader中是其实现),例如web应用中的servlet就是用这种机制加载的.

好，现在我们能够动态的载入Class了，这样我们就可以利用newInstance方法来获得一个Object。但我们如何将此Object造型呢？可以将此Object造型成它本身的Class吗？
首先让我们来分析一下java源文件的编译，运行吧！javac命令是调用“JAVA_HOME/lib/tools.jar”中的“com.sun.tools.javac.Main”的compile方法来编译：
public static int compile(String as[]);
public static int compile(String as[], PrintWriter printwriter);

其中 Main是由JVM使用Launcher初始化的system classloader载入的，根据全盘负责原则，编译器在解析这个java源文件时所发现的它所依赖和引用的所有Class也将由system classloader载入，如果system classloader不能载入某个Class时，编译器将抛出一个“cannot resolve symbol”错误。

所以首先编译就通不过，也就是编译器无法编译一个引用了不在CLASSPATH中的未知Class的java源文件，而由于拼写错误或者没有把所需类库放到CLASSPATH中，大家一定经常看到这个“cannot resolve symbol”这个编译错误吧！

其次，就是我们把这个Class放到编译路径中，成功的进行了编译，然后在运行的时候不把它放入到CLASSPATH中而利用我们自己的 classloader来动态载入这个Class，这时候也会出现“java.lang.NoClassDefFoundError”的违例，为什么呢？

我们再来分析一下，首先调用这个造型语句的可执行的Class一定是由JVM使用Launcher初始化的system classloader载入的，根据全盘负责原则，当我们进行造型的时候，JVM也会使用system classloader来尝试载入这个Class来对实例进行造型，自然在system classloader寻找不到这个Class时就会抛出“java.lang.NoClassDefFoundError”的违例。

OK，现在让我们来总结一下，java文件的编译和Class的载入执行，都是使用Launcher初始化的system classloader作为类载入器的，我们无法动态的改变system classloader，更无法让JVM使用我们自己的classloader来替换system classloader，根据全盘负责原则，就限制了编译和运行时，我们无法直接显式的使用一个system classloader寻找不到的Class，即我们只能使用Java核心类库，扩展类库和CLASSPATH中的类库中的Class。

还不死心！再尝试一下这种情况，我们把这个Class也放入到CLASSPATH中，让system classloader能够识别和载入。然后我们通过自己的classloader来从指定的class文件中载入这个Class（不能够委托 parent载入，因为这样会被system classloader从CLASSPATH中将其载入），然后实例化一个Object，并造型成这个Class，这样JVM也识别这个Class（因为 system classloader能够定位和载入这个Class从CLASSPATH中），载入的也不是CLASSPATH中的这个Class，而是从 CLASSPATH外动态载入的，这样总行了吧！十分不幸的是，这时会出现“java.lang.ClassCastException”违例。

为什么呢？我们也来分析一下，不错，我们虽然从CLASSPATH外使用我们自己的classloader动态载入了这个Class，但将它的实例造型的时候是JVM会使用system classloader来再次载入这个Class，并尝试将使用我们的自己的classloader载入的Class的一个实例造型为system classloader载入的这个Class（另外的一个）。大家发现什么问题了吗？也就是我们尝试将从一个classloader载入的Class的一个实例造型为另外一个classloader载入的Class，虽然这两个Class的名字一样，甚至是从同一个class文件中载入。但不幸的是JVM 却认为这个两个Class是不同的，即JVM认为不同的classloader载入的相同的名字的Class（即使是从同一个class文件中载入的）是不同的！这样做的原因我想大概也是主要出于安全性考虑，这样就保证所有的核心Java类都是system classloader载入的，我们无法用自己的classloader载入的相同名字的Class的实例来替换它们的实例。

看到这里，聪明的读者一定想到了该如何动态载入我们的Class，实例化，造型并调用了吧！

那就是利用面向对象的基本特性之一的多形性。我们把我们动态载入的Class的实例造型成它的一个systemclassloader所能识别的父类就行了！这是为什么呢？我们还是要再来分析一次。当我们用我们自己的classloader来动态载入这个Class的时候，发现它有一个父类Class，在载入它之前JVM先会载入这个父类Class，这个父类Class是system classloader所能识别的，根据委托机制，它将由system classloader载入，然后我们的classloader再载入这个Class，创建一个实例，造型为这个父类Class，注意了，造型成这个父类 Class的时候（也就是上溯）是面向对象的java语言所允许的并且JVM也支持的，JVM就使用system classloader再次载入这个父类Class，然后将此实例造型为这个父类Class。大家可以从这个过程发现这个父类Class都是由 system classloader载入的，也就是同一个class loader载入的同一个Class，所以造型的时候不会出现任何异常。而根据多形性，调用这个父类的方法时，真正执行的是这个Class（非父类 Class）的覆盖了父类方法的方法。这些方法中也可以引用system classloader不能识别的Class，因为根据全盘负责原则，只要载入这个Class的classloader即我们自己定义的 classloader能够定位和载入这些Class就行了。

这样我们就可以事先定义好一组接口或者基类并放入CLASSPATH中，然后在执行的时候动态的载入实现或者继承了这些接口或基类的子类。还不明白吗？让我们来想一想Servlet吧，web application server能够载入任何继承了Servlet的Class并正确的执行它们，不管它实际的Class是什么，就是都把它们实例化成为一个Servlet Class，然后执行Servlet的init，doPost，doGet和destroy等方法的,而不管这个Servlet是从web- inf/lib和web-inf/classes下由system classloader的子classloader(即定制的classloader)动态载入。说了这么多希望大家都明白了。在applet,ejb等容器中,都是采用了这种机制.

例：
public class CustomClassLoader extends ClassLoader {
    
    // 定义文件所在目录
    private static final String DEAFAULTDIR = "D:\\jar\\";
    
    @Override
    protected synchronized Class<?> loadClass(String name, boolean resolve) throws ClassNotFoundException {
    
    //系统类以及父类都使用system classloader进行加载
        if (name.startsWith("java.") || name.equals("ClassLoaderPack.ClassLoaderInf")) {
//如果父类也使用CustomClassLoader载入的话就无法实现动态载入
        // if (name.startsWith("java.")) {
            try {
                return super.loadClass(name, false);
            }
            catch (ClassNotFoundException e) {
                e.printStackTrace();
            }
            
        }
        byte[] b = null;
        try {
            b = loadClassData(GetClassName(name));
        }
        catch (Exception e) {
            e.printStackTrace();
        }
        return defineClass(name, b, 0, b.length);
    }
    
    private byte[] loadClassData(String filepath) throws Exception {
    
        int n = 0;
        BufferedInputStream br = new BufferedInputStream(new FileInputStream(new File(filepath)));
        ByteArrayOutputStream bos = new ByteArrayOutputStream();
        
        while ((n = br.read()) != -1) {
            bos.write(n);
        }
        br.close();
        return bos.toByteArray();
    }
    
    public static String GetClassName(String name) {
    
        return DEAFAULTDIR + name.replace('.', '/') + ".class";
    }
}

public class MainTest {
    
    public static void main(String[] args) throws ClassNotFoundException, InstantiationException, IllegalAccessException {
        
        CustomClassLoader customClsLoader = new CustomClassLoader();
        System.out.println(customClsLoader.getClass().getClassLoader());
        Thread.currentThread().setContextClassLoader(customClsLoader);
        //使用自定义的classloader加载子类：ClassLoaderBean（CustomClassLoader中父类是通过systemclassloader加载，
        //子类是通过自定义classloader加载）
        Object obj = Thread.currentThread().getContextClassLoader().loadClass("ClassLoaderPack.ClassLoaderBean").newInstance();
        System.out.println(obj.getClass().getClassLoader());
        //下面这个造型语句是将由CustomClassLoader载入的子类class造型为由system //classloader载入的父类class（也就是上溯，是面向对象的java语言所允许的并且JVM也支持的）
        //由此得出子类class和父类class不一定需要由同一个classloader载入 如果在自定义的CustomClassLoader中，
        //父类也使用CustomClassLoader载入的话那么下面的造型处理就会抛出java.lang.ClassCastException
        ClassLoaderInf clazz = (ClassLoaderInf) obj;
        System.out.println(ClassLoaderInf.class.getClassLoader());
        System.out.println(clazz.getClass().getClassLoader());
        System.out.println(obj instanceof ClassLoaderInf);
        clazz.myPrint();
        
    }
}

Thread. setContextClassLoader()
    上下文加载器
    是一个角色
    用以解决顶层ClassLoader无法访问底层ClassLoader的类的问题
    基本思想是，在顶层ClassLoader中，传入底层ClassLoader的实例

关于setContextClassLoader的理解：
调用setContextClassLoader后，就定义了一个上下文加载器（这里的上下文指线程），但是并不是setContextClassLoader之后该线程之后引用的所有类都是通过这个上下文加载器进行加载的（只有显式的调用这个上下文加载器加载的类才算）。
这就相当于在jvm类加载中增加了一个角色（打破顶层classloader无法访问底层classloader的类的问题）在需要打破双亲模式的时候显式的调用这个角色加载器进行加载，而其他的地方都是按照默认的加载模式进行加载
#################################################ClassLoader类加载#################################################

#################################################Java堆分析#################################################
在JVM中，有哪些内存区间？
堆，永久区，线程栈，直接内存
操作系统分配给每个进程的内存是有限制的，譬如32的Windows限制为2GB。虚拟机提供了参数来控制Java堆和方法区的这两部分内存的最大值。剩余的
内存为2GB（操作系统限制）减去Xmx（最大堆容量），再减去MaxPermSize（最大方法区容量），程序计数器消耗内存很小，可以忽略掉。如果虚拟机进程本身消耗的内存不计算在内，剩下的内存就由虚拟机和本地方法栈“瓜分”了。每个线程分配到的栈容量越大，可以建立的线程数量自然就越少，建立线程时就越容易把剩下的内存耗尽。
但是在64位虚拟机上Java堆的大小受限于物理内存和操作系统提供的虚拟内存（理论上JVM进程能分配到的内存只要不超过物理内存即可）

直接内存
DirectMemory容量可通过-XX:MaxDirectMemorySize=10M指定，如果不指定，则默认与Java堆最大值（-Xmx10M指定）一样。
 
在对象引用图中，所有指向对象B的路径都经过对象A（即：对象A是唯一引用对象B的对象）
则认为对象A支配对象B
如果对象A是离对象B最近的一个支配对象，
则认为对象A为对象B的直接支配者

支配者被回收，被支配对象也被回收

浅堆 
    一个对象结构所占用的内存大小
    3个int类型以及一个引用类型合计占用内存3*4+4=16个字节。再加上对象头的8个字节，因此String对象占用的空间，即浅堆的大小是16+8=24字节
    对象大小按照8字节对齐
    浅堆大小和对象的内容无关，只和对象的结构有关
深堆
    一个对象被GC回收后，可以真实释放的内存大小
    只能通过对象访问到的（直接或者间接）所有对象的浅堆之和 （支配树）

#################################################Java堆分析#################################################
