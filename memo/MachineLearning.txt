准确率、精确率、召回率和 F 值是在鱼龙混杂的环境中，选出目标的重要评价指标。不妨看看这些指标的定义先：
TP-将正类预测为正类(true positive)
FN-将正类预测为负类(false negative)
FP-将负类预测位正类(false positive)
TN-将负类预测位负类(true negative)
准确率（正确率）         =  所有预测正确的样本/总的样本             （TP+TN） / 总
查准率（精确率precision）=  将正类预测为正类 / 所有预测为正类        TP / （TP+FP）
查全率（召回率recall）   =  将正类预测为正类 / 所有正真的正类        TP / （TP+FN）
F值                      =  正确率 * 召回率 * 2 / (正确率 + 召回率) （F 值即为正确率和召回率的调和平均值）

举例来说：
一个数据库有500个文档，其中有50个文档符合定义。系统检索到75个文档，但是实际只有45个符合定义。则：
召回率R=45/50=90%
精确率P=45/75=60%
本例中，系统检索是比较有效的，召回率为90%。但是结果有很大的噪音，有近一半的检索结果是不相关。研究表明：在不牺牲精度的情况下，获得一个高召回率是很困难的。

====================================================回归、分类========================================================
回归(regression) Y变量为连续数值型(continuous numerical variable) 如：房价，人数，降雨量
分类(Classification): Y变量为类别型(categorical variable) 如：颜色类别，电脑品牌，有无信誉
====================================================回归、分类========================================================

====================================================分类问题========================================================
决策树/判定树(decision tree)
====================================================分类问题========================================================

====================================================回归问题========================================================
简单线性回归(Simple Linear Regression)
	很多做决定过过程通常是根据两个或者多个变量之间的关系
	回归分析(regression analysis)用来建立方程模拟两个或者多个变量之间如何关联
	被预测的变量叫做：因变量(dependent variable), y, 输出(output)
	被用来进行预测的变量叫做： 自变量(independent variable), x, 输入(input)
	简单线性回归包含一个自变量(x)和一个因变量(y)
	以上两个变量的关系用一条直线来模拟
	被用来描述因变量(y)和自变量(X)以及偏差(error)之间关系的方程叫做回归模型
多元回归分析(multiple regression)
	与简单线性回归区别(simple linear regression)：包含两个以上的自变量，
====================================================回归问题========================================================