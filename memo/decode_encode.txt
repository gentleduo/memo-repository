编码与解码
首先，明确一点，计算机中存储的信息都是二进制的

编码/解码本质上是一种映射（对应关系），比如'a'用ascii编码则是65，计算机中存储的就是00110101，但是显示的时候不能显示00110101，还是要显示'a'，但计算机怎么知道00110101是'a'呢，这就需要解码，当选择用ascii解码时，当计算机读到00110101时就到对应的ascii表里一查发现是'a'，就显示为'a'

编码：真实字符与二进制串的对应关系，真实字符→二进制串
解码：二进制串与真实字符的对应关系，二进制串→真实字符

ASCII & UTF-8
大家熟知的ASCII以1字节8个bit位表示一个字符，首位全是0，表示的字符集明显不够
unicode编码系统是为表达任意语言而设计的，为了防止存储上的冗余（比如，对应ascii码的部分），其采用了变长编码，但变长编码给解码带来了困难，无法判断是几个字节表示一个字符
UTF-8是针对unicode变长编码设计的一种前缀吗，根据前缀可判断是几个字节表示一个字符
Unicode符号范围      | UTF-8编码方式
(十六进制)           | (二进制)
0000 0000-0000 007F  | 0xxxxxxx
0000 0080-0000 07FF  | 110xxxxx 10xxxxxx
0000 0800-0000 FFFF  | 1110xxxx 10xxxxxx 10xxxxxx
0001 0000-0010 FFFF  | 11110xxx 10xxxxxx 10xxxxxx 10xxxxxx
如果一个字节的第一位是0，则这个字节单独就是一个字符；如果第一位是1，则连续有多少个1，就表示当前字符占用多少个字节。
比如"严"的unicode是4E25（100111000100101），4E25处在第三行的范围内（0000 0800-0000 FFFF），
因此"严"的UTF-8编码需要三个字节，即格式是"1110xxxx 10xxxxxx 10xxxxxx"。
然后，从"严"的最后一个二进制位开始，依次从后向前填入格式中的x，高位补0，得到"严"的UTF-8编码是"11100100 10111000 10100101"。

=========================================================Python编码=========================================================
一、了解字符编码的知识储备
　　1. 文本编辑器存取文件的原理（nodepad++，pycharm，word）
　　　　打开编辑器就打开了启动了一个进程，是在内存中的，所以在编辑器编写的内容也都是存放与内存中的，断电后数据丢失，因而需要保存到硬盘上，点击保存按钮，就从内存中把数据刷到了硬盘上。在这一点上，我们编写一个py文件（没有执行），跟编写其他文件没有任何区别，都只是在编写一堆字符而已。
　　即:在没有点击保存时,我们所写的内容都是写入内存。注意这一点，很重要！！当我们点击保存，内容才被刷到硬盘。
　　上面做了两件事：写内容到内存,从内存将内存刷到硬盘。这是两个过程。
    2. python解释器执行py文件的原理 ，例如python test.py
　　　　第一阶段：python解释器启动，此时就相当于启动了一个文本编辑器
　　　　第二阶段：python解释器相当于文本编辑器，去打开test.py文件，从硬盘上将test.py的文件内容读入到内存中
　　　　第三阶段：python解释器解释执行刚刚加载到内存中test.py的代码
　　　　python解释器执行py文件分为两个步骤:1.将文件读到内存,2.解释执行内容。

二、字符编码简介
　　要搞清楚字符编码，首先要解决的问题是：什么是字符编码？
　　我们都知道，计算机要想工作必须通电,也就是说‘电’驱使计算机干活,而‘电’的特性，就是高低电平(高低平即二进制数1,低电平即二进制数0),也就是说计算机只认识数字(010101).如果我们想保存数据,首先得将我们的数据进行一些处理，最终得转换成010101才能让计算机识别。
　　所以必须经过一个过程：
　　字符--------（翻译过程）------->数字 
　　这个过程实际就是一个字符如何对应一个特定数字的标准，这个标准称之为字符编码。
　　那么问题就来了？作为一种编码方案，还得解决两个问题:
　　　　a.字节是怎么分组的，如8 bits或16 bits一组，这也被称作编码单元。
　　　　b.编码单元和字符之间的映射关系。例如，在ASCII码中，十进制65映射到字母A上。
　　ASCII码是上个世纪最流行的编码体系之一，至少在西方是这样。下图显示了ASCII码中编码单元是怎么映射到字符上的。

三、字符编码的发展史
    阶段一：现代计算机起源于美国，最早诞生也是基于英文考虑的ASCII
　　随着计算机越来越流行，厂商之间的竞争更加激烈，在不同的计算机体系间转换数据变得十分蛋疼，人们厌烦了这种自定义造成的混乱。最终，计算机制造商一起制定了一个标准的方法来描述字符。他们定义使用一个字节的低7位来表示字符，并且制作了如上图所示的对照表来映射七个比特的值到一个字符上。例如，字母A是65，c是99，~是126等等， ASCII码就这样诞生了。原始的ASCII标准定义了从0到127 的字符，这样正好能用七个比特表示。
　　为什么选择了7个比特而不是8个来表示一个字符呢？我并不关心。但是一个字节是8个比特，这意味着1个比特并没有被使用，也就是从128到255的编码并没有被制定ASCII标准的人所规定，这些美国人对世界的其它地方一无所知甚至完全不关心。其它国家的人趁这个机会开始使用128到255范围内的编码来表达自己语言中的字符。例如，144在阿拉伯人的ASCII码中是گ，而在俄罗斯的ASCII码中是ђ。ASCII码的问题在于尽管所有人都在0-127号字符的使用上达成了一致，但对于128-255号字符却有很多很多不同的解释。你必须告诉计算机使用哪种风格的ASCII码才能正确显示128-255号的字符。
　　总结：ASCII，一个Bytes代表一个字符（英文字符/键盘上的所有其他字符），1Bytes=8bit，8bit可以表示0-2**8-1种变化，即可以表示256个字符，ASCII最初只用了后七位，127个数字，已经完全能够代表键盘上所有的字符了（英文字符/键盘的所有其他字符），后来为了将拉丁文也编码进了ASCII表，将最高位也占用了。
    阶段二:为了满足中文，中国人定制了GBK
　　GBK:2Bytes代表一个字符；为了满足其他国家，各个国家纷纷定制了自己的编码。日本把日文编到Shift_JIS里，韩国把韩文编到Euc-kr里
    阶段三：万国码Unicode编码
　　后来，有人开始觉得太多编码导致世界变得过于复杂了，让人脑袋疼，于是大家坐在一起拍脑袋想出来一个方法：所有语言的字符都用同一种字符集来表示，这就是Unicode。Unicode统一用2Bytes代表一个字符，2**16-1=65535，可代表6万多个字符，因而兼容万国语言.但对于通篇都是英文的文本来说，这种编码方式无疑是多了一倍的存储空间（英文字母只需要一个字节就足够,用两个字节来表示,无疑是浪费空间）.于是产生了UTF-8，对英文字符只用1Bytes表示，对中文字符用3Bytes.UTF-8是一个非常惊艳的概念，它漂亮的实现了对ASCII码的向后兼容，以保证Unicode可以被大众接受。在UTF-8中，0-127号的字符用1个字节来表示，使用和US-ASCII相同的编码。这意味着1980年代写的文档用UTF-8打开一点问题都没有。只有128号及以上的字符才用2个，3个或者4个字节来表示。因此，UTF-8被称作可变长度编码。于是下面字节流如下
    0100100001000101010011000100110001001111
　　这个字节流在ASCII和UTF-8中表示相同的字符：HELLO
　　至于其他的UTF-16，这里就不再叙述了。
　　总结一点：unicode：简单粗暴，所有字符都是2Bytes，优点是字符----->数字的转换速度快，缺点是占用空间大。
　　utf-8：精准，对不同的字符用不同的长度表示，优点是节省空间，缺点是：字符->数字的转换速度慢，因为每次都需要计算出字符需要多长的Bytes才能够准确表示。
　　因此，内存中使用的编码是unicode，用空间换时间（程序都需要加载到内存才能运行，因而内存应该是尽可能的保证快）；硬盘中或者网络传输用utf-8，网络I/O延迟或磁盘I/O延迟要远大与utf-8的转换延迟，而且I/O应该是尽可能地节省带宽，保证数据传输的稳定性。
　　所有程序，最终都要加载到内存，程序保存到硬盘不同的国家用不同的编码格式，但是到内存中我们为了兼容万国（计算机可以运行任何国家的程序原因在于此），统一且固定使用unicode，这就是为何内存固定用unicode的原因，你可能会说兼容万国我可以用utf－8啊，可以，完全可以正常工作，之所以不用肯定是unicode比utf－8更高效啊（uicode固定用2个字节编码，utf－8则需要计算），但是unicode更浪费空间，没错，这就是用空间换时间的一种做法，而存放到硬盘，或者网络传输，都需要把unicode转成utf－8，因为数据的传输，追求的是稳定，高效，数据量越小数据传输就越靠谱，于是都转成utf－8格式的，而不是unicode。

四、字符编码的使用
    内存Unicode格式的二进制
	    ∧                |
读取文件|:decode 保存文件|:encode
		|                ∨
    硬盘UTF-8格式的二进制
	
	不管是哪种类型的文件，只要记住一点：文件以什么编码保存的，就以什么编码方式打开.
　　下面我们来看看python中关于编码出现的问题:
　　如果不在python文件指定头信息＃-*-coding:utf-8-*-,那就使用默认的python2中默认使用ascii，python3中默认使用utf-8
　　读取已经加载到内存的代码（unicode编码的二进制），然后执行，执行过程中可能会开辟新的内存空间，比如x="hello"
　　内存的编码使用unicode，不代表内存中全都是unicode编码的二进制，在程序执行之前，内存中确实都是unicode编码的二进制,比如从文件中读取了一行x="hello",其中的x，等号，引号，地位都一样，都是普通字符而已，都是以unicode编码的二进制形式存放与内存中的.但是程序在执行过程中，会申请内存（与程序代码所存在的内存是俩个空间），可以存放任意编码格式的数据，比如x="hello",会被python解释器识别为字符串，会申请内存空间来存放"hello"，然后让x指向该内存地址，此时新申请的该内存地址保存也是unicode编码的hello,如果代码换成x="hello".encode('utf-8'),那么新申请的内存空间里存放的就是utf-8编码的字符串hello了.

五、Python2与python3编码区别

    在最新的python3版本中，字符串的类型是str， 在内存中都是以Unicode表示，一个字符对应若干个字节； 
如果要在网络上传输，或者保存到磁盘上，就需要把str变为以字节为单位的bytes。

　　1.在python2中有两种字符串类型str和unicode
　　　str类型:当python解释器执行到产生字符串的代码时（例如s='林'），会申请新的内存地址，然后将'林'编码成文件开头指定的编码格式，这已经是encode之后的结果了，所以s只能decode。再次encode就会报错。
　　　Unicode类型:当python解释器执行到产生字符串的代码时（例如s=u'林'），会申请新的内存地址，然后将'林'以unicode的格式存放到新的内存空间中，所以s只能encode，不能decode.
    2. 在python3中也有两种字符串类型str和bytes

　　  str类型变为unicode类型
      #coding:utf-8
      s='林' #当程序执行时，无需加u，'林'也会被以unicode形式保存新的内存空间中,
      #s可以直接encode成任意编码格式
      s.encode('utf-8')
      s.encode('gbk')
      print(type(s)) #<class 'str'>

	  bytes类型
      #coding:utf-8
      s='林' #当程序执行时，无需加u，'林'也会被以unicode形式保存新的内存空间中,
      #s可以直接encode成任意编码格式
      s1=s.encode('utf-8')
      s2=s.encode('gbk')
      print(s) #林
      print(s1) #b'\xe6\x9e\x97' 在python3中，是什么就打印什么
      print(s2) #b'\xc1\xd6' 同上
      print(type(s)) #<class 'str'>
      print(type(s1)) #<class 'bytes'>
      print(type(s2)) #<class 'bytes'>

什么叫编码（encode）？
编码的意思是将Unicode字符按照编码规则（如UTF-8）编成字节序列：
例如在python2中：
>>> a = u'测试'
>>> a.encode('utf-8')
'\xe6\xb5\x8b\xe8\xaf\x95'
>>>

什么叫解码（decode）?
对应的，解码就是将字节序列按照编码规则（如UTF-8）解释成unicode形式。
例如在python2中：
>>> a = b'测试'
>>> a.decode('GBK')
u'\u5a34\u5b2d\u762f'
>>>

这里或许又会有疑问，编码解码都是十六进制，那中文字符咋显示的？
这又要结合你的环境了。Unicode只是一种标准，而具体的编码才是实现方式。有了正确的Unicode编码，仅仅代表你有了正确的英文文献，想翻译成中文，还得再转换一次。而这一次转换，是你的环境帮你完成。举个例子，你打开一个文档，发现是乱码，多半是文本编辑器的解码方式有问题，换个解码规则就好了。

在Python3当中，文本字符串类型（使用Unicode数据存储）被命名为str,字节字符串类型被命名为bytes。一般情况下，实例化一个字符串会得到一个str对象
在Python3中的str对象在Python2中叫做unicode，但bytes对象在Python2中叫做str，如果你想得到一个文本字符串，你需要在字符串之前加上前缀u或者decode一下。
Python2中的str（字节）对象竟然有一个encode方法，它就是用来报错的，永远都别使用它！！！
例如：
>>> a = '测试'
>>> a.encode('utf-8')
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
UnicodeDecodeError: 'ascii' codec can't decode byte 0xe6 in position 0: ordinal not in range(128)
>>>
同样的，unicode（文本字符）对象也有一个用来报错的decode方法
>>> a = '测试'
>>> a.decode('GBK')
u'\u5a34\u5b2d\u762f'
>>> b = a.decode('GBK')
>>> type(b)
<type 'unicode'>
>>> b.decode('GBK')
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
UnicodeEncodeError: 'ascii' codec can't encode characters in position 0-2: ordinal not in range(128)
>>>

注意错误信息，在进行解码，规则是GBK，但它说无法用ascii进行编码，这是为什么？
这就是Python2自作聪明为了对一个unicode对象执行解码而进行的隐式编码，等于以下代码：
b.encode ('ascii').decode('GBK')


######################################cmd下或者linux系统下、进入Python交互式命令行中文显示正常的原因(针对于python2.7)######################################

新建一个demo.py文件，文件存储格式为utf-8文件中内容如下：
s = "中文"
print s
在cmd中运行python demo.py，报错内容如下：
D:\python-2.7>python demo.py
  File "demo.py", line 1
SyntaxError: Non-ASCII character '\xe4' in file demo.py on line 1, but no encoding declared; see http://python.org/dev/peps/pep-0263/ for details

而在linux系统下，输入python命令进入python交互式命令行，发现一切正常
[root@server02 ~]# python
Python 2.7.5 (default, Nov  6 2016, 00:28:07)
[GCC 4.8.5 20150623 (Red Hat 4.8.5-11)] on linux2
Type "help", "copyright", "credits" or "license" for more information.
>>> s = "中文"
>>> print s
中文
>>> s
'\xe4\xb8\xad\xe6\x96\x87'

cmd下报的错误Non-ASCII character '\xe4' in file demo.py on line 1, but no encoding declared;，翻译过来就是在demo.py文件的第1行有非ASCII字符 ‘\xe4’，而且没有声明编码，从上面基础知识可知，ASCII 编码是不能表示汉字中文的，demo.py文件第一行有中文两个汉字，而demo.py 文件存储格式为utf-8，所以中文两个汉字在文件中存储的时候是以utf-8编码存储的，查看demo.py文件16进制可以看到中文存储的是\xe4\xb8\xad\xe6\x96\x87。

sys.getdefaultencoding()读取python默认编码是ASCII，而ASCII是不认识\xe4的，所以会报错Non-ASCII character '\xe4' in file demo.py on line 1, but no encoding declared;，此时只要在 demo.py文件头加上# encoding:utf-8就可以了，虽然是注释，但python看到这句话就知道了接下来应该用utf-8编码了，而demo.py 存储时也是utf-8的，所以就正常了。
# encoding:utf-8
s = "中文"
print s
编码声明注释写成# -*- coding: utf-8 -*-也是可以的，只要满足正则表达式^[ \t\v]*#.*?coding[:=][ \t]*([-_.a-zA-Z0-9]+)就OK。
再次在cmd下运行python demo.py，输出乱码
D:\python-2.7>python demo.py
涓枃

试着在cmd下，输入python命令进入python交互式命令行输出中文看看，发现cmd下可以正常输出中文：
D:\python-2.7>python
Python 2.7.17 (v2.7.17:c2f86d86e6, Oct 19 2019, 21:01:17) [MSC v.1500 64 bit (AMD64)] on win32
Type "help", "copyright", "credits" or "license" for more information.
>>> s = "中文"
>>> print s
中文
>>> s
'\xd6\xd0\xce\xc4'
>>>

其实当在交互式命令行或者idle中打印字符的时候已经和文件编码方式没有关系了，此时起作用的是输出环境也就是cmd或者idle的编码方式有关，查看cmd的编码命令是 chcp，返回936，去网上查找可知936代表GBK 编码，这下我们大概知道什么原因了，demo.py文件存储和编码声明都是utf-8，但是cmd显示编码是GBK，而将中文的utf-8编码 \xe4\xb8\xad\xe6\x96\x87 强制转换为 GBK 就会乱码了，GBK 是两个字节存储一个中文字符，所以 \xe4\xb8\xad\xe6\x96\x87 会解码成三个字，很不幸这三个字涓枃不是常用字也不是我们想要的字符，所以就认为是乱码了。为什么在cmd下进入Python交互式命令行可以呢，这是因为当在python 交互式命令行输入s="中文"时，中文这两个汉字其实是以GBK编码存储的，cmd默认编码是GBK ，不信看s打印\xd6\xd0\xce\xc4，这就是GBK编码方式存储，而utf-8编码方式存储同样的中文为\xe4\xb8\xad\xe6\x96\x87。

demo.py文件存储和编码声明都是utf-8，所以"中文在文件中被存储为："\xe4\xb8\xad\xe6\x96\x87"
cmd命令行输入python demo.py后 python解释器会打开demo.py文件，先以python文件头指定的编码(如:# encoding:utf-8，如果文件头中没有指定，那就使用默认的，python2中默认使用ascii)对文件内容进行解码变成Unicode码，但是由于在python2中的string在内存中不是以unicode码而是以bytes形式保存的，所以在解码后，对于string类型的数据python解释器还会再用python文件头指定的编码对Unicode码再进行编码，然后保存到内存中
此时内存中的"中文"还是utf-8格式的："\xe4\xb8\xad\xe6\x96\x87" 
但是在print s的时候，由于输出环境cmd是GBK编码的，所以会有个utf-8到GBK的强转过程，由于\xe4\xb8\xad\xe6\x96\x87在GBK编码中都存在，所以不会报错，但是由于GBK编码是双字节编码所以会被编码成\xe4\xb8、\xad\xe6、\x96\x87三个字，它们在GBK编码中分别对应：涓枃


python2和python3中string最大的不同
1) python2中string是unicode字符再经过编码后的结果：bytes；而python3的string就是unicode
例：
#coding:utf-8
s='林' #在执行时,'林'会先被以conding:utf-8格式进行解码成unicode字符串，然后再以同样的格式编码，最后以conding:utf-8的bytes形式保存到新的内存空间中
print repr(s) #'\xe6\x9e\x97' 三个Bytes,证明确实是utf-8
print type(s) #<type 'str'>
s.decode('utf-8')
# s.encode('utf-8') #报错，s为编码后的结果bytes，所以只能decode
2) python2中string为编码后的结果bytes，所以只能decode
3) python2如果想定义unicode的字符串，则必须在字符串前面加u。例如：word = u'中文'
4) python3中无需加u，字符串都会被以unicode形式保存新的内存空间中，
5) python3中string可以直接encode成任意编码格式，encode后的类型就是bytes了
######################################cmd下或者linux系统下、进入Python交互式命令行中文显示正常的原因(针对于python2.7)######################################

=========================================================Python编码=========================================================