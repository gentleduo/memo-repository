docker二进制离线安装
https://download.docker.com/linux/static/stable/x86_64/

例：
1. 下载解压docker
wget https://download.docker.com/linux/static/stable/x86_64/docker-17.03.2-ce.tgz
2. 拷贝文件至bin下
chmod +x docker/*
cp docker/* /usr/local/bin
3. 创建服务文件
cat > /usr/lib/systemd/system/docker.service <<"EOF"
[Unit]
Description=Docker Application Container Engine
Documentation=https://docs.docker.com
After=network-online.target firewalld.service
Wants=network-online.target

[Service]
Type=notify
# the default is not to use systemd for cgroups because the delegate issues stil                                                                                        l
# exists and systemd currently does not support the cgroup feature set required
# for containers run by docker
ExecStart=/usr/bin/dockerd
ExecReload=/bin/kill -s HUP $MAINPID
# Having non-zero Limit*s causes performance problems due to accounting overhead
# in the kernel. We recommend using cgroups to do container-local accounting.
LimitNOFILE=infinity
LimitNPROC=infinity
LimitCORE=infinity
# Uncomment TasksMax if your systemd version supports it.
# Only systemd 226 and above support this version.
#TasksMax=infinity
TimeoutStartSec=0
# set delegate yes so that systemd does not reset the cgroups of docker containe                                                                                        rs
Delegate=yes
# kill only the docker process, not all processes in the cgroup
KillMode=process
# restart the docker process if it exits prematurely
Restart=on-failure
StartLimitBurst=3
StartLimitInterval=60s

[Install]
WantedBy=multi-user.target
EOF

4. 修改docker挂载路径，默认为/var/lib/docker，建议选择比较大的数据盘
修改文件为/etc/docker/daemon.json

5. 启动docker：
systemctl daemon-reload
systemctl restart docker

6. 设置开机启动：
systemctl enable docker

7. 检验是否启动：
systemctl status docker
docker info

若为running状态，docker info不报错即正常

注意：
cat > file << EOF 的用法
cat> 文件名<<eof  
用来创建文件
在这之后输入任何东西 都是在 文件里的
输入完成之后EOF结尾  代表结束
比如
cat > 1.txt <<eof
1
2
3
4
5
eof
就是创建1.txt这个文件里面内容是 1 2 3 4 5

docker安装：https://docs.docker.com/install/linux/docker-ce/centos/#install-using-the-repository
yum install -y yum-utils   device-mapper-persistent-data   lvm2
yum-config-manager     --add-repo     https://download.docker.com/linux/centos/docker-ce.repo
yum-config-manager --enable docker-ce-edge
yum-config-manager --enable docker-ce-test
yum-config-manager --disable docker-ce-edge
yum install docker-ce

测试docker
systemctl start docker
docker run hello-world
docker ps

docker-compose安装：https://docs.docker.com/compose/install/#install-compose
下载最新版的docker-compose文件 
curl -L https://github.com/docker/compose/releases/download/1.21.2/docker-compose-$(uname -s)-$(uname -m) -o /usr/local/bin/docker-compose
添加可执行权限 
chmod +x /usr/local/bin/docker-compose
测试安装结果 
docker-compose --version 

﻿从主机复制到容器sudo docker cp host_path containerID:container_path
从容器复制到主机sudo docker cp containerID:container_path host_path

方法一：如果要正常退出不关闭容器，请按Ctrl+P+Q进行退出容器
方法二：如果使用exit退出，那么在退出之后会关闭容器，可以使用下面的流程进行恢复
    使用docker restart命令重启容器
    使用docker attach命令进入容器
	
########################################################容器技术概念########################################################
容器其实是一种沙盒技术。顾名思义，沙盒就是能够像一个集装箱一样，把你的应用“装”起来的技术。这样，应用与应用之间，就因为有了边界而不至于相互干扰；而被装进集装箱的应用，也可以被方便地搬来搬去，这不就是PaaS最理想的状态吗。
容器技术的核心功能，就是通过约束和修改进程的动态表现，从而为其创造出一个“边界”。
对于Docker等大多数Linux容器来说，Cgroups技术是用来制造约束的主要手段，而Namespace技术则是用来修改进程视图的主要方法。

=====> Namespace
假设你已经有了一个Linux操作系统上的Docker项目在运行，比如我的环境是CentOS-7和Docker-CE-18.05。
首先创建一个容器
$ docker run -it centos:7 /bin/bash
这个命令是Docker项目最重要的一个操作，即大名鼎鼎的docker run。
而-it参数告诉了Docker项目在启动容器后，需要给我们分配一个文本输入/输出环境，也就是TTY，跟容器的标准输入相关联，这样我们就可以和这个 Docker容器进行交互了。而/bin/sh就是我们要在Docker容器里运行的程序。
所以，上面这条指令翻译成人类的语言就是：请帮我启动一个容器，在容器里执行/bin/sh，并且给我分配一个命令行终端跟这个容器交互。这样，我的CentOS-7机器就变成了一个宿主机，而一个运行着/bin/bash的容器，就跑在了这个宿主机里面。
此时，如果我们在容器里执行一下ps指令，就会发现一些更有趣的事情：
[root@5ec0ea1b662b /]# ps
  PID TTY          TIME CMD
    1 pts/0    00:00:00 bash
   13 pts/0    00:00:00 ps
可以看到，我们在Docker里最开始执行的/bin/bash，就是这个容器内部的第1号进程（PID=1），而这个容器里一共只有两个进程在运行。这就意味着，前面执行的/bin/bash，以及我们刚刚执行的ps，已经被Docker隔离在了一个跟宿主机完全不同的世界当中。
这究竟是怎么做到的呢？
本来，每当我们在宿主机上运行了一个/bin/bash程序，操作系统都会给它分配一个进程编号，比如PID=100。这个编号是进程的唯一标识，就像员工的工牌一样。所以PID=100，可以粗略地理解为这个/bin/bash是我们公司里的第100号员工，而第1号员工就自然是比尔·盖茨这样统领全局的人物。
而现在，我们要通过Docker把这个/bin/bash程序运行在一个容器当中。这时候，Docker就会在这个第100号员工入职时给他施一个“障眼法”，让他永远看不到前面的其他99个员工，更看不到比尔·盖茨。这样，他就会错误地以为自己就是公司里的第1号员工。
这种机制，其实就是对被隔离应用的进程空间做了手脚，使得这些进程只能看到重新计算过的进程编号，比如PID=1。可实际上，他们在宿主机的操作系统里，还是原来的第100号进程。
这种技术，就是Linux里面的Namespace机制。它是Linux内核用来隔离内核资源的方式，通过namespace可以让一些进程只能看到与自己相关的一部分资源，而另外一些进程也只能看到与它们自己相关的资源，这两拨进程根本就感觉不到对方的存在。而Namespace的使用方式也非常有意思：它其实只是Linux创建新进程的一个可选参数。我们知道，在Linux系统中创建线程的系统调用是clone()，比如：
int pid = clone(main_function, stack_size, SIGCHLD, NULL); 
这个系统调用就会为我们创建一个新的进程，并且返回它的进程号pid。
而当我们用clone()系统调用创建一个新进程时，就可以在参数中指定CLONE_NEWPID参数，比如：
int pid = clone(main_function, stack_size, CLONE_NEWPID | SIGCHLD, NULL); 
这时，新创建的这个进程将会“看到”一个全新的进程空间，在这个进程空间里，它的PID是1。之所以说“看到”，是因为这只是一个“障眼法”，在宿主机真实的进程空间里，这个进程的PID还是真实的数值，比如100。当然，我们还可以多次执行上面的clone()调用，这样就会创建多个PIDNamespace，而每个Namespace里的应用进程，都会认为自己是当前容器里的第1号进程，它们既看不到宿主机里真正的进程空间，也看不到其他PIDNamespace里的具体情况。
而除了我们刚刚用到的PID-Namespace，Linux操作系统还提供了Mount、UTS、IPC、Network和User这些Namespace，用来对各种不同的进程上下文进行“障眼法”操作。
比如，Mount-Namespace，用于让被隔离进程只看到当前Namespace里的挂载点信息；Network-Namespace，用于让被隔离进程看到当前Namespace里的网络设备和配置。
这，就是Linux容器最基本的实现原理了。
所以，Docker容器这个听起来玄而又玄的概念，实际上是在创建容器进程时，指定了这个进程所需要启用的一组Namespace参数。这样，容器就只能“看”到当前Namespace所限定的资源、文件、设备、状态，或者配置。而对于宿主机以及其他不相关的程序，它就完全看不到了。
所以说，容器，其实是一种特殊的进程而已。
总结
谈到为“进程划分一个独立空间”的思想，相信你一定会联想到虚拟机。其中，名为Hypervisor的软件是虚拟机最主要的部分。它通过硬件虚拟化功能，模拟出了运行一个操作系统需要的各种硬件，比如CPU、内存、I/O设备等等。然后，它在这些虚拟的硬件上安装了一个新的操作系统，即GuestOS。
这样，用户的应用进程就可以运行在这个虚拟的机器中，它能看到的自然也只有GuestOS的文件和目录，以及这个机器里的虚拟设备。这就是为什么虚拟机也能起到将不同的应用进程相互隔离的作用。
很多人会把Docker项目称为“轻量级”虚拟化技术的原因，实际上就是把虚拟机的概念套在了容器上。
在理解了Namespace的工作方式之后，你就会明白，跟真实存在的虚拟机不同，在使用Docker的时候，并没有一个真正的“Docker容器”运行在宿主机里面。Docker项目帮助用户启动的，还是原来的应用进程，只不过在创建这些进程时，Docker为它们加上了各种各样的Namespace参数。
这时，这些进程就会觉得自己是各自PID-Namespace里的第1号进程，只能看到各自Mount-Namespace里挂载的目录和文件，只能访问到各自Network-Namespace里的网络设备，就仿佛运行在一个个“容器”里面，与世隔绝。
Namespace Flag            Page                  Isolates
Cgroup    CLONE_NEWCGROUP cgroup_namespaces(7)  Cgroup root directory(cgroup的根目录)
IPC       CLONE_NEWIPC    ipc_namespaces(7)     System V IPC,POSIX message queues(信息量、消息队列和共享内存；隔离进程间通信)
Network   CLONE_NEWNET    network_namespaces(7) Network devices,stacks, ports, etc.(网络设备、网络栈、端口等；隔离网络资源).
Mount     CLONE_NEWNS     mount_namespaces(7)   Mount points(文件系统挂载点；隔离文件系统挂载点)
PID       CLONE_NEWPID    pid_namespaces(7)     Process IDs(进程编号；隔离进程的ID)
Time      CLONE_NEWTIME   time_namespaces(7)    Boot and monotonic clocks(允许操作系统为进程设定不同的系统时间；隔离系统时间)
User      CLONE_NEWUSER   user_namespaces(7)    User and group IDs(用户和用户组；隔离用户和用户组的ID)
UTS       CLONE_NEWUTS    uts_namespaces(7)     Hostname and NIS domain name(主机名与NIS域名；隔离主机名和域名信息)
									   
=====> Cgroups
前面详细介绍了Linux容器中用来实现“隔离”的技术手段：Namespace。而通过这些讲解，你应该能够明白，Namespace技术实际上修改了应用进程看待整个计算机“视图”，即它的“视线”被操作系统做了限制，只能“看到”某些指定的内容。但对于宿主机来说，这些被“隔离”了的进程跟其他进程并没有太大区别。
在虚拟机与容器技术的对比里，不应该把Docker-Engine或者任何容器管理工具放在跟Hypervisor相同的位置，因为它们并不像Hypervisor那样对应用进程的隔离环境负责，也不会创建任何实体的“容器”，真正对隔离环境负责的是宿主机操作系统本身：
所以，我们应该把Docker放在跟应用同级别并且靠边的位置。这意味着，用户运行在容器里的应用进程，跟宿主机上的其他进程一样，都由宿主机操作系统统一管理，只不过这些被隔离的进程拥有额外设置过的Namespace参数。而Docker项目在这里扮演的角色，更多的是旁路式的辅助和管理工作。
这样的架构也解释了为什么 Docker 项目比虚拟机更受欢迎的原因。
这是因为，使用虚拟化技术作为应用沙盒，就必须要由Hypervisor来负责创建虚拟机，这个虚拟机是真实存在的，并且它里面必须运行一个完整的GuestOS才能执行用户的应用进程。这就不可避免地带来了额外的资源消耗和占用。
根据实验，一个运行着CentOS的KVM虚拟机启动后，在不做优化的情况下，虚拟机自己就需要占用100~200MB内存。此外，用户应用运行在虚拟机里面，它对宿主机操作系统的调用就不可避免地要经过虚拟化软件的拦截和处理，这本身又是一层性能损耗，尤其对计算资源、网络和磁盘I/O的损耗非常大。
而相比之下，容器化后的用户应用，却依然还是一个宿主机上的普通进程，这就意味着这些因为虚拟化而带来的性能损耗都是不存在的；而另一方面，使用Namespace作为隔离手段的容器并不需要单独的GuestOS，这就使得容器额外的资源占用几乎可以忽略不计。
所以说，“敏捷”和“高性能”是容器相较于虚拟机最大的优势，也是它能够在PaaS这种更细粒度的资源管理平台上大行其道的重要原因。
不过，有利就有弊，基于LinuxNamespace的隔离机制相比于虚拟化技术也有很多不足之处，其中最主要的问题就是：隔离得不彻底。
首先，既然容器只是运行在宿主机上的一种特殊的进程，那么多个容器之间使用的就还是同一个宿主机的操作系统内核。
尽管你可以在容器里通过Mount-Namespace单独挂载其他不同版本的操作系统文件，比如CentOS或者Ubuntu，但这并不能改变共享宿主机内核的事实。这意味着，如果你要在Windows宿主机上运行Linux容器，或者在低版本的Linux宿主机上运行高版本的Linux容器，都是行不通的。
而相比之下，拥有硬件虚拟化技术和独立GuestOS的虚拟机就要方便得多了。最极端的例子是，Microsoft的云计算平台Azure，实际上就是运行在Windows服务器集群上的，但这并不妨碍你在它上面创建各种Linux虚拟机出来。
其次，在Linux内核中，有很多资源和对象是不能被Namespace化的，最典型的例子就是：时间。这就意味着，如果你的容器中的程序使用settimeofday(2)系统调用修改了时间，整个宿主机的时间都会被随之修改，这显然不符合用户的预期。相比于在虚拟机里面可以随便折腾的自由度，在容器里部署应用的时候，“什么能做，什么不能做”，就是用户必须考虑的一个问题。
在介绍完容器的“隔离”技术之后，我们再来研究一下容器的“限制”问题。也许你会好奇，我们不是已经通过Linux-Namespace创建了一个“容器”吗，为什么还需要对容器做“限制”呢？我还是以PID-Namespace为例，来给你解释这个问题。虽然容器内的第1号进程在“障眼法”的干扰下只能看到容器里的情况，但是宿主机上，它作为第100号进程与其他所有进程之间依然是平等的竞争关系。这就意味着，虽然第100号进程表面上被隔离了起来，但是它所能够使用到的资源（比如CPU、内存），却是可以随时被宿主机上的其他进程（或者其他容器）占用的。当然，这个100号进程自己也可能把所有资源吃光。这些情况，显然都不是一个“沙盒”应该表现出来的合理行为。而Linux的Cgroups就是Linux内核中用来为进程设置资源限制的一个重要功能。
Linux Cgroups的全称是Linux Control Group。它最主要的作用，就是限制一个进程组能够使用的资源上限，包括CPU、内存、磁盘、网络带宽等等。
此外，Cgroups还能够对进程进行优先级设置、审计，以及将进程挂起和恢复等操作。下面重点探讨它与容器关系最紧密的“限制”能力。
在Linux中，Cgroups给用户暴露出来的操作接口是文件系统，即它以文件和目录的方式组织在操作系统的/sys/fs/cgroup路径下。可以用mount指令把它们展示出来
[root@server01 ~]# mount -t cgroup
cgroup on /sys/fs/cgroup/systemd type cgroup (rw,nosuid,nodev,noexec,relatime,xattr,release_agent=/usr/lib/systemd/systemd-cgroups-agent,name=systemd)
cgroup on /sys/fs/cgroup/pids type cgroup (rw,nosuid,nodev,noexec,relatime,pids)
cgroup on /sys/fs/cgroup/freezer type cgroup (rw,nosuid,nodev,noexec,relatime,freezer)
cgroup on /sys/fs/cgroup/cpu,cpuacct type cgroup (rw,nosuid,nodev,noexec,relatime,cpuacct,cpu)
cgroup on /sys/fs/cgroup/memory type cgroup (rw,nosuid,nodev,noexec,relatime,memory)
cgroup on /sys/fs/cgroup/blkio type cgroup (rw,nosuid,nodev,noexec,relatime,blkio)
cgroup on /sys/fs/cgroup/net_cls,net_prio type cgroup (rw,nosuid,nodev,noexec,relatime,net_prio,net_cls)
cgroup on /sys/fs/cgroup/devices type cgroup (rw,nosuid,nodev,noexec,relatime,devices)
cgroup on /sys/fs/cgroup/hugetlb type cgroup (rw,nosuid,nodev,noexec,relatime,hugetlb)
cgroup on /sys/fs/cgroup/perf_event type cgroup (rw,nosuid,nodev,noexec,relatime,perf_event)
cgroup on /sys/fs/cgroup/cpuset type cgroup (rw,nosuid,nodev,noexec,relatime,cpuset)
它的输出结果，是一系列文件系统目录。如果你在自己的机器上没有看到这些目录，那你就需要自己去挂载Cgroups，具体做法可以自行Google。可以看到，在/sys/fs/cgroup下面有很多诸如cpuset、cpu、memory这样的子目录，也叫子系统。这些都是我这台机器当前可以被Cgroups进行限制的资源种类。而在子系统对应的资源种类下，你就可以看到该类资源具体可以被限制的方法。比如，对CPU子系统来说，我们就可以看到如下几个配置文件，这个指令是：
[root@server01 ~]# ls /sys/fs/cgroup/cpu
cgroup.clone_children  cgroup.sane_behavior  cpuacct.usage         cpu.cfs_quota_us   cpu.shares  notify_on_release  tasks
cgroup.event_control   container             cpuacct.usage_percpu  cpu.rt_period_us   cpu.stat    release_agent      user.slice
cgroup.procs           cpuacct.stat          cpu.cfs_period_us     cpu.rt_runtime_us  docker      system.slice
如果熟悉Linux-CPU管理的话，你就会在它的输出里注意到cfs_period和cfs_quota这样的关键词。这两个参数需要组合使用，可以用来限制进程在长度为cfs_period的一段时间内，只能被分配到总量为cfs_quota的CPU时间。
而这样的配置文件又如何使用呢？
你需要在对应的子系统下面创建一个目录，比如，我们现在进入/sys/fs/cgroup/cpu目录下：
[root@server01 cpu]# mkdir container
[root@server01 cpu]# ls container/
cgroup.clone_children  cgroup.procs  cpuacct.usage         cpu.cfs_period_us  cpu.rt_period_us   cpu.shares  notify_on_release
cgroup.event_control   cpuacct.stat  cpuacct.usage_percpu  cpu.cfs_quota_us   cpu.rt_runtime_us  cpu.stat    tasks
这个目录就称为一个“控制组”。你会发现，操作系统会在你新创建的container目录下，自动生成该子系统对应的资源限制文件。
现在，我们在后台执行这样一条脚本：
[root@server01 cpu]# while : ; do : ; done &
[1] 1780
显然，它执行了一个死循环，可以把计算机的CPU吃到100%，根据它的输出，我们可以看到这个脚本在后台运行的进程号（PID）是1780。
这样，我们可以用top指令来确认一下CPU有没有被打满：
top - 11:33:50 up  2:43,  1 user,  load average: 0.63, 0.18, 0.10
Tasks:  79 total,   2 running,  77 sleeping,   0 stopped,   0 zombie
%Cpu(s):100.0 us,  0.0 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st
KiB Mem :  2048668 total,  1091004 free,   345076 used,   612588 buff/cache
KiB Swap:  1952764 total,  1952764 free,        0 used.  1520152 avail Mem
  PID USER      PR  NI    VIRT    RES    SHR S %CPU %MEM     TIME+ COMMAND
 1780 root      20   0  115736    644    136 R 99.9  0.0   0:50.91 bash
在输出里可以看到，CPU的使用率已经100%了（%Cpu0 :100.0 us）。
而此时，可以通过查看container目录下的文件，看到container控制组里的CPU quota还没有任何限制（即：-1），CPU period则是默认的100ms（100000 us）：
[root@server01 cpu]# cat /sys/fs/cgroup/cpu/container/cpu.cfs_quota_us
-1
[root@server01 cpu]# cat /sys/fs/cgroup/cpu/container/cpu.cfs_period_us
100000
接下来，我们可以通过修改这些文件的内容来设置限制。比如，向container组里的cfs_quota文件写入20ms（20000us）：
[root@server01 cpu]# echo 20000 > /sys/fs/cgroup/cpu/container/cpu.cfs_quota_us
结合前面的介绍，你应该能明白这个操作的含义，它意味着在每100ms的时间里，被该控制组限制的进程只能使用20ms的CPU时间，也就是说这个进程只能使用到20%的CPU带宽。接下来，我们把被限制的进程的PID写入container组里的tasks文件，上面的设置就会对该进程生效了：
[root@server01 cpu]# echo 1780 > /sys/fs/cgroup/cpu/container/tasks
我们可以用 top 指令查看一下：
top - 11:37:14 up  2:47,  1 user,  load average: 1.07, 0.62, 0.29
Tasks:  78 total,   2 running,  76 sleeping,   0 stopped,   0 zombie
%Cpu(s): 20.4 us,  0.3 sy,  0.0 ni, 79.3 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st
KiB Mem :  2048668 total,  1090896 free,   345204 used,   612568 buff/cache
KiB Swap:  1952764 total,  1952764 free,        0 used.  1520044 avail Mem

  PID USER      PR  NI    VIRT    RES    SHR S %CPU %MEM     TIME+ COMMAND
 1780 root      20   0  115736    644    136 R 20.3  0.0   3:54.90 bash
可以看到，计算机的CPU使用率立刻降到了20%（%Cpu0:20.3us）。
除CPU子系统外，Cgroups的每一个子系统都有其独有的资源限制能力，比如：blkio，为​​​块​​​设​​​备​​​设​​​定​​​I/O限​​​制，一般用于磁盘等设备；cpuset，为进程分配单独的CPU核和对应的内存节点；memory，为进程设定内存使用的限制。LinuxCgroups的设计还是比较易用的，简单粗暴地理解呢，它就是一个子系统目录加上一组资源限制文件的组合。而对于Docker等Linux容器项目来说，它们只需要在每个子系统下面，为每个容器创建一个控制组（即创建一个新目录），然后在启动容器进程之后，把这个进程的PID填写到对应控制组的tasks文件中就可以了。
总结
综上所述，一个正在运行的Docker容器，其实就是一个启用了多个Linux-Namespace的应用进程，而这个进程能够使用的资源量，则受Cgroups配置的限制。
这也是容器技术中一个非常重要的概念，即：容器是一个“单进程”模型。
由于一个容器的本质就是一个进程，用户的应用进程实际上就是容器里PID=1的进程，也是其他后续创建的所有进程的父进程。这就意味着，在一个容器中，你没办法同时运行两个不同的应用，除非你能事先找到一个公共的PID=1的程序来充当两个不同应用的父进程，这也是为什么很多人都会用systemd或者supervisord这样的软件来代替应用本身作为容器的启动进程。
但是，在后面分享容器设计模式时，我还会推荐其他更好的解决办法。这是因为容器本身的设计，就是希望容器和应用能够同生命周期，这个概念对后续的容器编排非常重要。否则，一旦出现类似于“容器是正常运行的，但是里面的应用早已经挂了”的情况，编排系统处理起来就非常麻烦了。
另外，跟Namespace的情况类似，Cgroups对资源的限制能力也有很多不完善的地方，被提及最多的自然是/proc文件系统的问题。
众所周知，Linux下的/proc目录存储的是记录当前内核运行状态的一系列特殊文件，用户可以通过访问这些文件，查看系统以及当前正在运行的进程的信息，比如CPU使用情况、内存占用率等，这些文件也是top指令查看系统信息的主要数据来源。
但是，你如果在容器里执行top指令，就会发现，它显示的信息居然是宿主机的CPU和内存数据，而不是当前容器的数据。
造成这个问题的原因就是，/proc文件系统并不知道用户通过Cgroups给这个容器做了什么样的资源限制，即：/proc文件系统不了解Cgroups限制的存在。
在生产环境中，这个问题必须进行修正，否则应用程序在容器里读取到的CPU核数、可用内存等信息都是宿主机上的数据，这会给应用的运行带来非常大的困惑和风险。这也是在企业中，容器化应用碰到的一个常见问题，也是容器相较于虚拟机另一个不尽如人意的地方。

=====> chroot、pivot_root
chroot的作用是帮你“change root file system”，即改变进程的根目录到你指定的位置。
假设，我们现在有一个 $HOME/test 目录，想要把它作为一个 /bin/bash 进程的根目录。
首先，创建一个test目录和几个lib文件夹：
[root@localhost ~]# mkdir -p $HOME/test
[root@localhost ~]# mkdir -p $HOME/test/{bin,lib64,lib}
[root@localhost ~]# cd $T
然后，把bash命令拷贝到test目录对应的bin路径下：
[root@localhost ~]# cp -v /bin/{bash,ls} $HOME/test/bin
接下来，把bash命令需要的所有so文件，也拷贝到test目录对应的lib路径下。找到so文件可以用ldd命令：
[root@localhost ~]# T=$HOME/test
[root@localhost ~]# list="$(ldd /bin/ls | egrep -o '/lib.*\.[0-9]')"
[root@localhost ~]# for i in $list; do cp -v "$i" "${T}${i}"; done
最后，执行chroot命令，告诉操作系统，我们将使用$HOME/test目录作为/bin/bash 进程的根目录：
[root@localhost ~]# chroot $HOME/test /bin/bash
这时，你如果执行"ls /"，就会看到，它返回的都是$HOME/test目录下面的内容，而不是宿主机的内容。
更重要的是，对于被chroot的进程来说，它并不会感受到自己的根目录已经被“修改”成 $HOME/test了。
pivot_root的man手册
https://man7.org/linux/man-pages/man2/pivot_root.2.html
pivot_root改变当前进程所在mount namespace内的所有进程的root mount移到put_old，然后将new_root作为新的root mount；
pivot_root并没有修改当前调用进程的工作目录，通常需要使用chdir("/")来实现切换到新的root mount的根目录。
chroot只改变当前进程的“/”
pivot_root改变当前mount namespace的“/”

=====> overlay
overlay是联合文件系统（Union File System）的一种技术实现，Union File System也叫UnionFS，最主要的功能是将多个不同位置的目录联合挂载（union mount）到同一个目录下。
overlayfs通过三个目录：lower目录、upper目录、以及work目录实现，其中lower目录可以是多个，work目录为工作基础目录，挂载后内容会被清空，且在使用过程中其内容用户不可见，最后联合挂载完成给用户呈现的统一视图称为为merged目录。

mkdir -p /opt/overlay_test
cd /opt/overlay_test
mkdir -p /tmp/test A/aa B C worker
echo "from A" > A/a.txt
echo "from B" > B/b.txt
echo "from B" > B/a.txt
echo "from C" > C/c.txt
echo "from A" > A/x.txt
echo "from C" > C/x.txt
mount -t overlay overlay -o lowerdir=A:B,upperdir=C,workdir=worker /tmp/test

overlay文件系统分为lowerdir、upperdir、merged，对外统一展示为merged，
upperdir和lowerdir的同名文件会被upperdir覆盖。
lowerdir中存在同名的文件时，merged层目录会显示离它最近层的文件

overlay只支持两层，upper文件系统通常是可写的；lower文件系统则是只读，这就表示着，当我们对overlay文件系统做任何的变更，都只会修改upper文件系统中的文件。那下面看一下overlay文件系统的读，写，删除操作。
读
¬读upper没有而lower有的文件时，需从lower读；
¬读只在upper有的文件时，则直接从upper读
¬读lower和upper都有的文件时，则直接从upper读。
写
¬对只在upper有的文件时，则直接在upper写
¬对在lower和upper都有的文件时，则直接在upper写。
¬对只在lower有的文件写时，则会做一个copy_up的操作，先从lower将文件拷贝一份到upper，同时为文件创建一个硬链接。此时可以看到upper目录下生成了两个新文件，写的操作只对从lower复制到upper的文件生效，而lower还是原文件。
删
¬删除lower和upper都有的文件时，upper的会被删除，在upper目录下创建一个‘without’文件，而lower的不会被删除。
¬删除lower有而upper没有的文件时，会为被删除的文件在upper目录下创建一个‘without’文件，而lower的不会被删除。
¬删除lower和upper都有的目录时，upper的会被删除，在upper目录下创建一个类似‘without’文件的‘opaque’目录，而lower的不会被删除。
可以看到，因为lower是只读，所以无论对lower上的文件和目录做任何的操作都不会对lower做变更。所有的操作都是对在upper做。
copy_up只在第一次写时对文件做copy_up操作，后面的操作都不再需要做copy_up，都只操作这个文件，特别适合大文件的场景。overlay的copy_up操作要比AUFS相同的操作要快，因为AUFS有很多层，在穿过很多层时可能会有延迟，而overlay只有两层。而且overlay在2014年并入linux-kernel-mailline，但是aufs并没有被并入linux-kernel-mailline，所以overlay可能会比AUFS快。

=====> setns
docker exec是如何进入通过Linux Namespace机制创建的隔离空间中的
实际上，Linux Namespace创建的隔离空间虽然看不见摸不着，但一个进程的Namespace信息在宿主机上是确确实实存在的，并且是以一个文件的方式存在。
比如，通过如下指令，你可以看到当前正在运行的Docker容器的进程号（PID）是25686：
[root@server01 opt]# docker inspect --format '{{ .State.Pid }}' 625e8df55f45
1262
这时，你可以通过查看宿主机的 proc 文件，看到这个 25686 进程的所有 Namespace 对应的文件：
[root@server01 opt]# ls -l /proc/1262/ns
总用量 0
lrwxrwxrwx 1 root root 0 1月  18 13:17 ipc -> ipc:[4026532192]
lrwxrwxrwx 1 root root 0 1月  18 13:17 mnt -> mnt:[4026532190]
lrwxrwxrwx 1 root root 0 1月  18 12:49 net -> net:[4026532195]
lrwxrwxrwx 1 root root 0 1月  18 13:17 pid -> pid:[4026532193]
lrwxrwxrwx 1 root root 0 1月  18 13:17 user -> user:[4026531837]
lrwxrwxrwx 1 root root 0 1月  18 13:17 uts -> uts:[4026532191]
可以看到，一个进程的每种Linux Namespace，都在它对应的/proc/[进程号]/ns下有一个对应的虚拟文件，并且链接到一个真实的Namespace文件上。
有了这样一个可以“hold住”所有Linux Namespace的文件，我们就可以对Namespace做一些很有意义事情了，比如：加入到一个已经存在的Namespace当中。
这也就意味着：一个进程，可以选择加入到某个进程已有的Namespace当中，从而达到“进入”这个进程所在容器的目的，这正是docker exec的实现原理。
而这个操作所依赖的，乃是一个名叫 setns()的Linux系统调用。它的调用方法，可以用如下一段小程序来说明：
#define _GNU_SOURCE
#include <fcntl.h>
#include <sched.h>
#include <unistd.h>
#include <stdlib.h>
#include <stdio.h>

#define errExit(msg) do { perror(msg); exit(EXIT_FAILURE);} while (0)

int main(int argc, char *argv[]) {
    int fd;
    fd = open(argv[1], O_RDONLY);
    if (setns(fd, 0) == -1) {
        errExit("setns");
    }
    execvp(argv[2], &argv[2]); 
    errExit("execvp");
}
这段代码功能非常简单：它一共接收两个参数，第一个参数是argv[1]，即当前进程要加入的Namespace文件的路径，比如/proc/1262/ns/net；而第二个参数，则是你要在这个Namespace里运行的进程，比如/bin/bash。
这段代码的核心操作，则是通过open()系统调用打开了指定的Namespace文件，并把这个文件的描述符fd交给setns()使用。在setns()执行后，当前进程就加入了这个文件对应的Linux Namespace当中了。
现在，可以编译执行一下这个程序，加入到容器进程（PID=1262）的Network Namespace中：
[root@server01 opt]# gcc -o dockerExec dockerExec.c
[root@server01 opt]# ./dockerExec /proc/1262/ns/net /bin/bash
[root@server01 opt]# ifconfig
eth0: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1500
        inet 172.17.0.2  netmask 255.255.0.0  broadcast 172.17.255.255
        ether 02:42:ac:11:00:02  txqueuelen 0  (Ethernet)
        RX packets 16  bytes 1296 (1.2 KiB)
        RX errors 0  dropped 0  overruns 0  frame 0
        TX packets 0  bytes 0 (0.0 B)
        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0

lo: flags=73<UP,LOOPBACK,RUNNING>  mtu 65536
        inet 127.0.0.1  netmask 255.0.0.0
        loop  txqueuelen 1  (Local Loopback)
        RX packets 0  bytes 0 (0.0 B)
        RX errors 0  dropped 0  overruns 0  frame 0
        TX packets 0  bytes 0 (0.0 B)
        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0
如上所示，当执行ifconfig命令查看网络设备时，会发现能看到的网卡“变少”了：只有两个。而我的宿主机则至少有四个网卡。这是怎么回事呢？
实际上，在setns()之后我看到的这两个网卡，正是我在前面启动的Docker容器里的网卡。也就是说，我新创建的这个/bin/bash进程，由于加入了该容器进程（PID=1262）的Network Namepace，它看到的网络设备与这个容器里是一样的，即：/bin/bash进程的网络设备视图，也被修改了。

=====> Volume
Docker Volume要解决的问题：Volume机制，允许你将宿主机上指定的目录或者文件，挂载到容器里面进行读取和修改操作。
那么，Docker又是如何做到把一个宿主机上的目录或者文件，挂载到容器里面去呢？难道又是Mount Namespace的黑科技吗？实际上，并不需要这么麻烦。
当容器进程被创建之后，尽管开启了Mount-Namespace，但是在它执行chroot（或者pivot_root）之前，容器进程一直可以看到宿主机上的整个文件系统。而宿主机上的文件系统，也自然包括了我们要使用的容器镜像。这个镜像的只读层保存在LowerDir目录下，在容器进程启动后，它和可写层UpperDir联合挂载在MergedDir目录中，这样容器所需的rootfs就准备好了。
所以，只需要在rootfs准备好之后，在执行pivot_root之前，把Volume指定的宿主机目录（比如/home目录），挂载到指定的容器目录（比如/test目录）在宿主机上对应的目录（即：可写层UpperDir/test）上，这个Volume的挂载工作就完成了。
更重要的是，由于执行这个挂载操作时，“容器进程”已经创建了，也就意味着此时Mount-Namespace已经开启了。所以，这个挂载事件只在这个容器里可见。你在宿主机上，是看不见容器内部的这个挂载点的。这就保证了容器的隔离性不会被Volume打破。
注意：这里提到的"容器进程"，是Docker创建的一个容器初始化进程(dockerinit)，而不是应用进程(ENTRYPOINT+CMD)。dockerinit会负责完成根目录的准备、挂载设备和目录、配置hostname等一系列需要在容器内进行的初始化操作。最后，它通过execv()系统调用，让应用进程取代自己，成为容器里的PID=1的进程。
而这里要使用到的挂载技术，就是Linux的绑定挂载（bind-mount）机制。它的主要作用就是，允许你将一个目录或者文件，而不是整个设备，挂载到一个指定的目录上。并且，这时你在该挂载点上进行的任何操作，只是发生在被挂载的目录或者文件上，而原挂载点的内容则会被隐藏起来且不受影响。
其实，如果你了解Linux内核的话，就会明白，绑定挂载实际上是一个inode替换的过程。在Linux操作系统中，inode可以理解为存放文件内容的“对象”，而dentry，也叫目录项，就是访问这个inode所使用的“指针”。
mount -- bind /home /test
会将/home挂载到/test上。其实相当于将/test的dentry，重定向到了/home的inode。这样当我们修改/test目录时，实际修改的是/home目录的inode。这也就是为何，一旦执行umount命令，/test目录原先的内容就会恢复：因为修改真正发生在的，是/home目录里。
所以，在一个正确的时机，进行一次绑定挂载，Docker就可以成功地将一个宿主机上的目录或文件，不动声色地挂载到容器中。
这样，进程在容器里对这个/test目录进行的所有操作，都实际发生在宿主机的对应目录（比如，/home）里，而不会影响容器镜像的内容。
这个/test目录里的内容，虽然挂载在容器rootfs的可读写层，但是不会被dockercommit提交掉。
这个原因其实我们前面已经提到过。容器的镜像操作，比如docker-commit，都是发生在宿主机空间的。而由于Mount-Namespace的隔离作用，宿主机并不知道这个绑定挂载的存在。所以，在宿主机看来，容器中可读写层的/UpperDir/test目录，始终是空的。不过，由于Docker一开始还是要创建/UpperDir/test这个目录作为挂载点，所以执行了docker-commit之后，你会发现新产生的镜像里，会多出来一个空的/UpperDir/test目录。毕竟，新建目录操作，又不是挂载操作，Mount-Namespace对它可起不到“障眼法”的作用。

>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>模拟一个简单的docker容器创建过程<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
#define _GNU_SOURCE
#include <sys/mount.h> 
#include <sys/types.h>
#include <sys/wait.h>
#include <sys/syscall.h>
#include <sys/stat.h>
#include <sys/mman.h>
#include <stdio.h>
#include <sched.h>
#include <signal.h>
#include <unistd.h>
#include<stdlib.h>
#include <limits.h>
#define STACK_SIZE (1024 * 1024)
#define errExit(msg)    do { perror(msg); exit(EXIT_FAILURE); \
                               } while (0)

static char container_stack[STACK_SIZE];
char* const container_args[] = {
  "/bin/bash",
  NULL
};
char* const mount_args[] = {
  "mount",
  "-t",
  "overlay",
  "overlay",
  "-o",
  "lowerdir=/var/lib/docker/overlay2/20f04012d6a965fb7a9ce094caa18138596743a96be3a99299e27aeec133efc1-init/diff:/var/lib/docker/overlay2/05f27cb6334067dcc7de438d938206dece782bec26279b378241b1d81a93fde7/diff,upperdir=/opt/DockerRuntime,workdir=/opt/DockerWorker",
  "/opt/DockerTmp",
  NULL
};

static int pivot_root(const char *new_root, const char *put_old)
{
    return syscall(SYS_pivot_root, new_root, put_old);
}
int container_main(void *arg)
{  
  printf("Container - inside the container!\n");
  //通过pivot_root改变当前mount namespace的“/”
  char ** args = arg;
  char * new_root = args[0];
  char * put_old = args[1];
  char path[PATH_MAX];
  /* Ensure that 'new_root' and its parent mount don't have
     shared propagation (which would cause pivot_root() to
     return an error), and prevent propagation of mount
     events to the initial mount namespace */
  if (mount(NULL, "/", NULL, MS_REC | MS_PRIVATE, NULL) == -1)
      errExit("mount-MS_PRIVATE");
  /* Ensure that 'new_root' is a mount point */
  if (mount(new_root, new_root, NULL, MS_BIND, NULL) == -1)
      errExit("mount-MS_BIND");
  /* Create directory to which old root will be pivoted */
  snprintf(path, sizeof(path), "%s/%s", new_root, put_old);
  if (mkdir(path, 0777) == -1)
      errExit("mkdir");
  /* And pivot the root filesystem */
  if (pivot_root(new_root, path) == -1)
      errExit("pivot_root");
  /* Switch the current working directory to "/" */
  if (chdir("/") == -1)
      errExit("chdir");
  if (mount("proc", "/proc", "proc", 0, NULL) == -1)
      errExit("mount proc");
  /* Unmount old root and remove mount point */
  if (umount2(put_old, MNT_DETACH) == -1)
      perror("umount2");
  if (rmdir(put_old) == -1)
      perror("rmdir");
  execv(container_args[0], container_args);
  printf("Something's wrong!\n");
  return 1;
}

int main()
{
  printf("Parent - start a container!\n");
  //execv("/usr/bin/mount", mount_args);
  //通过联合挂载将镜像层（只读）和容器层（可写）合并成一个新的根文件系统目录，然后再通过pivot_root改变当前mount namespace的“/”
  system("mount -t overlay overlay -o lowerdir=/var/lib/docker/overlay2/20f04012d6a965fb7a9ce094caa18138596743a96be3a99299e27aeec133efc1-init/diff:/var/lib/docker/overlay2/05f27cb6334067dcc7de438d938206dece782bec26279b378241b1d81a93fde7/diff,upperdir=/opt/DockerRuntime,workdir=/opt/DockerWorker /opt/DockerTmp");
  char *argv[] = {"/opt/DockerTmp","/oldrootfs"};
  //通过clone fork新的子进程的时候加入各种namespace参数来进行隔离
  int container_pid = clone(container_main, container_stack+STACK_SIZE, CLONE_NEWNS | CLONE_NEWPID | CLONE_NEWUSER | SIGCHLD, &argv);
  printf("Container - pid = %d \n" ,container_pid);
  waitpid(container_pid, NULL, 0);
  printf("Parent - container stopped!\n");
  return 0;
}
编译并运行程序：
[root@server01 opt]# gcc -o ns ns.c
[root@server01 opt]# ./ns
Parent - start a container!
Container - pid = 1660
Container - inside the container!
/usr/bin/id: cannot find name for group ID 65534
/usr/bin/id: cannot find name for user ID 65534
[I have no name!@server01 /]$
使用top命令查看运行的进程：
top - 11:53:11 up  1:38,  0 users,  load average: 0.00, 0.01, 0.05
Tasks:   2 total,   1 running,   1 sleeping,   0 stopped,   0 zombie
%Cpu(s):  0.0 us,  0.0 sy,  0.0 ni,100.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st
KiB Mem :  2048668 total,  1485900 free,   302184 used,   260584 buff/cache
KiB Swap:  1952764 total,  1952764 free,        0 used.  1595692 avail Mem

  PID USER      PR  NI    VIRT    RES    SHR S %CPU %MEM     TIME+ COMMAND
    1 65534     20   0   15248   1908   1484 S  0.0  0.1   0:00.00 bash
   14 65534     20   0   59596   1980   1448 R  0.0  0.1   0:00.00 top
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>模拟一个简单的docker容器创建过程<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
注意：
在CentOS内核3.8或更高版本中，添加了user-namespaces（户名命名空间）功能。但是，该功能默认情况下是禁用的，原因是RedHat希望该功能在社区中孵化更长时间，以确保该功能的稳定性和安全性。
配置CentOS-7系统启用user-namespaces：
# kernel 设置
[root@localhost ~]# grubby --args="user_namespace.enable=1" --update-kernel="$(grubby --default-kernel)"
# 重启
[root@localhost ~]# reboot
如需关闭user-namespace ，使用如下命令：
[root@localhost ~]# grubby --remove-args="user_namespace.enable=1" --update-kernel="$(grubby --default-kernel)"

配置系统max_user_namespaces
临时配置，重启会失效，可用作临时验证：
# 查看系统 user namespaces 最大为 0
[root@localhost ~]# cat /proc/sys/user/max_user_namespaces
0
# 临时开启 user namespace ，向文件内写入一个整数。
[root@localhost ~]# echo 10000 > /proc/sys/user/max_user_namespaces
永久配置
# 写入配置文件
[root@localhost ~]# echo "user.max_user_namespaces=10000" >> /etc/sysctl.conf
# 重启
[root@localhost ~]# reboot
########################################################容器技术概念########################################################

########################################################Dockerfile########################################################
FROM 基于哪个镜像

MAINTAINER 镜像创建者

COPY 格式为 COPY <src> <dest> 。
复制本地主机的 <src> （为Dockerfile所在目录的相对路径）到容器中的 <dest>（如果目标路径不存在，则会自动创建目标路径）
从上面的定义中可获知，src可以是Dockerfile所在目录的一个相对路径，但在实际操作中，只有与Dockerfile文件在同一目录的文件或目录可以成功的使用ADD <src> <dest>，如：（ADD ./test /data/code/nginx）
如果文件或目录不与Dockerfile在同一目录会提示 no such file or directory，如：（ADD ../test2 /data/code/nginx），从Dockerfile所在目录通过 cd ../test2可以到达test2

WORKDIR 切换目录用，可以多次切换(相当于cd命令)，对RUN,CMD,ENTRYPOINT生效

RUN 安装软件用
构建指令，RUN可以运行任何被基础image支持的命令。如基础image选择了ubuntu，那么软件管理部分只能使用ubuntu的命令。
该指令有两种格式：
RUN <command> (the command is run in a shell - `/bin/sh -c`)  
RUN ["executable", "param1", "param2" ... ]  (exec form) 

CMD 设置container启动时执行的操作
设置指令，用于container启动时指定的操作。该操作可以是执行自定义脚本，也可以是执行系统命令。该指令只能在文件中存在一次，如果有多个，则只执行最后一条。
该指令有三种格式
CMD ["executable","param1","param2"] (like an exec, this is the preferred form)  
CMD command param1 param2 (as a shell)  
当Dockerfile指定了ENTRYPOINT，那么使用下面的格式：
CMD ["param1","param2"] (as default parameters to ENTRYPOINT) 
ENTRYPOINT指定的是一个可执行的脚本或者程序的路径，该指定的脚本或者程序将会以param1和param2作为参数执行。所以如果CMD指令使用上面的形式，那么Dockerfile中必须要有配套的ENTRYPOINT。

ENTRYPOINT 设置container启动时执行的操作
设置指令，指定容器启动时执行的命令，可以多次设置，但是只有最后一个有效。
两种格式:
ENTRYPOINT ["executable", "param1", "param2"] (like an exec, the preferred form)  
ENTRYPOINT command param1 param2 (as a shell)  
该指令的使用分为两种情况，一种是独自使用，另一种和CMD指令配合使用。
当独自使用时，如果你还使用了CMD命令且CMD是一个完整的可执行的命令，那么CMD指令和ENTRYPOINT会互相覆盖只有最后一个CMD或者ENTRYPOINT有效。
# CMD指令将不会被执行，只有ENTRYPOINT指令被执行  
CMD echo "Hello, World!"  
ENTRYPOINT ls -l  
另一种用法和CMD指令配合使用来指定ENTRYPOINT的默认参数，这时CMD指令不是一个完整的可执行命令，仅仅是参数部分；ENTRYPOINT指令只能使用JSON方式指定执行命令，而不能指定参数。
FROM ubuntu  
CMD ["-l"]  
ENTRYPOINT ["/usr/bin/ls"]
########################################################Dockerfile########################################################

########################################################Docker容器使用########################################################
运行一个web应用
docker run -d -P training/webapp python app.py
参数说明:
-d:让容器在后台运行。
-P:将容器内部使用的网络端口映射到我们使用的主机上
使用 docker ps 来查看我们正在运行的容器
docker ps
这里多了端口信息。
PORTS
0.0.0.0:32769->5000/tcp
Docker 开放了 5000 端口（默认 Python Flask 端口）映射到主机端口 32769 上。
我们也可以通过 -p 参数来设置不一样的端口：
docker run -d -p ip:hostPort:containerPort training/webapp python app.py
使用-p参数  会分配宿主机的端口映射到虚拟机。 
IP表示主机的IP地址。
hostPort表示宿主机的端口。
containerPort表示虚拟机的端口。
支持的格式有三种：
ip:hostPort:containerPort：映射指定地址的指定端口到虚拟机的指定端口（不常用） 
如：127.0.0.1:3306:3306，映射本机的3306端口到虚拟机的3306端口。 
ip::containerPort：映射指定地址的任意端口到虚拟机的指定端口。（不常用） 
如：127.0.0.1::3306，映射本机的3306端口到虚拟机的3306端口。 
hostPort:containerPort：映射本机的指定端口到虚拟机的指定端口。（常用） 
如：3306:3306，映射本机的3306端口到虚拟机的3306端口。

Format 格式化显示
如果想自定义显示容器字段，可以用格式化选项 --format 。
基于 Go template（https://golang.org/pkg/html/template/）语法，可用的占位符如下：
占位符        描述
.ID           Container ID
.Image        Image ID
.Command      Quoted command
.CreatedAt    Time when the container was created
.RunningFor   Elapsed time since the container war started
.Ports        Exposed ports
.Status       Container status
.Size         Container disk size
.Names        Container names
.Labels       All labels assigned to the container
.Label        Value of a specific label for this container  For example'{{.Label "com.docker.swarm.cpu"}}'
.Mounts       Names of the volumes mounted in this container
.Networks     Names of the networks attached to this container     
1. 当使用了 --format 选项，那么 ps 命令只会输出 template 中指定的内容：
$ docker ps --format "{{.ID}}: {{.Command}}"
2. 如果想带上表格列头，需要再 template 中加上 table 指令
$ docker ps --format "table {{.ID}}: {{.Command}}"

docker run -d -p 5000:5000 training/webapp python app.py
docker ps查看正在运行的容器
容器内部的 5000 端口映射到我们本地主机的 5000 端口上。
-P和-p两种方式的区别是:
    -P :是容器内部端口随机映射到主机的端口。
    -p :是容器内部端口绑定到指定的主机端口。

网络端口的快捷方式
通过docker ps 命令可以查看到容器的端口映射，docker还提供了另一个快捷方式：docker port,使用 docker port 可以查看指定 （ID或者名字）容器的某个确定端口映射到宿主机的端口号。
上面我们创建的web应用容器ID为:7a38a1ad55c6 名字为：determined_swanson
可以使用docker port 7a38a1ad55c6 或docker port determined_swanson来查看容器端口的映射情况
runoob@runoob:~$ docker port 7a38a1ad55c6
5000/tcp -> 0.0.0.0:5000
runoob@runoob:~$ docker port determined_swanson
5000/tcp -> 0.0.0.0:5000
可是使用docker port adoring_stonebraker 5000来查看容器端口映射到的是哪个宿主机端口
runoob@runoob:~$ docker port adoring_stonebraker 5000
127.0.0.1:5001

docker: 为运行的container增加多个端口
docker run -p 8080:8080 -p 80:80 -td test02

docker run ubuntu:15.10 /bin/echo "Hello world"
各个参数解析：
docker: Docker 的二进制执行文件。
run:与前面的 docker 组合来运行一个容器。
ubuntu:15.10指定要运行的镜像，Docker首先从本地主机上查找镜像是否存在，如果不存在，Docker 就会从镜像仓库 Docker Hub 下载公共镜像。
/bin/echo "Hello world": 在启动的容器里执行的命
以上命令完整的意思可以解释为：Docker 以 ubuntu15.10 镜像创建一个新容器，然后在容器里执行 bin/echo "Hello world"，然后输出结果。

运行交互式的容器
我们通过docker的两个参数 -i -t，让docker运行的容器实现"对话"的能力
docker run -i -t ubuntu:15.10 /bin/bash
各个参数解析：
-t:在新容器内指定一个伪终端或终端。
-i:允许你对容器内的标准输入 (STDIN) 进行交互

启动容器（后台模式）
使用以下命令创建一个以进程方式运行的容器
docker run -d ubuntu:15.10 /bin/sh -c "while true; do echo hello world; sleep 1; done"
在输出中，我们没有看到期望的"hello world"，而是一串长字符
2b1b7a428627c51ab8810d541d759f072b4fc75487eed05812646b8534a2fe63
这个长字符串叫做容器ID，对每个容器来说都是唯一的，我们可以通过容器ID来查看对应的容器发生了什么。
首先，我们需要确认容器有在运行，可以通过 docker ps 来查看
docker ps
CONTAINER ID:容器ID
NAMES:自动分配的容器名称
在容器内使用docker logs命令，查看容器内的标准输出
docker logs 2b1b7a428627

退出容器
如果使用exit，命令退出，则容器的状态处于Exit，而不是后台运行。如果想让容器一直运行，而不是停止，可以使用快捷键 ctrl+p ctrl+q 退出，此时容器的状态为Up。
看到当前有一个ID为aa97ba3292ce的容器
启动、停止、重启容器aa97ba3292ce的命令：
~$ docker start aa97ba3292ce
~$ docker stop aa97ba3292ce
~$ docker restart aa97ba3292ce
后台启动一个容器后，如果想进入到这个容器，可以使用attach或者exec命令：
~$ docker attach aa97ba3292ce
~$ docker exec -it 775c7c9ee1e1 /bin/bash
两种方式的区别
docker attach方式进入的话。当多个窗口同时使用该命令进入该容器时，所有的窗口都会同步显示。如果有一个窗口阻塞了，那么其他窗口也无法再进行操作。
docker attach方式进入的话。如果从这个stdin中exit，会导致容器的停止。

删除容器或者镜像
如果想删除容器或者镜像，可以使用rm命令，注意：删除镜像前必须先删除以此镜像为基础的容器（哪怕是已经停止的容器），否则无法删除该镜像，会报错Failed to remove image (e4415b714b62): Error response from daemon: conflict: unable to delete e4415b714b62 (cannot be forced) - image has dependent child images类似这种
~$ docker rm container_id
~$ docker rmi image_id
有的时候尽管删除了全部容器，镜像还是无法删除，这时点击mac顶栏中的docker logo，选择restart，然后再试一次rmi，应该就没问题了。

列出所有的容器 ID
docker ps -aq

停止所有的容器
docker stop $(docker ps -aq)

删除所有的容器
docker rm $(docker ps -aq)

删除所有的镜像
docker rmi $(docker images -q)
########################################################Docker容器使用########################################################

#########################################################Docker 镜像使用#######################################################
创建镜像
当我们从docker镜像仓库中下载的镜像不能满足我们的需求时，我们可以通过以下两种方式对镜像进行更改。
1.从已经创建的容器中更新镜像，并且提交这个镜像
2.使用 Dockerfile 指令来创建一个新的镜像
更新镜像
更新镜像之前，我们需要使用镜像来创建一个容器。 
runoob@runoob:~$ docker run -t -i ubuntu:15.10 /bin/bash
root@e218edb10161:/# 
在运行的容器内使用 apt-get update 命令进行更新。在完成操作之后，输入 exit命令来退出这个容器。
此时ID为e218edb10161的容器，是按我们的需求更改的容器。我们可以通过命令 docker commit来提交容器副本。
runoob@runoob:~$ docker commit -m="has update" -a="runoob" e218edb10161 runoob/ubuntu:v2
sha256:70bf1840fd7c0d2d8ef0a42a817eb29f854c1af8f7c59fc03ac7bdee9545aff8
各个参数说明：
    -m:提交的描述信息
    -a:指定镜像作者
    e218edb10161：容器ID
    runoob/ubuntu:v2:指定要创建的目标镜像名

构建镜像
我们使用命令 docker build ， 从零开始来创建一个新的镜像。为此，我们需要创建一个 Dockerfile 文件，其中包含一组指令来告诉 Docker 如何构建我们的镜像。
runoob@runoob:~$ cat Dockerfile 
FROM    centos:6.7
MAINTAINER      Fisher "fisher@sudops.com"

RUN     /bin/echo 'root:123456' |chpasswd
RUN     useradd runoob
RUN     /bin/echo 'runoob:123456' |chpasswd
RUN     /bin/echo -e "LANG=\"en_US.UTF-8\"" >/etc/default/local
EXPOSE  22
EXPOSE  80
CMD     /usr/sbin/sshd -D
每一个指令都会在镜像上创建一个新的层，每一个指令的前缀都必须是大写的。第一条FROM，指定使用哪个镜像源；RUN 指令告诉docker 在镜像内执行命令，安装了什么。。。
然后，我们使用 Dockerfile 文件，通过 docker build 命令来构建一个镜像。
使用本地目录的Dockerfile创建镜像。
--file, -f，Dockerfile的完整路径
--tag, -t，镜像的名字及tag，通常name:tag或者name格式；可以在一次构建中为一个镜像设置多个tag
docker build -t composetest3:latest -f /home/composetest_3/Dockerfile /home/composetest_3/

使用URL github.com/creack/docker-firefox 的 Dockerfile 创建镜像。
docker build github.com/creack/docker-firefox
runoob@runoob:~$ docker build -t runoob/centos:6.7 .
Sending build context to Docker daemon 17.92 kB
Step 1 : FROM centos:6.7
 ---&gt; d95b5ca17cc3
Step 2 : MAINTAINER Fisher "fisher@sudops.com"
 ---&gt; Using cache
 ---&gt; 0c92299c6f03
Step 3 : RUN /bin/echo 'root:123456' |chpasswd
 ---&gt; Using cache
 ---&gt; 0397ce2fbd0a
Step 4 : RUN useradd runoob
......
参数说明：
-t ：指定要创建的目标镜像名
.  ：环境目录（.表示当前目录）
docker build需要传入一个目录作为参数，这个目录是docker build的context，也就是在构建过程中的环境目录，对于ADD一类命令在使用相对的宿主机目录时，都是以此目录为基准的。
如果我们没有传入-f去定义Dockerfile的位置，也会默认在这个目录中查询。但并不是传入了-f，就能省略这个定义环境目录参数的。

设置镜像标签
使用 docker tag 命令，为镜像添加一个新的标签
runoob@runoob:~$ docker tag 860c279d2fec runoob/centos:dev
docker tag 镜像ID，这里是 860c279d2fec ,用户名称、镜像源名(repository name)和新的标签名(tag)。


保存镜像为文件
docker save -o 要保存的文件名 要保存的镜像
docker save -o centos.tar mycentos:dev
从文件载入镜像
docker load < 文件名

docker rmi报错Error response from daemon
ocker commit了一个镜像之后想删除旧的镜像，出现以下报错
Error response from daemon: conflict: unable to delete 6f8214d56bfc (cannot be forced) - image has dependent child images
解决思路：
docker save -o 要保存的文件名 要保存的镜像
docker images
docker save REPOSITORY > XX.tar
删除镜像容器
docker ps -a
docker rm CONTAINER ID
docker images
docker rmi IMAGE ID
最后再导入回去
docker load < XX.tar
#########################################################Docker 镜像使用#######################################################

###############################################Docker NetWork###############################################
当你安装Docker后，它会自动创建三个network，你可以使用命令：docker network ls 列出它们：
从历史上看，这三个network是Docker实现的一部分。当你运行一个container时，你可以用--net标志去指定这个container运行在哪一种network上。这三种network你都可以使用。

这个bridge network 代表所有安装了Docker的主机的docker0 network。除非使用docker run --set=<NETWORK>选项指定一个其它的network，否则Docker daemon会默认使用这个network连接contrainer。你可以使用系统的ifconfig命令查看主机的network stack中的docker0

这个nonenetwork 会将容器添加到一个 container-specific 的 network stack。这个容器缺少一个network interface。如果你想连接这个容器并查看它的stack，你可以这样：
docker attach nonenetcontainer

这个hostnetwork，将container添加到主机的network stack。你会发现这个container的网络配置与主机是一致的。
除了bridgenetwork，你可能不需要其他的默认network。虽然你可以列出并查看这些network，但是你不能删除它们。这些是Docker所需要的。然而你可以添加属于你的自定义network，当你不再需要这些network的时候你可以删除它们。在你了解更多关于创建属于你自己的network之前，默认的bridgenetwork还是值得你看看的。

brigde network
这个默认的bridgenetwork存在于所有的Docker主机。docker network inspect命令可以返回关于network的信息：
docker network inspect bridge
Docker Engine 会自动创建一个 Subnet和Gateway在这个network。docker run命令自动添加一个新的container到这个network：
在启动两个新的container之后，查看一下bridge网络。这两个容器的id会出现在 Containers这个字段中：

上面是 docker network inspect命令根据给定的network回显的这个network已连接的容器和它的一些网络资源。在这个默认的network中的container可以利用IP地址相互通信。在默认的bridgenetwork中Docker不支持自动的服务发现。如果你的container想要通过其他container的name在这个默认的bridgenetwork中通行，你必须通过docker run --linke选项来实现。

###############################################Docker NetWork###############################################

###############################################Docker 配置HTTP、HTTPS代理服务器###############################################
1 创建目录
mkdir -p /etc/systemd/system/docker.service.d
================================HTTP代理================================
2.1 创建文件/etc/systemd/system/docker.service.d/http-proxy.conf，内容如下：
[Service]
Environment="HTTP_PROXY=127.0.0.1:8118/" "NO_PROXY=localhost,172.16.0.0/16,192.168.0.0/16.,127.0.0.1,10.10.0.0/16"
================================HTTP代理================================
================================HTTPS代理================================
2.2 创建文件/etc/systemd/system/docker.service.d/https-proxy.conf，内容如下：
[Service]
Environment="HTTPS_PROXY=127.0.0.1:8118/" "NO_PROXY=localhost,172.16.0.0/16,192.168.0.0/16.,127.0.0.1,10.10.0.0/16"
================================HTTPS代理================================
3 重启docker
systemctl daemon-reload
systemctl restart docker
4 验证docker代理是否设置成功
systemctl show --property=Environment docker　　
显示如下结果说明设置成功
Environment=HTTP_PROXY=127.0.0.1:8118/ NO_PROXY=localhost,172.16.0.0/16,192.168.0.0/16.,127.0.0.1,10.10.0.0/16 HTTPS_PROXY=127.0.0.1:8118/

###############################################Docker 配置HTTP代理服务器###############################################

###############################################Get started with Docker Compose###############################################
https://docs.docker.com/compose/gettingstarted/
https://www.cnblogs.com/52fhy/p/5991344.html

docker-compose.yml
每个docker-compose.yml必须定义image或者build中的一个，其它的是可选的。
image
指定镜像tag或者ID。示例：
image: redis
image: ubuntu:14.04
image: tutum/influxdb
image: example-registry.com:4000/postgresql
image: a4bc65fd
注意，在version 1里同时使用image和build是不允许的，version 2则可以，如果同时指定了两者，会将build出来的镜像打上名为image标签。
build
用来指定一个包含Dockerfile文件的路径。一般是当前目录.。Fig将build并生成一个随机命名的镜像。
注意，在version 1里bulid仅支持值为字符串。version 2里支持对象格式。
build: ./dir
# build后可直接接Dockerfile所在目录，该目录必须存在Dockerfile

build:
  #指定Dockerfile所在的目录
  context: ./dir
  #当Dockerfile文件名不是默认名称时，使用dockerfile参数指定Dockerfile的文件名
  dockerfile: Dockerfile-alternate
  args:
    buildno: 1
context为路径，dockerfile为需要替换默认docker-compose的文件名，args为构建(build)过程中的环境变量，用于替换Dockerfile里定义的ARG参数，容器中不可用。

container_name
Compose 的容器名称格式是：<项目名称><服务名称><序号>
虽然可以自定义项目名称、服务名称，但是如果你想完全控制容器的命名，可以使用这个标签指定：
container_name: app
这样容器的名字就指定为 app 了。

depends_on
在使用Compose时，最大的好处就是少打启动命令，但是一般项目容器启动的顺序是有要求的，如果直接从上到下启动容器，必然会因为容器依赖问题而启动失败。例如在没启动数据库容器的时候启动了应用容器，这时候应用容器会因为找不到数据库而退出，为了避免这种情况我们需要加入一个标签，就是 depends_on，这个标签解决了容器的依赖、启动先后的问题。
例如下面容器会先启动 redis 和 db 两个服务，最后才启动 web 服务：
version: '2'
services:
  web:
    build: .
    depends_on:
      - db
      - redis
  redis:
    image: redis
  db:
    image: postgres
注意的是，默认情况下使用 docker-compose up web 这样的方式启动 web 服务时，也会启动 redis 和 db 两个服务，因为在配置文件中定义了依赖关系。

links
depends_on标签解决的是启动顺序问题，这个标签解决的是容器连接问题，与Docker client的--link一样效果，会连接到其它服务中的容器。
格式如下：
links:
 - db
 - db:database
 - redis
使用的别名将会自动在服务容器中的/etc/hosts里创建。（links解决的是服务之间通过别名可以进行相互通信）例如： 
172.12.2.186  db
172.12.2.186  database
172.12.2.187  redis
相应的环境变量也将被创建。
例如：
同一个宿主机上的多个docker容器之间如果想进行通信，可以通过使用容器的ip地址来通信，也可以通过宿主机的ip加上容器暴露出的端口号来通信，前者会导致ip地址的硬编码，不方便迁移，并且容器重启后ip地址会改变，除非使用固定的ip，后者的通信方式比较单一，只能依靠监听在暴露出的端口的进程来进行有限的通信。通过docker的link机制可以通过一个name来和另一个容器通信，link机制方便了容器去发现其它的容器并且可以安全的传递一些连接信息给其它的容器。其使用方式如下:
1.运行一个容器,通过–name指定一个便于记忆的名字,这个容器被称为source container，也就是要连接的容器
docker run --name db -e MYSQL_ROOT_PASSWORD=server -d mysql
上面通过传递环境变量MYSQL_ROOT_PASSWORD=server，来设置mysql服务的密码为server
2.运行另外一个容器，并link到上面启动的容器，这个容器被称为received container
sudo docker run -d --name web --link db:aliasdb nginx
上面通过--link连接名为db的容器，并为其设置了别名aliasdb 
完成了上面的两个步骤后，在nginx的容器中就可以使用db或者aliasdb作为连接地址来连接mysql服务，即使容器重启了，地址发生了变化，不会影响两个容器之间的连接。

networks
加入指定网络，格式如下：
services:
  some-service:
    networks:
     - some-network
     - other-network
关于这个标签还有一个特别的子标签aliases，这是一个用来设置服务别名的标签，例如：
services:
  some-service:
    networks:
      some-network:
        aliases:
         - alias1
         - alias3
      other-network:
        aliases:
         - alias2
相同的服务可以在不同的网络有不同的别名。

示例：
Dockerfile:

ARG buildno
ARG password

RUN echo "Build number: $buildno"
RUN script-requiring-password.sh "$password"

docker-compose.yml:
build:
  context: .
  args:
    buildno: 1
    password: secret
build:
  context: .
  args:
    - buildno=1
    - password=secret

docker-compose -f /home/composetest_2/docker-compose.yml build
docker-compose -f /home/composetest_2/docker-compose.yml run web /bin/bash

Docker-compose命令详解
Define and run multi-container applications with Docker.

Usage:
  docker-compose [-f=<arg>...] [options] [COMMAND] [ARGS...]
  docker-compose -h|--help

Options:
  -f, --file FILE             Specify an alternate compose file (default: docker-compose.yml)
  -p, --project-name NAME     Specify an alternate project name (default: directory name)
  --verbose                   Show more output
  -v, --version               Print version and exit
  -H, --host HOST             Daemon socket to connect to

  --tls                       Use TLS; implied by --tlsverify
  --tlscacert CA_PATH         Trust certs signed only by this CA
  --tlscert CLIENT_CERT_PATH  Path to TLS certificate file
  --tlskey TLS_KEY_PATH       Path to TLS key file
  --tlsverify                 Use TLS and verify the remote
  --skip-hostname-check       Don't check the daemon's hostname against the name specified
                              in the client certificate (for example if your docker host
                              is an IP address)

Commands:
  build              Build or rebuild services
  config             Validate and view the compose file
  create             Create services
  down               Stop and remove containers, networks, images, and volumes
  events             Receive real time events from containers
  help               Get help on a command
  kill               Kill containers
  logs               View output from containers
  pause              Pause services
  port               Print the public port for a port binding
  ps                 List containers
  pull               Pulls service images
  restart            Restart services
  rm                 Remove stopped containers
  run                Run a one-off command
  scale              Set number of containers for a service
  start              Start services
  stop               Stop services
  unpause            Unpause services
  up                 Create and start containers
  version            Show the Docker-Compose version information
  
-f   指定docker-compose.xml文件，默认是 docker-compose.xml  ，  当一条命令有多个-f参数时，会做替换操作
-p  指定docker-compose的项目目录，也就是docker-compose.xml文件的存储目录
###############################################Get started with Docker Compose###############################################

##################################################dockerfile 中 ARG与ENV的区别################################################
ARG只是在build构建过程中使用，构建完成后，变量将会消失和ENV有着明显的区别
ARG标签的变量仅用在构建过程中。而environment和Dockerfile中的ENV指令一样会把变量一直保存在镜像、容器中，类似 docker run -e 的效果。
https://docs.docker.com/compose/environment-variables/

The ARG instruction defines a variable that users can pass at build-time to the builder with the docker build command using the --build-arg <varname>=<value> flag.ARG指令定义了用户可以在编译时或者运行时传递的变量，如使用如下命令：--build-arg <varname>=<value>
The ENV instruction sets the environment variable <key> to the value <value>. The environment variables set using ENV will persist when a container is run from the resulting image.ENV指令是在dockerfile里面设置环境变量，不能在编译时或运行时传递。

以下是ARG和ENV的有效结合:
    ARG var
    ENV var=${var}
You can then either build an image with a specific var value at build-time (docker build --build-arg var=xxx), or run a container with a specific runtime value (docker run -e var=yyy)

ARG <name>[=<default value>]
ARG指令定义了一个变量，能让用户可以在构建期间使用docker build命令和其参数–build-arg =对这个变量赋值。
如果用户指定了一个构建参数没有定义在Dockerfile的话，将输出错误。

docker build --build-arg kerneldevel=kernel-devel-3.10.0-514.el7.x86_64.rpm --build-arg  kernelheaders=kernel-headers-3.10.0-514.el7.x86_64.rpm --build-arg pythonversion=Python-3.6.8.tgz -t testimage -f /home/athena_training_py3/Dockerfile /home/athena_training_py3/

Dockerfile作者可以指定ARG一次定义一个变量，或者指定ARG多次定义多个变量。例如：
FROM busybox
ARG user1
ARG buildno
Dockerfile作者也可以为这个变量指定一个默认值
FROM busybox
ARG user1=someuser
ARG buildno=1
如果ARG指定了一个默认值并且在构建期间没有传递值过去，那么就使用默认值。
ARG变量定义从在Dockerfile定义的行生效，而不是从在命令行参数的使用或其它地方。
例如下面的Dockerfile:
FROM busybox
USER ${user:-some_user}
ARG user
USER $user
使用如下命令构建：
$ docker build --build-arg user=what_user Dockerfile
第2行的USER的值为some_user，因为user变量在第3行才定义。第4行的USER值为what_user，
因为user变量在它之前定义了并且在命令行给user变量赋值为what_user。在ARG指令定义变量之前引用这个变量的得，都会得到空值。

可以使用ARG或ENV指令指定可用于RUN指令的变量。使用ENV定义的环境变量始终会覆盖同一名称的ARG指令定义的变量。例如：
FROM ubuntu
ARG CONT_IMG_VER
ENV CONT_IMG_VER v1.0.0
RUN echo $CONT_IMG_VER
然后使用如下命令构建镜像：
$ docker build --build-arg CONT_IMG_VER=v2.0.1 Dockerfile
在这种情况中，RUN指令解析CONT_IMG_VER变量的值为v1.0.0而不是ARG设置并由用户传递过来的v2.0.1。
使用上面的示例，但不一样的ENV定义可以在ARG和ENV指令之前创建更有用的交互：
FROM ubuntu
ARG CONT_IMG_VER
ENV CONT_IMG_VER ${CONT_IMG_VER:-v1.0.0}
RUN echo $CONT_IMG_VER
不像ARG指令，ENV的值始终会存在于镜像中。使用如下不带–build-arg构建镜像：
$ docker build Dockerfile
使用这个Dockerfile示例，CONT_IMG_VER仍然会存在于镜像中，不过它的值会是默认的v1.0.0，当然你也可以在命令行中更改它。

- env_file，environment中定义的环境变量是传给container用的，不是给在docker-compose.yml文件中的引用的环境变量用的
- docker-compose.yml中的环境变量${VARIABLE:-default}引用的是在.env中定义的或者同个shell export出来的
The ".env" file
You can set default values for any environment variables referenced in the Compose file, or used to configure Compose, in an environment file named .env:（您可以在名为.env的环境文件中为Compose文件中引用的任何环境变量设置默认值，或者用于配置Compose：）
$ cat .env
TAG=v1.5

$ cat docker-compose.yml
version: '3'
services:
  web:
    image: "webapp:${TAG}"
When you run docker-compose up, the web service defined above uses the image webapp:v1.5. You can verify this with the config command, which prints your resolved application config to the terminal:（当您运行docker-compose时，上面定义的Web服务使用image webapp：v1.5。 您可以使用config命令验证此问题，该命令会将已解析的应用程序配置打印到终端：）
$ docker-compose config
version: '3'
services:
  web:
    image: 'webapp:v1.5'
Values in the shell take precedence over those specified in the .env file. If you set TAG to a different value in your shell, the substitution in image uses that instead:（shell中的值优先于.env文件中指定的值。 如果在外壳中将TAG设置为不同的值，则图像中的替换将使用该值：）
$ export TAG=v2.0
$ docker-compose config
version: '3'
services:
  web:
    image: 'webapp:v2.0'
When you set the same environment variable in multiple files, here’s the priority used by Compose to choose which value to use:
（当您在多个文件中设置相同的环境变量时，以下是Compose用于选择要使用的值的优先级：）
1.Compose file,
2.Environment file,
3.Dockerfile,
4.Variable is not defined.
In the example below, we set the same environment variable on an Environment file, and the Compose file:
（在下面的例子中，我们在Environment文件和Compose文件上设置了相同的环境变量：）
$ cat ./Docker/api/api.env
NODE_ENV=test

$ cat docker-compose.yml
version: '3'
services:
  api:
    image: 'node:6-alpine'
    env_file:
     - ./Docker/api/api.env
    environment:
     - NODE_ENV=production

When you run the container, the environment variable defined in the Compose file takes precedence.
（运行容器时，在撰写文件中定义的环境变量优先。）
$ docker-compose exec api node

> process.env.NODE_ENV
'production'

Having any ARG or ENV setting in a Dockerfile evaluates only if there is no Docker Compose entry for environment or env_file.
（只有在环境或env_file没有Docker Compose条目时，Dockerfile中的任何ARG或ENV设置才会评估）

#####################################################
########.env、env-file、environment区别的实例########
#####################################################
docker-compose中的环境变量
使用docker-compose部署一个MySQL server. mysq serverl的数据库文件存放在/var/lib/mysql目录下，为了重启mysql server不至于丢失创建的数据库数据，我们需要mount一个目录到mysql server容器的/var/lib/mysql。用docker-compose创建一个mysql instance大概如下：
version: '2'
services:
  mysql:
    image:mysql
    volumes:
      - ${MYSQL_DATA_DIR}:/var/lib/mysql
MYSQL_DATA_DIR是我用到的环境变量，希望配置到一个文件中，不同的MySQL instance用不同的目录，所以用到了环境变量。
粗粗的浏览了一下docker-compose参考文档，好像变量可以定义到一个文件中,如定义到mysql,.env中，这样mysql服务的定义就改为了：
version: '2'
services:
  mysql:
    image:mysql
   env-file:
      - ./mysql.env
    volumes:
      - ${MYSQL_DATA_DIR}:/var/lib/mysql
mysql.env的内容如下：
$ cat mysql.env
MYSQL_DATA_DIR=/my/sql/data-dir
然后启动mysql:
$ docker-compose up -d
docker-composegeic给出警告：
WARNING: The MYSQL_DATA_DIR variable is not set. Defaulting to a blank string.
奇怪，定义在MYSQL_DATA_DIR中的环境变量不起作用。环境变量也可以定义在environment中，不从文件中读取环境变量了，直接定义在environment中有如何。docker-compose.yml改为：
version: '2'
services:
  mysql:
    image:mysql
    environment:
      - MYSQL_DATA_DIR=/my/sql/data-dir
    volumes:
      - ${MYSQL_DATA_DIR}:/var/lib/mysql
用docker-compose启动mysql:
$docker-compose up -d
得到一样的错误。什么原因？文档上不是说可以用环境变量并且可以把环境变量定义在env_file和environment中吗。为什么就不工作呢？google一把，有人问同样的问题，看了几个回到，终于有人说到了点子上：
- env_file，environment中定义的环境变量是穿给container用的不是在docker-compose.yml中的环境变量用的
- docker-compose.yml中的环境变量${VARIABLE:-default}引用的是在.env中定义的或者同个shell export出来的
原来如此，把MYSQL_DATA_DIR定义在.env中试试：
$ cat .env
MYSQL_DATA_DIR=/my/sql/data-dir
然后重新启动mysql:
$ docker-compose up -d
这次没有任何错误了，一切工作正常。


##################################################dockerfile 中 ARG与ENV的区别################################################

######################################################RUN CMD ENTRYPOINT#####################################################
RUN是在building image时会运行的指令, 在Dockerfile中可以写多条RUN指令.
CMD和ENTRYPOINT则是在运行container 时会运行的指令, 都只能写一条, 如果写了多条, 则最后一条生效.
######################################################RUN CMD ENTRYPOINT#####################################################

#########################################################CMD ENTRYPOINT########################################################
The CMD instruction has three forms:
CMD ["executable","param1","param2"] (exec form, this is the preferred form)
CMD ["param1","param2"] (as default parameters to ENTRYPOINT)
CMD command param1 param2 (shell form)

用法1：带有中括号的形式。这时，命令没有在任何shell终端环境下，如果我们要执行shell，必须把shell加入到中括号的参数中。这种用法就像一个c语言的exec函数，意思是我们要执行一个进程。比如：
FROM centos
CMD ["/bin/bash", "-c", "echo 'hello cmd!'"]
需要注意，采用中括号形式，那么第一个参数必须是命令的全路径才行。而且，一个dockerfile至多只能有一个cmd，如果有多个，只有最后一个生效。
官网推荐采用这种方法。
以上都是体现了cmd的"默认"行为。如果我们在run时指定了命令或者有 ，那么cmd就会被覆盖。例：
docker run -it --rm centos:latest '/bin/bash' '-c' 'echo $0' 11111
docker run -it --rm centos:latest 'echo' '11111'

用法2：
作为ENTRYPOINT 的默认参数
如果dockerfile中同时指定了ENTRYPOINT和CMD，CMD将作为ENTRYPOINT的默认参数，这里两个指令都指的是exec 格式，都将解析为JSON数组，所以只能用双引号。

用法3：shell form，即没有中括号的形式。那么命令command默认是在"/bin/sh -c"下执行的。比如下面的dockerfile：
FROM centos
CMD echo "hello cmd!"

ENTRYPOINT has two forms: 
ENTRYPOINT ["executable", "param1", "param2"] (exec form, preferred)
ENTRYPOINT command param1 param2 (shell form)

用法1：命令行模式，也就是带中括号的。和cmd的中括号形式是一致的，但是这里貌似是在shell的环境下执行的，与cmd有区别。如果run命令后面有东西，那么后面的全部都会作为entrypoint的参数。如果run后面没有额外的东西，但是cmd有，那么cmd的全部内容会作为entrypoint的参数，这同时是cmd的第二种用法。
例：
dockerfile为：
FROM centos
CMD ["p in cmd"]
ENTRYPOINT ["echo"]
如果run不带参数：docker run cfcc 则输出为：p in cmd、如果run带参数：docker run cfcc p in run 则输出为：p in run。
而且，确实entrypoint的中括号形式下，command是在shell环境下运行的，否则这里的echo是无法被执行的。

用法2：shell模式。在这种模式下，任何run和cmd的参数都无法被传入到entrypoint里。官网推荐第一种用法。例：
FROM centos
CMD ["p in cmd"]
ENTRYPOINT echo
docker run 949a cmd中的参数没有被打印

用docker run中的--entrypoint替换dockerfile的ENTRYPOINT
docker run -it --entrypoint=/bin/bash athena:1.0

docker run -it --rm --entrypoint=ls centos:latest '-lh'
docker run -it --rm --entrypoint=/bin/bash centos:latest '-c' 'ls -lh'
docker run -it --rm --entrypoint=/bin/bash centos:latest '-c' 'echo $0' 11111

一、 ENTRYPOINT指令

ENTRYPOINT 的两种格式：
• ENTRYPOINT ["executable", "param1", "param2"] (exec格式，推荐使用此格式)
• ENTRYPOINT command param1 param2 (shell 格式)

ENTRYPOINT的目的和CMD一样，都是指定容器的启动程序及参数。ENTRYPOINT在运行时也可以通过docker run的参数--entrypoint来替代镜像中默认的ENTRYPOINT，通过--entrypoint传的必须是可执行的二进制程序，即不会以sh -c形式执行。
当指定了ENTRYPOINT（exec格式）后，CMD的含义就发生了改变，不再是直接运行的命令，而是将CMD的内容作为参数传给ENTRYPOINT指令，换句话说实际执行时，将变为：<ENTRYPOINT> "<CMD>"
通过docker run <image>启动容器时的命令行参数将作为ENTRYPOINT的参数追加到其已有的参数后面，此时所有的CMD参数将无效，被命令行参数覆盖；
CMD作为ENTRYPOINT的参数时需要是exec格式，如果是shell格式将转化成/bin/sh -c 式的exec格式，作为参数传给 ENTRYPOINT 时可能会出错；
当指定了ENTRYPOINT 为shell格式，CMD将无效，即dockerfile里的CMD和启动容器时传的命令行参数都将无效，此时ENTRYPOINT将以/bin/sh –c的形式启动，即作为sh的子命令来执行，这种形式下ENTRYPOINT的执行程序不能通过Unix信号控制，因进程号不是容器的PID 1 （sh的进程PID为1），也就不能以docker stop <container> 的形式来优雅地停止（接收SIGTERM信号）ENTRYPOINT的执行程序 ，因为这时docker stop <container>会在超时时间后通过发送SIGKILL信号给sh 强制停止容器，这会导致stop时间加长，为避免这种缺点，在shell命令前加exec，以这种方式运行即可，如：ENTRYPOINT exec <shell command>。
和shell格式不同，当ENTRYPOINT是exec格式时不会调用shell，通常的shell变量将不会被解析执行，ENTRYPOINT [ "echo", "$HOME" ] 中的$HOME不会被替换，如果需要变量替换，则可以用shell格式的ENTRYPOINT。

二、 CMD指令

启动容器的时候，需要指定所运行的程序及参数。CMD 指令就是用于指定默认的容器主进程的启动命令的。
CMD指令有三种格式：
• CMD ["executable","param1","param2"] (exec 格式，推荐用此格式)
• CMD ["param1","param2"] (作为ENTRYPOINT 的默认参数)
• CMD command param1 param2 (shell 格式)

在dockerfile中只能有1个CMD指令，如有多个，最后一个生效。CMD的目的是提供默认的执行程序或执行程序的参数给容器，如果是参数，需要有ENTRYPOINT提供执行程序。
如果dockerfile中同时指定了ENTRYPOINT和CMD，CMD将作为ENTRYPOINT的默认参数，这里两个指令都指的是exec格式，都将解析为JSON数组，所以只能用双引号；
exec格式不会解析shell环境变量，如CMD [ "echo", "$HOME" ] 将无法解析变量HOME变量，dockerfile里如果CMD用shell格式，在实际执行时将以 /bin/sh -c 执行，如：
CMD echo $HOME
在实际执行时将变成CMD [ "sh", "-c", "echo $HOME" ] 也就会解析出HOME变量。
CMD用exec格式执行系统的命令时，需要命令的全路径和JSON数组格式，就是得使用双引号，每个参数单独分别地追加在数组中，如下用法：
CMD ["/usr/bin/wc", "--help"]

三、 理解和结合使用CMD和ENTRYPOINT
• Dockerfile 应该至少指定CMD或ENTRYPOINT其中的1个；
• 容器用作可执行的程序应用时应该用ENTRYPOINT；
• CMD应该用作ENTRYPOINT的默认参数来使用，或是在容器中执行临时的命令；
• 启动容器时如果传递参数将覆盖dockerfile中指定的CMD参数；
#########################################################CMD ENTRYPOINT########################################################

#############################################在ubuntu16.04镜像上安装GPU显卡驱动############################################
linux查看系统已安装内核:
version = uname -r

ubuntu的话apt-get install如下两个模块
linux-headers-4.4.0-21
linux-headers-4.4.0-21-generic

apt-get install -y linux-headers-${version}
apt-get install -y linux-headers-${version}-generic

docker build --build-arg version=3.10.0-514.el7.x86_64 -t athena-gpu:1.0.0.20180917_base -f /home/robot_env_gpu/Dockerfile /home/robot_env_gpu/

docker build -t athena-training:1.2.20181010_release --build-arg version=3.10.0-514.el7.x86_64 -f /home/athena_training/Dockerfile /home/athena_training/

docker build -t athena-training:1.0.20181013_release -f /home/athena_training/Dockerfile /home/athena_training/

docker build -t athena-inference:1.0.20181013_release -f /home/athena_inference/Dockerfile /home/athena_inference/

docker run -it --privileged=true ubuntu:container /bin/bash
#############################################在ubuntu16.04镜像上安装GPU显卡驱动############################################

#########################################Centos7 安装docker-18.03.1-ce（离线安装）########################################
一、引言
为了实现离线安装docker-18.03.1-ce这个想法，我遍寻网络，什么 RPM 搜索大法啦，yum localinstall 方法啦，都是复杂到不行。

二、终极解决
直接上网址： Install Docker CE from binaries (官方文档：通过二进制包安装 docker 社区版)
https://docs.docker.com/install/linux/docker-ce/binaries/#install-static-binaries
友情提示：访问该网页需要科学上网：）
这里，我把当前最新（2018-05-24）的 docker-18.03.1-ce 上传到了百度云，以方便大家下载使用： docker-18.03.1-ce 百度云密码：pah1

1. 通过 FileZilla 等文件传输工具将 docker-18.03.1-ce.tar 放到用户目录下，并移动到该目录执行下述命令解压二进制包
$ tar xzvf docker-18.03.1-ce.tar

2. 将解压出来的 docker 文件所有内容移动到 /usr/bin/ 目录下
$ sudo cp docker/* /usr/bin/
 
3. 开启 docker 守护进程（这个与常规安装方式不一样）
$ sudo dockerd &

4. 现在你可以尝试着打印下版本号，试着看看 images，看看 info，看看容器了
$ sudo docker images $ sudo docker ps -a $ sudo docker --version $ sudo docker info
都没有问题，则表示安装成功：）
#########################################Centos7 安装docker-18.03.1-ce（离线安装）########################################

#########################################service endpoint with name xxx already exists.#########################################
使用Docker时，在启动一个容器时，有时会遇到如下问题：
docker: Error response from daemon: service endpoint with name xxx already exists.
说明此端口已经被名为xxx的容器占用了。
我这里遇到的是问题是，在启动mysql时出现问题：
root@iZuf6axmuekh1n14dwcufmZ:~# docker restart mysql1 
Error response from daemon: Cannot restart container mysql1: service endpoint with name mysql1 already exists

解决方法：
1.停止所有的容器
docker stop $(docker ps -q)

2.强制移除此容器
docker rm -f mysql1

3.清理此容器的网络占用
格式：docker network disconnect --force 网络模式 容器名称
示例：docker network disconnect --force bridge mysql1

4.简查是否还有同名容器占用
格式：docker network inspect 网络模式
示例：docker network inspect bridge
#########################################service endpoint with name xxx already exists.#########################################

#########################################docker inspect工具#########################################
docker inspect : 获取容器/镜像的元数据。

语法
docker inspect [OPTIONS] NAME|ID [NAME|ID...]
OPTIONS说明：
    -f :指定返回值的模板文件。
    -s :显示总的文件大小。
    --type :为指定类型返回JSON。
docker inspect -f "{{.Mounts}}" d2cc496561d6
等价于
docker inspect --format="{{.Mounts}}" d2cc496561d6

docker inspect --format='{{ XXX }}' $(docker ps -aq)
一级属性{{.属性}} 二级属性 {{.属性.属性}} 三级属性 {{.属性.属性.属性}}

获取容器的名字
[root@i-ifgwrq7g ~]# docker inspect --format='{{.Name}}' $(docker ps -aq)
/app

获取容器的 pid
[root@i-ifgwrq7g ~]# docker  inspect  -f='{{ .State.Pid }} {{ .Id }}' $(docker ps -aq)
21613 73bbdbc9b8b243244b82c9538bddc06c9a217b43d0e001f462ba644b4a36070b

#########################################docker inspect工具#########################################

#########################################docker nsenter工具#########################################
nsenter使用
在使用nsenter命令之前需要获取到docker容器的进程，然后再使用nsenter工具进去到docker容器中，具体的使用方法如下
$ docker inspect -f {{.State.Pid}} 容器名或者容器id   #每一个容器都有.State.Pid，所以这个命令除了容器的id需要我们根据docker ps -a去查找，其他的全部为固定的格式
$ nsenter --target 上面查到的进程id --mount --uts --ipc --net --pid  #输入该命令便进入到容器中

解释nsenter指令中进程id之后的参数的含义： 
* –mount参数是进去到mount namespace中 
* –uts参数是进入到uts namespace中 
* –ipc参数是进入到System V IPC namaspace中 
* –net参数是进入到network namespace中 
* –pid参数是进入到pid namespace中 
* –user参数是进入到user namespace中

在Linux中，最爱简单的查看指定命令参数含义的办法是在终端中输入：
$ nsenter --help  #会回显所有与该命令有关的参数
$ man nsenter  #能查到更加详细的使用示例和参数说明

由于使用DOCKER的时候，ESTABLISHED连接不会出现在netstat中，在运行中的docker容器中列出打开的套接字的方法
查找docker的进程号 ：
docker inspect -f '{{.State.Pid}}' <containerid>   
$ docker inspect -f '{{.State.Pid}}' 1746bf8c10aa  
1829

查看连接： 
sudo nsenter -t <pid> -n netstat | grep ESTABLISHED  
$ nsenter -t 1829 -n netstat |grep ESTABLISHED  
tcp        0      0 localhost:60353         localhost:epmd          ESTABLISHED
tcp        0      0 localhost:epmd          localhost:60353         ESTABLISHED
tcp        0      0 localhost.localdo:15672 192.168.56.1:59679      ESTABLISHED
tcp6       0      0 172.17.0.2:amqp         192.168.56.1:59898      ESTABLISHED
tcp6      21      0 172.17.0.2:amqp         192.168.56.1:59571      ESTABLISHED 
#########################################docker nsenter工具#########################################


#########################################docker打开api remote接口设置#########################################
1、查看配置文件位于哪里
systemctl show --property=FragmentPath docker 
FragmentPath=/usr/lib/systemd/system/docker.service
2、编辑配置文件内容，接收所有ip请求
vim  /usr/lib/systemd/system/docker.service 
ExecStart=/usr/bin/dockerd -H unix:///var/run/docker.sock -H tcp://0.0.0.0:5678 -g /opt/docker
-g, --graph=""修改docker默认的镜像安装目录
3、重新加载配置文件，重启docker daemon
systemctl daemon-reload 
systemctl restart docker
4、测试
最后用docker info命令查看Docker的镜像及容器的存放目录（Docker Root Dir）
docker -H 192.168.56.110:5678 images

import docker
client = docker.api.APIClient(base_url='http://192.168.56.111:5678')
#拉取镜像
image = client.pull('192.168.56.110:5000/athena-inference-py3:1.0.20190628_release')
#创建容器：返回字典类型{'Id': '0e61c28a56a33de782194b9797043d3247d65a678e87d9bce600aeccccdf48a8', 'Warnings': None}
container = client.create_container('192.168.56.110:5000/athena-inference-py3:1.0.20190628_release',entrypoint='/bin/bash',detach=True)
#启动容器：
client.start('0e61c28a56a33de782194b9797043d3247d65a678e87d9bce600aeccccdf48a8')
#停止容器
client.stop('0e61c28a56a33de782194b9797043d3247d65a678e87d9bce600aeccccdf48a8')
#删除容器
client.remove_container('0e61c28a56a33de782194b9797043d3247d65a678e87d9bce600aeccccdf48a8')

container = client.create_container('192.168.56.110:5000/athena-inference-py3:1.0.20190628_release',volumes={'/home/docker-remote-api/entrypoint.d/':{'bind':'/entrypoint.d/','mode':'rw'},'/home/docker-remote-api/app/':{'bind':'/athena/','mode':'rw'}},detach=True)

client = docker.DockerClient(base_url='http://192.168.56.111:5678')
#拉取镜像
image = client.api.pull('192.168.56.110:5000/athena-inference-py3:1.0.20190628_release')
#创建容器：返回Container对象<Container: 3962704a42>，可以调用name、id获取容器的名字和id，也可通过调用stop方法停止容器
container = client.containers.run('192.168.56.110:5000/athena-inference-py3:1.0.20190628_release',volumes={'/home/docker-remote-api/entrypoint.d/':{'bind':'/entrypoint.d/','mode':'rw'},'/home/docker-remote-api/app/':{'bind':'/athena/','mode':'rw'}},privileged =True,remove=True,detach=True)
print('name=%s,id=%s' % (container.name,container.id)) #获取容器的名字和ID
container.stop()                                       #停止容器 
#停止容器
client.api.stop('271d7b97eb')
#删除容器
client.api.remove_container('271d7b97eb')

#阻塞直到容器停止，并且返回exit code
exit_dict = container.wait()
error = res_dict['Error']
exit_code = res_dict['StatusCode'] #0:正常;1:异常

#获取当前存活的容器
client.containers.list()
#获取指定容器（当容器不存在会抛docker.errors.NotFound: 404 Client Error: Not Found ("No such container: 容器ID")）
client.containers.get(container.id)
try:
    client.containers.get('1111')
except docker.errors.NotFound:
    print('')
#########################################docker打开api remote接口设置#########################################

#########################################centos7 Docker私有仓库搭建及删除镜像#########################################
环境：两个装有Docker 18.05.0-ce 的centos7虚拟机 
虚拟机一：192.168.56.111 用户开发机 
虚拟机二：192.168.56.110 用作私有仓库

在110机器上下载registry镜像
docker pull registry

启动容器前注意两个事项：
默认情况下，会将仓库存放于容器内的/tmp/registry目录下，这样如果容器被删除，则存放于容器中的镜像也会丢失，所以我们一般情况下会指定本地一个目录挂载到容器内的/tmp/registry下，
不过具体的情况还是要到容器里去看
先启动容器
docker run -d -p 5000:5000 -v /opt/data/registry:/tmp/registry registry 
b4c21ca8cf8a23ea72e0471909742541ffc312ea5cf492486b5bdc3130179864
可以看到容器存放位置不在/tmp 下
我们接着来查找下，挂载位置到底在哪里
可以看到registry 挂载目录是 在 /var/lib/registry 下

将容器内的config.yml复制到宿主机下
docker cp 57164a1347ab:/etc/docker/registry/config.yml /opt/data/config.yml
按下面的要求修改config.yml
config.yml 这个是什么呢？我们在下面删除仓库镜像介绍
这里需要说明一点，在启动仓库时，需在配置文件中的storage配置中增加delete=true配置项，允许删除镜像。默认的镜像是没有这个参数
cat config.yml
version: 0.1
log:
  fields:
    service: registry
storage:
  delete:
    enabled: true
  cache:
    blobdescriptor: inmemory
  filesystem:
    rootdirectory: /var/lib/registry
http:
  addr: :5000
  headers:
    X-Content-Type-Options: [nosniff]
health:
  storagedriver:
    enabled: true
    interval: 10s
    threshold: 3

我们重新启动下 registry
docker run -d -p 5000:5000 -v /opt/data/registry:/var/lib/registry -v /opt/data/config.yml:/etc/docker/registry/config.yml registry

配置https权限支持
Docker从1.3.X之后，与docker registry交互默认使用的是https，然而此处搭建的私有仓库只提供http服务，所以当与私有仓库交互时就会报错。为了解决这个问题需要在启动docker server时增加启动参数为默认使用http访问。修改docker启动配置文件：
vim /etc/docker/daemon.json
添加：{"insecure-registries":["192.168.56.110:5000"]}
service docker restart
insecure-registry 192.168.56.110:5000，表示开启5000端口的非安全模式，也就是http模式
重启docker
systemctl daemon-reload
systemctl restart docker

测试
操作把一个本地镜像push到私有仓库中。首先在110机器下pull一个比较小的镜像来测试（此处使用的是busybox）。
docker pull busybox
接下来修改一下该镜像的tag。（在镜像前面加上了运行私有registry的ip:port，这是必须的）
docker tag busybox 192.168.56.110:5000/busybox:1.0.20190802_release
其中192.168.56.110:5000/busybox为REPOSITORY，1.0.20190802_release为TAG
接下来把打了tag的镜像上传到私有仓库。
docker push 192.168.56.110:5000/busybox:1.0.20190802_release

拉取镜像
docker pull 192.168.56.110:5000/busybox:1.0.20190802_release

私有Docker Registry删除镜像
curl -I -X DELETE http://192.168.0.153:5000/v2/<name>/manifests/<reference>
name:镜像名称
reference: 镜像对应sha256值

name:镜像名称
reference: 镜像对应sha256值
在私有registry上查看镜像
curl -X 'GET' http://192.168.56.110:5000/v2/_catalog
{"repositories":["busybox"]}

获取镜像所有标签（取镜像的名称）
curl -X 'GET' http://192.168.56.110:5000/v2/busybox/tags/list
{"name":"busybox","tags":["1.0.20190802_release"]}

获取标签对应的digest（取镜像对应sha256值）
curl -i -X 'GET' -H 'Accept:application/vnd.docker.distribution.manifest.v2+json' http://192.168.56.110:5000/v2/busybox/manifests/1.0.20190802_release
注意：必须配置 Header Accept:application/vnd.docker.distribution.manifest.v2+json，否则获取的值不对。
HTTP/1.1 200 OK
Content-Length: 527
Content-Type: application/vnd.docker.distribution.manifest.v2+json
Docker-Content-Digest: sha256:895ab622e92e18d6b461d671081757af7dbaa3b00e3e28e12505af7817f73649
Docker-Distribution-Api-Version: registry/2.0
Etag: "sha256:895ab622e92e18d6b461d671081757af7dbaa3b00e3e28e12505af7817f73649"
X-Content-Type-Options: nosniff
注意看前面操作返回值的Header，使用Docker-Content-Digest的完整值，包含sha256:前缀

删除镜像索引（只删除了元数据，数据大小没有变化）
curl -I -X 'DELETE' http://192.168.56.110:5000/v2/busybox/manifests/sha256:895ab622e92e18d6b461d671081757af7dbaa3b00e3e28e12505af7817f73649

进入容器执行垃圾回收命令
docker exec -it registry /bin/sh
registry garbage-collect /etc/docker/registry/config.yml

#########################################centos7 Docker私有仓库搭建及删除镜像#########################################

##################################################nvidia docker指定显卡启动##################################################
docker启动参数上加-e NVIDIA_VISIBLE_DEVICES=1(0代表第一块显卡，１代表第二块显卡，不加参数是全部启动)
docker run -it  --runtime=nvidia -e NVIDIA_VISIBLE_DEVICES=1 需要启动的docker名称 bash
多显卡机器上，如果显卡０正在被其他程序占用，但是程序指定显卡０，你就可以加这个命令，只启动部分显卡，docker里面看到cuda０编号就是你启动外部１编号．
##################################################nvidia docker指定显卡启动##################################################

##################################################VirtualBox 中虚拟机硬盘空间不足扩容##################################################
D:\oracle\VirtualBox>VBoxManage modifyhd  D:\server03\server03.vdi --resize 30720
##################################################VirtualBox 中虚拟机硬盘空间不足扩容##################################################

创建用于挂载的目录
sudo mkdir /my/mysql/datadir #用于挂载mysql数据文件
sudo mkdir /my/mysql/conf.d #用于挂载mysql配置文件

使用镜像创建容器
docker run --name mysql5.7 -p 12345:3306 -v /home/mysql/datadir:/var/lib/mysql -v /home/mysql/mysql.conf.d:/etc/mysql/mysql.conf.d -e MYSQL_ROOT_PASSWORD=123456 -d mysql:5.7

docker run --name mysql5.7 -p 12345:3306 -v /home/mysql/datadir:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=123456 -d mysql:5.7

docker run --name mysql5.7 -p 12345:3306 -e MYSQL_ROOT_PASSWORD=123456 -d mysql:5.7

命令解析：
--name：容器名
--p：映射宿主主机端口
-v：挂载宿主目录到容器目录
-e：设置环境变量，此处指定root密码
-d：后台运行容器

