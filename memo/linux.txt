/**********************************************************linux版本**********************************************************
radhat或centos存在：/etc/redhat-release 这个文件
debian或ubuntu 存在 /etc/debian_version 这个文件
Slackware存在 /etc/slackware_version 这个文件
ubuntu存在 /etc/lsb-release 这个文件
/**********************************************************linux版本**********************************************************

/****************************************************VirtualBox虚拟机复制******************************************************
http://chensenlin.blog.51cto.com/10559465/1875324
VBoxManage.exe clonevdi "C:\Users\Administrator\VirtualBox VMs\Virtual-01\Virtual-01.vdi" "D:\Virtual-02\Virtual-02.vdi"
/****************************************************VirtualBox虚拟机复制******************************************************


/*********************************************************#!/bin/bash********************************************************
shell脚本的第一行一般会写有以下字样：#!/bin/bash或者#!/bin/sh或者#!/bin/awk
第一行的内容指定了shell脚本解释器的路径，而且这个指定路径只能放在文件的第一行。第一行写错或者不写时，系统会有一个默认的解释器进行解释。
只有当Shell脚本的第一行的内容以#!开头才认为是指定脚本解释器的路径。（如果不写，或者以#开头的话系统会有一个默认的解释器，但是如果以#!开头然后没有正确指定解释器的路径的话执行脚本就会报错）

为什么.sh脚本必须在前面加上./*****.sh才能执行（运行其它二进制的程序也一样）
Linux不像DOS，默认的先搜索当前路径，而Linux一般情况下是按$PATH变量去寻找可执行程序，你的当前目录通常不在PATH里，所以写成start.sh是会找不到命令的。再根据linux下"."表示当前目录,所以在命令之前加上"./"便可以很自然的理解为在当前目录下寻找程序。

/bin/bash -c "cmd string"
If the -c option is present, then commands are read from the first non-option argument command_string. If there are arguments after the command_string, they are assigned to the positional parameters, starting with $0.
大致意思就是，如果用-c 那么bash 会从第一个非选项参数后面的字符串中读取命令，如果字符串有多个空格，第一个空格前面的字符串是要执行的命令，也就是$0, 后面的是参数，即$1, $2....
例子
首先有个atest shell脚本,里面的内容为
echo $0
echo $1
echo $2
执行bash -c "./atest hello world"他的输出如下
./atest
hello
world
个人理解bash -c "./atest hello world"实际上和./atest hello world等价
bash -c "./atest hello world"和./atest hello world等价，那具体有没有什么区别呢？ 是有的，上面的介绍是直接在终端中运行命令。那当我们在代码中要运行上面的脚本的时候，比如fork + exec的时候，这种情况下一般就使用bash -c

/bin/bash -c "echo $0" 'parm1' 输出:/bin/bash
/bin/bash -c 'echo $0' 'parm1' 输出:parm1
原因如下：
/bin/bash -c相当于执行两步
第一步；将-c后面的cmd string做一次解析（相当于执行一次Shell命令）
由于第一条命令中使用双引号变量会被展开，因此解析的结果为：echo /bin/bash
为啥第一条命令中的$0为被解析为/bin/bash呢？例：
shell.sh的内容为echo $0。运行./shell.sh 输出的结果为：shell.sh，因为在shell里面$0相当于你要执行的命令，在这里你要执行的命令是shell.sh
同样的道理运行/bin/bash -c也是执行一次Shell命令，这里你执行的命令是/bin/bash；因此$0就是/bin/bash 
（/bin/bash -c "echo $0"就相当在linux终端里直接输入echo $0；两者的输出一样，都是输出：/bin/bash）
由于第二条命令中使用单引号变量不再展开，因此解析的结果为：echo %0 'parm1'
第二步；在执行第一步解析完后的结果。
第一条命令输出:/bin/bash
第二条命令输出:parm1

在bash里，这两个都是引号，用来表明字符串，区别是，双引号中的变量会被展开，而单引号中不再展开。
例子：
a="abc"
echo "str=$a"  # 结果显示 str=abc
echo 'str=$a'  # 结果显示str=$a
/*********************************************************#!/bin/bash********************************************************

/**********************************************linux查看系统已安装内核*******************************************************
1) uname -r
2) rpm -qa | grep kernel
3) rpm -qi kernel
第一种和第三种为当前运行内核，第二种已安装的所有内核
/**********************************************linux查看系统已安装内核*******************************************************

/**********************************************linux rpm命令*******************************************************
查询是否安装某个软件
[root@localhost 1]# rpm -qa | grep vim
vim-filesystem-7.4.160-1.el7.x86_64
vim-enhanced-7.4.160-1.el7.x86_64
vim-common-7.4.160-1.el7.x86_64
vim-minimal-7.4.160-1.el7.x86_64

查询命令属于哪个软件
[root@localhost 1]# which passwd 
/usr/bin/passwd
[root@localhost 1]# rpm -qf /usr/bin/passwd
passwd-0.79-4.el7.x86_64

查看通过yum安装的软件所在的目录

查看通过yum（或者yum源）安装的软件所在的目录
1) 如果是直接通过yum install安装的软件，用如下方式查找
[root@localhost ~]# rpm -ql python
/usr/bin/pydoc
/usr/bin/python
/usr/bin/python2
/usr/bin/python2.7
/usr/share/doc/python-2.7.5
/usr/share/doc/python-2.7.5/LICENSE
/usr/share/doc/python-2.7.5/README
/usr/share/man/man1/python.1.gz
/usr/share/man/man1/python2.1.gz
/usr/share/man/man1/python2.7.1.gz
2) 如果是通过yum源安装的软件（例：通过执行rpm -ivh mysql80-community-release-el7-1.noarch.rpm命令安装的软件），用如下方式查找
首先通过which加rpm -qf的方式找到该命令属于哪个软件
[root@server01 ~]# which mysql
/usr/bin/mysql
[root@server01 ~]# rpm -qf /usr/bin/mysql
mysql-community-client-5.7.26-1.el7.x86_64
然后再通过rpm -ql查找安装的软件所在的目录
[root@server01 ~]# rpm -ql mysql-community-client-5.7.26-1.el7.x86_64
/usr/bin/mysql
/usr/bin/mysql_config_editor
/usr/bin/mysqladmin
/usr/bin/mysqlbinlog
/usr/bin/mysqlcheck
/usr/bin/mysqldump
/usr/bin/mysqlimport
/usr/bin/mysqlpump
/usr/bin/mysqlshow
/usr/bin/mysqlslap
/usr/share/doc/mysql-community-client-5.7.26
/usr/share/doc/mysql-community-client-5.7.26/COPYING
/usr/share/doc/mysql-community-client-5.7.26/README
/usr/share/man/man1/mysql.1.gz
/usr/share/man/man1/mysql_config_editor.1.gz
/usr/share/man/man1/mysqladmin.1.gz
/usr/share/man/man1/mysqlbinlog.1.gz
/usr/share/man/man1/mysqlcheck.1.gz
/usr/share/man/man1/mysqldump.1.gz
/usr/share/man/man1/mysqlimport.1.gz
/usr/share/man/man1/mysqlpump.1.gz
/usr/share/man/man1/mysqlshow.1.gz
/usr/share/man/man1/mysqlslap.1.gz
/**********************************************linux rpm命令*******************************************************

/**********************************************回车与换行*******************************************************
关于换行和回车其实平时我们不太在意，所以关于两者的区别也不太清楚，在平时开发时可能会遇到一些文件处理的问题，放到不同的操作系统上出现各种问题
1. 由来
在计算机还没有出现之前，有一种叫做电传打字机（Teletype-Model—33）的机械打字机，每秒钟可以打10个字符。但是它有一个问题，就是打完一行换行的时候，要用去0.2秒，正好可以打两个字符。要是在这0.2秒里面，又有新的字符传过来，那么这个字符将丢失。
于是，研制人员想了个办法解决这个问题，就是在每行后面加两个表示结束的字符。一个叫做“回车”，告诉打字机把打印头定位在左边界，不卷动滚筒；另一个叫做“换行”，告诉打字机把滚筒卷一格，不改变水平位置。这就是“换行”和“回车”的由来。
2. 使用
后来，计算机发明了，这两个概念也就被般到了计算机上。那时，存储器很贵，一些科学家认为在每行结尾加两个字符太浪费了，加一个就可以。于是，就出现了分歧。
回车 \r 本义是光标重新回到本行开头，r的英文return，控制字符可以写成CR，即Carriage Return
换行 \n 本义是光标往下一行（不一定到下一行行首），n的英文newline，控制字符可以写成LF，即Line Feed
符号    ASCII码      意义
\n        10        换行NL
\r        13        回车CR
在不同的操作系统这几个字符表现不同，比如在WIN系统下，这两个字符就是表现的本义，在UNIX类系统，换行\n就表现为光标下一行并回到行首，在MAC上，\r就表现为回到本行开头并往下一行，至于ENTER键的定义是与操作系统有关的。通常用的Enter是两个加起来。
不同操作系统下的含义：
\n:  UNIX 系统行末结束符
\r\n: window 系统行末结束符
\r:  MAC OS 系统行末结束符
我们经常遇到的一个问题就是，Unix/Mac系统下的文件在Windows里打开的话，所有文字会变成一行；而Windows里的文件在Unix/Mac下打开的话，在每行的结尾可能会多出一个^M符号。
/**********************************************回车与换行*******************************************************

/*********************************************NFS服务和挂载*********************************************
服务器端
使用yum -y install nfs-utils因为centos7自带了rpcbind，所以不用安装rpc服务，rpc监听在111端口，可以使用ss -tnulp | grep 111查看rpc服务是否自动启动，如果没有启动，就systemctl start rpcbind 启动rpc服务。rpc在nfs服务器搭建过程中至关重要，因为rpc能够获得nfs服务器端的端口号等信息，nfs服务器端通过rpc获得这些信息后才能连接nfs服务器端。

vim /etc/exports
/home/nfs/ 192.168.1.0/24(rw,sync,fsid=0)
同192.168.1.0/24一个网络号的主机可以挂载NFS服务器上的/home/nfs/目录到自己的文件系统中
rw表示可读写；sync表示同步写，fsid=0表示将/data找个目录包装成根目录
/sharedata *(rw,no_root_squash,sync,insecure)
表示同局域网内的所有主机都可以挂在NFS服务器上的/sharedata/目录到自己的文件系统中

启动nfs服务，systemctl start nfs ,启动后 使用rpcinfo -p 192.168.1.188 查看

使用showmount -e localhost
Export list for localhost:
/data 192.168.1.0/24

创建/data目录添加文件,更改权限（很重要！！！！！）
mkdir /data 
touch /data/1.txt
echo "hello nfs" >> /data/1.txt
chown -R nfsnobody.nfsnobody /data

客户端
yum -y intall nfs-utils （客户端上不需要启动nfs服务，只是为了使用showmount工具）

检测rpc是否启动
systemctl status rpcbind
 
使用showmount -e 192.168.1.188查看

挂载至本地/mnt目录
mount -t nfs 192.168.1.188:/data /mnt

接下来在服务器端执行
systemctl enable nfs-server.server
systemctl enable rpcbind
让nfs，rpcbind开机自动启动

故障解决
客户端无法卸载nfs目录
umount.nfs4: /var/nfs: device is busy
执行fuser -km /var/nfs/，然后再执行umount
umount -l /home 强行解除挂载

mount.nfs: Stale file handle的解决方法
[root@lnmp02 ~]# mount -t nfs 192.168.20.6:/data /mnt
mount.nfs: Stale file handle
原因是当client端mount上了server端的directory之后，假如server端又将这个directory unshare了或者删除了，那么就会在client端出现这个错误。我前面确实删除过NFS服务端的/data目录，所以在再次挂载的时候出现了这个问题。那么应该怎么做呢？
解决方法：
[root@lnmp02 ~]# umount -lf /mnt
/*********************************************NFS服务和挂载*********************************************

/*********************************************通过yum下载rpm包及其依赖包*********************************************
通过yum下载rpm包及其依赖包（只下载不安装）
yum -y install --downloadonly --downloaddir=/home nfs-utils
downloadonly指出本次下载仅仅下载，参数downloaddir指定了保存的目录。

但是如果系统已经下载了相关安装包（包括依赖包），那么这些rpm包是无法下载保存的
可以使用如下的方式解决：
yum -y install --downloadonly --installroot=/tmp/createrepo --releasever=/ --downloaddir=/software/nfs nfs-utils

--installroot=/usr/local        表示指定自定义的安装目录（如果安装到自定义目录，会额外安装很多依赖的软件包，即使这些依赖包已经安装过，也会在你自定义的目录中重新安装）

切换到下载目录rpm中批量安装：
rpm -ivh * --nodeps --force
/*********************************************通过yum下载rpm包及其依赖包*********************************************

/*********************************************************linux tar*********************************************************
-c: 建立压缩档案
-x：解压
-t：查看内容
-r：向压缩归档文件末尾追加文件
-u：更新原压缩包中的文件

这五个是独立的命令，压缩解压都要用到其中一个，可以和别的命令连用但只能用其中一个。下面的参数是根据需要在压缩或解压档案时可选的

-z：有gzip属性的
-j：有bz2属性的
-Z：有compress属性的
-v：显示所有过程
-O：将文件解开到标准输出

下面的参数-f是必须的

-f: 使用档案名字，切记，这个参数是最后一个参数，后面只能接档案  名。
例如使用『 tar -zcvfP tfile sfile 』就是错误的写法，要写成『 tar -zcvPf tfile sfile 』才对喔！

# tar -cf all.tar *.jpg
这条命令是将所有.jpg的文件打成一个名为all.tar的包。-c是表示产生新的包，-f指定包的文件名。
# tar -rf all.tar *.gif
这条命令是将所有.gif的文件增加到all.tar的包里面去。-r是表示增加文件的意思。
# tar -uf all.tar logo.gif
这条命令是更新原来tar包all.tar中logo.gif文件，-u是表示更新文件的意思。
# tar -tf all.tar
这条命令是列出all.tar包中所有文件，-t是列出文件的意思
# tar -xf all.tar
这条命令是解出all.tar包中所有文件，-t是解开的意思

压缩
tar -cvf jpg.tar *.jpg            //将目录里所有jpg文件打包成tar.jpg 
tar -czf jpg.tar.gz *.jpg         //将目录里所有jpg文件打包成jpg.tar后，并且将其用gzip压缩，生成一个gzip压缩过的包，命名为jpg.tar.gz
tar -cjf jpg.tar.bz2 *.jpg        //将目录里所有jpg文件打包成jpg.tar后，并且将其用bzip2压缩，生成一个bzip2压缩过的包，命名为jpg.tar.bz2
tar -cZf jpg.tar.Z *.jpg          //将目录里所有jpg文件打包成jpg.tar后，并且将其用compress压缩，生成一个umcompress压缩过的包，命名为jpg.tar.Z
tar -cvzf /opt/a.tar.gz /opt/b    //将目录/opt/b压缩为/opt/a.tar.gz  
                      
解压                       
tar -xvf file.tar                 //解压 tar包
tar -xzvf file.tar.gz             //解压tar.gz
tar -xjvf file.tar.bz2            //解压 tar.bz2
tar -xZvf file.tar.Z              //解压tar.Z
tar -xzvf /file.tar.gz -C /files  //把根目录下的file.tar.gz解压到/files下，前提要保证存在/files这个目录 
/*********************************************************linux tar*********************************************************

/**********************************************************grep命令***********************************************************
grep（global search regular expression(RE) and print out the line，全面搜索正则表达式并把行打印出来）是一种强大的文本搜索工具，它能使用正则表达式搜索文本，并把匹配的行打印出来。

用法: grep [选项]... PATTERN [FILE]...
在每个 FILE 或是标准输入中查找 PATTERN。
默认的 PATTERN 是一个基本正则表达式(缩写为 BRE)。
例如: grep -i 'hello world' menu.h main.c

选项

-a 不要忽略二进制数据。
-A<显示列数> 除了显示符合范本样式的那一行之外，并显示该行之后的内容。
-b 在显示符合范本样式的那一行之外，并显示该行之前的内容。
-c 计算符合范本样式的列数。
-C<显示列数>或-<显示列数>  除了显示符合范本样式的那一列之外，并显示该列之前后的内容。
-d<进行动作> 当指定要查找的是目录而非文件时，必须使用这项参数，否则grep命令将回报信息并停止动作。
-e<范本样式> 指定字符串作为查找文件内容的范本样式。
-E 将范本样式为延伸的普通表示法来使用，意味着使用能使用扩展正则表达式。
-f<范本文件> 指定范本文件，其内容有一个或多个范本样式，让grep查找符合范本条件的文件内容，格式为每一列的范本样式。
-F 将范本样式视为固定字符串的列表。
-G 将范本样式视为普通的表示法来使用。
-h 在显示符合范本样式的那一列之前，不标示该列所属的文件名称。
-H 在显示符合范本样式的那一列之前，标示该列的文件名称。
-i 忽略字符大小写的差别。
-l 列出文件内容符合指定的范本样式的文件名称。
-L 列出文件内容不符合指定的范本样式的文件名称。
-n 在显示符合范本样式的那一列之前，标示出该列的编号。
-q 不显示任何信息。
-R/-r 此参数的效果和指定“-d recurse”参数相同。
-s 不显示错误信息。
-v 反转查找。
-w 只显示全字符合的列。
-x 只显示全列符合的列。
-y 此参数效果跟“-i”相同。
-o 只输出文件中匹配到的部分。

grep -rE '*PYTHONPATH*' ./
grep -rE --directories=recurse '*PYTHONPATH*' ./
/**********************************************************grep命令***********************************************************

####################################################【linux】grep、sed、awk####################################################
grep、sed、awk 概述
grep：文本过滤器，如果仅仅是过滤文本，可使用grep，其效率要比其他的高很多
sed：Stream EDitor，流编辑器，默认只处理模式空间，不处理原数据，如果你处理的数据是针对行进行处理的，可以使用sed
awk：报告生成器，格式化以后显示。如果对处理的数据需要生成报告之类的信息，或者你处理的数据是按列进行处理的，最好使用awk

grep
Linux系统中grep命令是一种强大的文本搜索工具，它能使用正则表达式搜索文本，并把匹 配的行打印出来。grep全称是Global Regular Expression Print，表示全局正则表达式版本，它的使用权限是所有用户。

sed
sed 是一种在线编辑器，它一次处理一行内容。处理时，把当前处理的行存储在临时缓冲区中，称为“模式空间”（pattern space），接着用sed命令处理缓冲区中的内容，处理完成后，把缓冲区的内容送往屏幕。接着处理下一行，这样不断重复，直到文件末尾。文件内容并没有改变，除非你使用重定向存储输出。Sed主要用来自动编辑一个或多个文件；简化对文件的反复操作；编写转换程序等。

awk
awk是一个强大的文本分析工具，相对于grep的查找，sed的编辑，awk在其对数据分析并生成报告时，显得尤为强大。简单来说awk就是把文件逐行的读入，以空格为默认分隔符将每行切片，切开的部分再进行各种分析处理。 
awk有3个不同版本: awk、nawk和gawk，未作特别说明，一般指gawk，gawk是 AWK的 GNU版本

sed命令：
利用sed命令来删除文件中带字符"2"的行：
sed '/2/d' roc.txt
这个命令的command部分是/2/d，而且它是用单引号括起来的。用到sed，别忘了用单引号将command部分括起来。/2/d中的d表示删除，意思是说，只要某行内容中含有字符2，就删掉这一行。（sed所谓的删除都是在模式空间中执行的，不会真正改动roc.txt原文件。）

sed命令实现cut命令的效果
head -n 5 /etc/passwd | sed 's/:.*$//'
command部分指定成了's/：.*$//'，表示要把每一行的第一个冒号到结尾的部分都清空，这样留下的便是第一个冒号前的内容。
's/XXXX/YYYY/'是vi命令中的替换，表示将XXXX替换为YYYY

sed会将模式空间里的行经过处理后输出到标准输出，这是默认的处理方式。也就是说，除非你使用“d”来删除此行，否则经过“模式空间”处理的行都是会被输出到标准输出（屏幕）上的。例：
原文件的内容
[roc@roclinux ~]$ cat roc.txt
1
2
3
4
5
输出中出现了两个“4”
[roc@roclinux ~]$ sed '/4/p' roc.txt
1
2
3
4
4
5
所有的原始文件内容都被输出来了，而且含有字符4的行被输出了两遍。这就是sed命令的工作原理，它会把经过处理的行先输出出来，然后再执行后面的动作。（在这里我们设定了p，表示打印此行。）这明显不符合我们的初衷，我们只是想让sed命令找到含有4的行再输出。
加上-n选项后发现，结果变得如你所愿了。
[roc@roclinux ~]$ sed -n '/4/p' roc.txt
4
-n选项表示：除非是明确表明要输出的行，否则不要输出。-n选项经常和p配合使用，其含义就是，输出那些匹配的行。

sed命令的命令格式是这样的：
$ sed command file
其中，command部分是sed命令的精髓，对command部分的掌握程度决定了你是不是sed高手。
command部分可以分为两块知识：一块是范围设定，一块是动作处理。
范围设定，可以采用两种不同的方式来表达：
    指定行数：比如'3,5'表示第3、第4和第5行；而'5,$'表示第5行至文件最后一行。
    模式匹配：比如/^[^dD]/表示匹配行首不是以d或D开头的行。
而动作处理部分，会提供很丰富的动作供你选择，下面就来介绍几个最常用的动作吧：
    d：表示删除行。
    p：打印该行。
    r：读取指定文件的内容。
    w：写入指定文件。
    a：在下面插入新行新内容。

显示test文件的第10行到第20行的内容
[roc@roclinux ~]$ sed -n '10,20p' test

所有以d或D开头的行里的所有小写x字符变为大写X字符：
[roc@roclinux ~]$ sed '/^[dD]/s/x/X/g' test

这个用法表示我们在command部分采用了/AA/s/BB/CC/g的语法格式，这表示我们要匹配到文件中带有AA的行，并且将这些行中所有的BB替换成CC。
删除每行最后的两个字符
[roc@roclinux ~]$ sed 's/..$//' test

在sed命令中，&字符表示的是"之前被匹配的部分"
先展示文件的内容
[roc@roclinux ~]$ cat mysed.txt
Beijing
London
使用&符号替换后的结果
[roc@roclinux ~]$ sed 's/B.*/&2008/' mysed.txt
Beijing2008
London

在sed命令中，小括号'()'称之为"sed的预存储技术"，也就是命令中被"("和")"括起来的内容会被依次暂存起来，存储到\1、\2…里面。这样你就可以使用'\N'形式来调用这些预存储的内容了。例：
[roc@roclinux ~]$ echo "hello world" | sed 's/\(hello\).*/world \1/'
world hello

-e选项来设置多个command
sed命令可以包含不只一个command。如果要包含多个command，只需在每个command前面分别加上一个-e选项即可。例：
通过2个-e选项设置了两个command
[roc@roclinux ~]$ sed -n -e '1,2p' -e '4p' mysed.txt
Beijing 2003
Beijing 2004
Beijing 2006
-e选项的后面要立即接command内容，不允许再夹杂其他选项。多个command之间，是按照在命令中的先后顺序来执行的。

awk命令：
awk是逐行处理的，意思就是说：当awk处理一个文本时，会一行一行进行处理，处理完当前行，再处理下一行，awk默认以"换行符"为标记，识别每一行，也就是说，awk每次遇到"回车换行"就认为是当前行的结束，新的一行的开始，awk会按照用户指定的分隔符去分割当前行，如果没有指定分隔符，默认使用空格作为分隔符。（分割完的第一个字段为$1，第二个字段为$2依次类推，用$0表示当前处理的整个一行）

awk '{action}' {filenames} # 行匹配语句awk只能用单引号。
例：
$ cat log.txt
2 this is a test
3 Are you like awk
This's a test
10 There are orange,apple,mongo
# 每行按空格或TAB分割（默认情况），输出文本中的1、4项
$ awk '{print $1,$4}' log.txt
2 a
3 like
This's
10 orange,apple,mongo

awk -F #-F相当于内置变量FS, 指定分割字符。
例：
$ cat log.txt的内容如下：
2,this,is,a,test
3 Are you like awk    
$  awk -F, '{print $1,$2}'   log.txt
2 this
3 Are you like awk
# 使用多个分隔符：先使用空格分割，然后对分割结果再使用","分割
$ awk -F '[ ,]'  '{print $1,$2,$5}'   log.txt
2 this
3 Are

awk -v # 设置变量。
例：
$ cat log.txt
2 this is a test
3 Are you like awk
This's a test
10 There are orange,apple,mongo
$ awk -va=1 '{print $1,$1+a}' log.txt
2 3
3 4
This's 1
10 11
$ awk -va=1 '{print $1,$(1+a)}' log.txt
2 this
3 Are
This's a
10 There
$ awk -va=1 -vb=s '{print $1,$1+a,$1b}' log.txt
2 3 2s
3 4 3s
This's 1 This'ss
10 11 10s
$1+a：当两个变量都为数字的时候当数字运算，当有一方为String的时候当字符串拼接处理。

awk 'Pattern {action}' {filenames} # Pattern用来指定判断条件，{}中包含的是awk的动作，也就是awk对记录的操作，比如$3+$4或print。
例：
$ awk '$1>2' log.txt    #命令
#输出
3 Are you like awk
This's a test
10 There are orange,apple,mongo
例：
$ awk '$1==2 {print $1,$3}' log.txt    #命令
#输出
2 is
例：
$ awk '$1>2 && $2=="Are" {print $1,$2,$3}' log.txt    #命令
#输出
3 Are you

####################################################【linux】grep、sed、awk####################################################

/***********************************************yum安装时需要安装到指定的文件夹***********************************************
yum install --installroot=/usr/local/vim vim
/***********************************************yum安装时需要安装到指定的文件夹***********************************************


/*******************************************************用户以及组*******************************************************
//查看当前登录用户所属组
groups

//查看Linux某用户属于哪个组
id  user(用户名)
groups user(用户名)

//查看当前登录用户名
whoami

//etc目录下的group文件包含所有组
/etc/group 

//新建test工作组
groupadd test 

//删除用户组
groupdel groupname

gpasswd命令
功能：管理组
用法：gpasswd[-a user][-d user][-A user,...][-M user,...][-r][-R]groupname
参数：
-a：添加用户到组
-d：从组删除用户
-A：指定管理员
-M：指定组成员和-A的用途差不多
-r：删除密码
-R：限制用户登入组，只有组中的成员才可以用newgrp加入该组 

//修改用户所属组
usermod -g groupA user
-g 用户组 指定用户所属的用户组。
-G 附加组 指定用户所属的附加组。

//修改文件或者文件夹的所有者和所属组。
chown -R ubsadm(用户名):users(所属组) /home/ubsadm
-R 表示递归遍历子目录，把修改应用到目录下所有文件和子目录

//添加新的用户账号使用 useradd命令，其语法如下： 
useradd 选项 用户名
其中各选项含义如下：
代码:
-c comment 指定一段注释性描述。
-d 目录 指定用户主目录，如果此目录不存在，则同时使用-m选项，可以创建主目录。
-g 用户组 指定用户所属的用户组。
-G 用户组，用户组 指定用户所属的附加组。
-s Shell文件 指定用户的登录Shell。
-u 用户号 指定用户的用户号，如果同时有-o选项，则可以重复使用其他用户的标识号。
例1：
useradd -g dl4juser –d /home/dl4juser -m dl4juser
其中-m选项用来为创建用户dl4juser， -d选项表示为用户dl4juser产生一个主目录/usr/dl4juser（/usr为默认的用户主目录所在的父目录）。
passwd dl4juser 给已创建的用户dl4juser设置密码
例2：
# useradd -s /bin/sh -g group –G adm,root gem
此命令新建了一个用户gem，该用户的登录Shell是/bin/sh，它属于group用户组，同时又属于adm和root用户组，其中group用户组是其主组。
# passwd username
修改用户的密码

关于#!/bin/bash和#!/bin/sh
#!/bin/bash是指此脚本使用/bin/bash来解释执行。
其中，#!是一个特殊的表示符，其后，跟着解释此脚本的shell路径。
bash只是shell的一种，还有很多其它shell，如：sh,csh,ksh,tcsh,...
我们可以通过以下一个示例来进行实验，了解#!/bin/bash的使用。
除第一行外，脚本中所有以“#”开头的行都是注释。
1）#!/bin/bash只能放在第一行，如果后面还有#!，那么只能看成是注释。
这里有三个脚本（脚本都要使用”chmod +x scriptname“命令来获得可执行权限）：
tbash1.sh:
#!/bin/sh
source abc
echo "hello abc"
 
tbash2.sh:
#!/bin/bash
source abc
echo "hello abc"
 
tbash3.sh:
source abc
echo "hello abc"
 
三个脚本执行的结果：
[nsvc@localhost other]$ ./tbash1.sh 
./tbash1.sh: line 2: abc: No such file or directory
注：当source命令执行有问题时，sh不再往下面执行。
[nsvc@localhost other]$ ./tbash2.sh 
./tbash2.sh: line 2: abc: No such file or directory
hello abc
注：当source命令执行有问题时，bash继续执行下面命令。
[nsvc@localhost other]$ ./tbash3.sh 
./tbash3.sh: line 1: abc: No such file or directory
hello abc
注：自身登录系统所在的shell是bash。所以，当source命令执行有问题时，bash继续执行下面命令。
 
如果将tbash1.sh改成：
echo "abc"
#!/bin/sh
source abc
echo "hello abc"
那么，执行结果是：
[nsvc@localhost other]$ ./tbash1.sh 
abc
./tbash1.sh: line 3: abc: No such file or directory
hello abc
也就是说，脚本忽略了第二行“#!/bin/sh"，直接使用当前所在的shell（也就是bash）来解释脚本。
 
当把tbash1.sh改成：
#!/bin/sh
#!/bin/bash
source abc
echo "hello abc"
执行结果为：
[nsvc@localhost other]$ ./tbash1.sh 
./tbash1.sh: line 3: abc: No such file or directory
当执行完source命令时，并没有往下执行。说明，#!/bin/sh这一行起到作用了，但#!/bin/bash并没有起作用。在脚本中，除第一行外，脚本中所有以“#”开头的行都是注释。
 
2）#!后面的路径一定要正确，不正确会报错。
假如，我们把tbash1.sh中第一行的#!后面加了一个不存在的路径”/home/sh“：
#!/home/sh
source abc
echo "hello abc"
执行结果为：
[nsvc@localhost other]$ ./tbash1.sh 
-bash: ./tbash1.sh: /home/sh: bad interpreter: No such file ordirectory
系统会提示/home/sh的路径不存在。
 
3）如果一个脚本在第一行没有加上#!+shell路径这一行，那么，脚本会默认当前用户登录的shell，为脚本解释器。
在1）中，脚本tbash3.sh的执行结果，就是用当前自己登录的shell（bash）解释后的结果。我们通常所用的shell都是bash，如果哪天登录到sh，再使用以上类型的脚本，就会有问题。以下是自己登录到sh下，执行tbash3.sh的结果：
-sh-3.2$ ./tbash3.sh 
./tbash3.sh: line 1: abc: 没有那个文件或目录
与1）中的执行结果是不一样的。
因此，大家应该养成脚本首行加上#!+shell路径的习惯。
 
4）/bin/sh相当于/bin/bash --posix
我们将脚本tbash1.sh改为：
#!/bin/bash --posix
source abc
echo "hello abc"
执行结果：
[nsvc@localhost other]$ ./tbash1.sh 
./tbash1.sh: line 2: abc: No such file or directory
与tbash1.sh原脚本执行的结果一样。
 
我们还可以以tbash3.sh为示例。
用以下命令来执行该脚本：
[nsvc@localhost other]$ bash tbash3.sh
tbash3.sh: line 1: abc: No such file or directory
hello abc
[nsvc@localhost other]$ sh tbash3.sh 
tbash3.sh: line 1: abc: No such file or directory
[nsvc@localhost other]$ bash --posix tbash3.sh 
tbash3.sh: line 1: abc: No such file or directory
 "bash tbash3.sh"表示使用bash来作为脚本解释器来执行tbash3.sh。同样，也可以使用如”sh脚本名“这样的命令，来用sh作为脚本解释器。
从结果可以看出，/bin/bash--posix与/bin/sh的执行结果相同。总结起来，sh跟bash的区别，实际上是bash有没开启posix模式的区别。遵守posix规范，可能包括，”当某行代码出错时，不继续往下执行。“
 
最后加上一点说明，每个脚本开头都使用"#!"，#!实际上是一个2字节魔法数字，这是指定一个文件类型的特殊标记，在这种情况下，指的就是一个可执行的脚本。在#!之后，接一个路径名，这个路径名指定了一个解释脚本命令的程序，这个程序可以是shell，程序语言或者任意一个通用程序。

//删除用户
userdel test //删除用户，但不删除其相关文件
userdel -r test //删除用户的同时，删除其相关文件
/*******************************************************用户以及组*******************************************************

/*****************************************************为每个用户定义PATH*****************************************************
用户登录时先加载/etc/profile里面设置的path，然后再加载自己目录下.bash_profile文件里面设置的path
利用这一点，可以为每个用户创立一套自己的环境变量
1） 在用户自己的目录中vi .bash_profile这个隐藏文件
cat /home/dl4juser/.bash_profile

2)  用自定义的path覆盖/etc/profile里面定义过的path(这个2个是自己用的$HOME/.local/bin:$HOME/bin)

if [ -f ~/.bashrc ]; then
        . ~/.bashrc
fi
#这里可以完全自定义出一套当前用户的PATH
PATH=/usr/local/bin:/usr/bin:/bin:/usr/bin/X11:/usr/X11R6/bin:/usr/games:/usr/lib/mit/bin:/usr/lib/mit/sbin:$HOME/.local/bin:$HOME/bin
exprot PATH
/*****************************************************为每个用户定义PATH*****************************************************

/***************************************************CentOS 7网络配置*******************************************************
VirtualBox里面要设置虚拟机可以访问外网，并且虚拟机虚拟机之间，虚拟机和宿主机之间可以通信的话必须设置2片网卡
第一片网卡在【VirtualBox-->管理-->全局设定-->网络-->NAT网络】里面设置。系统默认是这片网卡：enp0s3
第二片网卡在【VirtualBox-->管理-->全局设定-->网络-->仅主机(Host-Only)网络】里面设置 拷贝/etc/sysconfig/network-scripts/enp0s3重命名成enp0s8
enp0s3是上网的网卡，enp0s8是和宿主机通讯的网卡
然后修改每台虚拟机的【设置-->网络-->网卡1，网卡2】里面的设置：1)勾选启动网络连接 2)连接方式网卡1:网络地址转化(NAT);网络2:仅主机(Host-Only)网络

默认CentOS 7只有ifcfg-enp0s3的配置文件,enp0s3是用来管理上网的网卡
/etc/sysconfig/network-scripts/ifcfg-enp0s3
TYPE="Ethernet"
BOOTPROTO="dhcp"
DEFROUTE="yes"
PEERDNS="yes"
PEERROUTES="yes"
IPV4_FAILURE_FATAL="no"
IPV6INIT="yes"
IPV6_AUTOCONF="yes"
IPV6_DEFROUTE="yes"
IPV6_PEERDNS="yes"
IPV6_PEERROUTES="yes"
IPV6_FAILURE_FATAL="no"
IPV6_ADDR_GEN_MODE="stable-privacy"
NAME="enp0s3"
UUID="d50fbebb-e4ca-4b21-833d-0b7565a11915"
DEVICE="enp0s3"
ONBOOT="yes"

如果要配置和宿主机通讯则需要拷贝enp0s3的信息再配置一块网卡(一般命名为:enp0s8) 
需要修改的地方：
1) HWADDR从VirtualBox能查到
2) BOOTPROTO改成static
3) UUID随便改一位只要和enp0s3中的不一样即可
4) NAME和DEVICE都改成enp0s8
5) IPADDR="192.168.56.110" // 设置成和【VirtualBox-->管理-->全局设定-->网络-->仅主机(Host-Only)网络】里面设置的网络保持同一网段
6) NETMASK="255.255.255.0" // 设置成和【VirtualBox-->管理-->全局设定-->网络-->仅主机(Host-Only)网络】里面设置的服务器网络掩码
7) NM_CONTROLLED="no" //表示该接口将通过该配置文件进行设置，而不是通过网络管理器进行管理；如果设置为yes的话那配置的ifcfg-enp0s8将没有效果
/etc/sysconfig/network-scripts/ifcfg-enp0s8
HWADDR="08:00:27:F3:C0:DA"
TYPE="Ethernet"
BOOTPROTO="static"
DEFROUTE="yes"
PEERDNS="yes"
PEERROUTES="yes"
IPV4_FAILURE_FATAL="no"
IPV6INIT="yes"
IPV6_AUTOCONF="yes"
IPV6_DEFROUTE="yes"
IPV6_PEERDNS="yes"
IPV6_PEERROUTES="yes"
IPV6_FAILURE_FATAL="no"
IPV6_ADDR_GEN_MODE="stable-privacy"
NAME="enp0s8"
UUID="d50fbebb-e4ca-4b21-833d-0b7565a11916"	
DEVICE="enp0s8"
ONBOOT="yes"
IPADDR="192.168.56.110"
NETMASK="255.255.255.0"
NM_CONTROLLED="no"

不使用网络管理配置静态IP地址:
进入/etc/sysconfig/network-scripts目录，找到该接口的配置文件（ifcfg-enp0s3）。如果没有，请创建一个。
打开配置文件并编辑以下变量：
“NM_CONTROLLED=no”表示该接口将通过该配置文件进行设置，而不是通过网络管理器进行管理。
“ONBOOT=yes”告诉我们，系统将在启动时开启该接口。
service network restart

使用网络管理器配置静态IP地址
如果你想要使用网络管理器来管理该接口，你可以使用nmtui（网络管理器文本用户界面），它提供了在终端环境中配置配置网络管理器的方式。
在使用nmtui之前，首先要在/etc/sysconfig/network-scripts/ifcfg-enp0s3中设置“NM_CONTROLLED=yes”。
然后继续去编辑enp0s3接口的网络管理器配置：nmtui edit enp0s3
我们可以手动输入与/etc/sysconfig/network-scripts/ifcfg-enp0s3中所包含的内容相同的信息。
使用箭头键在屏幕中导航，按回车选择值列表中的内容（或填入想要的内容），最后点击屏幕底部右侧的确定按钮。
最后，重启网络服务：systemctl restart network.service
/***************************************************CentOS 7网络配置*******************************************************

/****************************************************************免密登陆*****************************************************
一、概述
1、就是为了让两个linux机器之间使用ssh不需要用户名和密码。采用了数字签名RSA或者DSA来完成这个操作
2、模型分析：假设A为客户机器，B为目标机；要达到的目的：A机器ssh登录B机器无需输入密码；加密方式选 rsa|dsa均可以，默认dsa
二、具体操作流程
单向登陆的操作过程（能满足上边的目的）：
1、登录A机器 
2、ssh-keygen -t [rsa|dsa]，将会生成密钥文件和私钥文件id_rsa,id_rsa.pub或id_dsa,id_dsa.pub（一路回车，既可完成生成私钥和公钥）
3、将.pub文件复制到B机器的.ssh目录，并cat id_dsa.pub >> /root/.ssh/authorized_keys
4、.ssh目录的权限必须是700，chmod 700 .ssh；授权列表authorized_keys的权限必须是600，chmod 600 authorized_keys 
5、大功告成，从A机器登录B机器的目标账户，不再需要密码了；（直接运行 #ssh B机器的IP ）
上面只将公钥拷贝并且追加到了/root/.ssh/authorized_keys中所以只是在A机器中用root用户登陆B机器时免密，而其他B机器的用户（如：admin）从A机器登陆B机器的时候还是需要密码，要想在A机器用B机器的用户admin登陆的时候也实现免密登陆则需要将A机器生成的公钥也拷贝追加到/home/admin/.ssh/authorized_keys中
/****************************************************************免密登陆*****************************************************

/********************************************************vi文本编辑器********************************************************
1) 最基本用法
vi  somefile.4
1、首先会进入“一般模式”，此模式只接受各种快捷键，不能编辑文件内容
2、按i键，就会从一般模式进入编辑模式，此模式下，敲入的都是文件内容
3、编辑完成之后，按Esc键退出编辑模式，回到一般模式；
4、再按：，进入“底行命令模式”，输入wq命令，回车即可

2) 一些常用快捷键
一些有用的快捷键（在一般模式下使用）：
a  在光标后一位开始插入
A   在该行的最后插入
I   在该行的最前面插入
gg   直接跳到文件的首行
G    直接跳到文件的末行
dd   删除行，如果  5dd   ，则一次性删除光标后的5行
yy  复制当前行,  复制多行，则  3yy，则复制当前行附近的3行
p   粘贴
v  进入字符选择模式，用方向键进行文本选择，完成后，按y复制，按p粘贴
ctrl+v  进入块选择模式，选择完成后，按y复制，按p粘贴
shift+v  进入行选择模式，选择完成后，按y复制，按p粘贴
在底行命令模式下，输入:.,$d再按回车，表示从当前行到末行全部删除掉。

3) 查找并替换（在底行命令模式中输入）
/pattern         从光标开始处向文件尾搜索pattern
?pattern         从光标开始处向文件首搜索pattern
n                在同一方向重复上一次搜索命令
N                在反方向上重复上一次搜索命令
%                查找配对的括号（将光标停顿在"{"上按%，即可定位到对应的"}"上。相反，光标停顿在"}"上按%即可定位到对应的"{"上咯。）
:s/p1/p2/g       将当前行中所有p1均用p2替代，若要每个替换都向用户询问则应该用gc选项
:n1,n2s/p1/p2/g  将第n1至n2行中所有p1均用p2替代
:g/p1/s//p2/g    将文件中所有p1均用p2替换
.*[]^%~$         在Vi中具有特殊含义，若需要查找则应该加上转义字符"\"

%s/sad/88888888888888     效果：查找文件中所有sad，替换为88888888888888

1:  :s/vivian/sky/         #替换当前行第一个 vivian 为 sky
2:  :s/vivian/sky/g        #替换当前行所有 vivian 为 sky
3:  :n,$s/vivian/sky/      #替换第 n 行开始到最后一行中每一行的第一个 vivian 为 sky
4:  :n,$s/vivian/sky/g     #替换第 n 行开始到最后一行中每一行所有 vivian 为 sky（n 为数字，若 n 为 .，表示从当前行开始到最后一行） 
7:  :%s/vivian/sky/        #（等同于 :g/vivian/s//sky/） 替换每一行的第一个 vivian 为 sky
8:  :%s/vivian/sky/g       #（等同于 :g/vivian/s//sky/g） 替换每一行中所有 vivian 为 sky

%s/four/4/g
↑         ↑
|         +-- 替换行中所有的匹配项目
在所有行中执行替换

:%s/\<four\>/4/gc    //只替换 four
                ↑
                在每次替换前提示确认

/you       效果：查找文件中出现的you，并定位到第一个找到的地方，按n可以定位到下一个匹配位置（按N定位到上一个）

vi 文件名，打开文件后
如果要显示所有行号，使用 :set nu
如果要显示当前行号，使用 :nu
如果要跳转到指定行，使用 :行号
例如，跳转到第10行，使用 :10

vim列编辑模式


在使用vim时，我们可能有这样的需求，在文件的某一列或几列加上统一的字符，比如写shell脚本时，需要注释掉某段程序，或者删除某一列或几列上的字符，比如删除之前添加的注释符。手工一个个整肯定是要把人整疯的，还好vim本身有支持列编辑。下面介绍一下如何实现一列的添加和删除。

添加一列：
1）vim 打开文件，并移动光标到要添加列的起始行
2）按下ctrl+v，打开visual模式
3）通过光标向下选中你要添加内容的位置
4）按下I（即shift＋i）键，然后输入你要插入的内容
5）按下ESC键，大概1s后，你就能看到内容加上了

删除一列：
1）vim打开文件，并移动光标到要删除列所在的启示位置
2）按下ctrl＋v，进入visual模式
3）通过移动光标，选中你要删除的区域
4）按下d键完成删除

同理，如果你要在一个区域内添加或者删除内容，只需要在上面的第3步选择你要操作的区域即可。

Vi 撤销 回退 操作
在一般模式下：
u   撤销上一步的操作
Ctrl+r 恢复上一步被撤销的操作
/*******************************************************vi文本编辑器*******************************************************

/*******************************************************vim查看文件字符编码和转换编码*******************************************************
一，查看文件编码：
1.在Vim中可以直接查看文件编码:set fileencoding即可显示文件编码格式。
如果你只是想查看其它编码格式的文件或者想解决用Vim查看文件乱码的问题，那么你可以在~/.vimrc文件中添加以下内容：set encoding=utf-8 fileencodings=ucs-bom,utf-8,cp936这样，就可以让vim自动识别文件编码（可以自动识别UTF-8或者GBK编码的文件），其实就是依照fileencodings提供的编码列表尝试，如果没有找到合适的编码，就用latin-1(ASCII)编码打开。
二，文件编码转换
在Vim中直接进行转换文件编码,比如将一个文件转换成utf-8格式====>:set fileencoding=utf-8然后输入:wq保存退出即可
/*******************************************************vim查看文件字符编码和转换编码*******************************************************

/*******************************************************vim处理windows文件回车符*******************************************************
通常情况下，我们在linux中使用vim打开window环境下编辑的文件文本时，行尾不会显示出在linux环境下多除的"\r"(window下回车符)字符。这是因为vim打开此文件时自动转换为linux的格式进行显示。如要让其显示出来，可以使用e ++ff=unix %命令。实际显示会是“^M”代表"\r"。
虽然vim在显示window格式文本时，会自动处理"\r“字符。但实际我们使用wq命令保存退出时，其并不会自动将"\r”字符去掉，保存成linux格式的文件。这样就会导致一些问题。比如window下编辑的shell脚本，在linux环境下无法执行会报如下类似错误：
./test.sh: 行 2: $'\r': 未找到命令
./test.sh: 行 8: $'\r': 未找到命令
./test.sh: 行 17: $'\r': 未找到命令
 这样就需要我们做格式转换。
方法1如下：
1.vim tesh.sh 打开文件
2.输入：e ++ff=unix % 命令显示window下的回车符（\r），这时每行尾会显示^M字符，此字符就表示windows下的回车符。
3.输入：%s/^M//g 替换命令将回车符去掉。注意^M的输入方法是键盘Ctrl + V (^) 加上 Ctrl + M（M）
4.输入：wq保存文件并退出
方法2如下:
1.利用sed -i 's/\r$//' test.sh 命令直接修改文件。
方法3如下：
1.vim test.sh 打开文件
2.输入：set fileformat=unix
3.输入：wq保存并退出
/*******************************************************vim处理windows文件回车符*******************************************************

/*******************************************************查看文件内容*******************************************************
Cat
[功能说明]
cat本身是一个串接命令，把指定一个或多个源文件的内容，利用>符号重定向到目标文件中，如果不指定重定向文件，则默认在标准输出设备上显示。此时，可以利用cat命令来显示文件的内容。若源文件定向到屏幕上，则以连续滚动的方式显示文件内容。如果文件太大，只能看见满屏的字符滚动，看不清文件的内容，所以cat命令适合查看内容不满一屏的文件
[语法格式]
Cat[参数][源文件][>|>>重定向的文件名]
[选项参数]
参数      说明
-n        所有输出的行数编号
-b        和-n类似，但不对空白行编号
-s        输出多行空白，即当遇到有连续两行以上空白，就替换成一行空白行
-E        在每行结尾显示$符号
-T        将文件中的tab建显示为^I（i的大写）
-v        显示非打印的字符
-t ;-a    等于-Vt；等于-VEt
--version 显示版本信息并退出
--help    显示帮助信息并退出

Head
[功能说明]
如果只需要查看文件头部的内容，利用more和less命令也可以实现，但是用户必须从一屏幕的内容里面提取自己需要的信息，幸运的是，Linux提供了一个方便查看文件头部的命令-head
[语法格式]
Head[参数][文件名]
[选项参数]
参数               说明
-<N>               指定显示的行数
-n<N>或--lines=<N> 显示目标文件的前N行，若N前面加“-”则表示显示除文件最后N行的其他所有行
-c<N>或--bytes=<N> 显示目标文件的前N行字节，若N前面加“-”则表示显示除文件最后Nbyter行的其他所有内容
-v或-verbose       总是打印文件名
--hele             显示帮助信息并退出
--version          显示版本信息并退出

More
[功能说明]
more和cat相反，适合查看大文件，因为more分屏显示文件的内容，默认情况下每次显示一屏。输入空格后，继续显示下一屏数据，而按Enter只显示下一行数据。用户可以利用Enter建逐行查看文件的内容。输入q，即可退出more命令。
[语法格式]
More[参数][文件名]
[选项参数]
参数 说明
-d   在屏幕底部显示press space to continue，‘q’to quit，对于不熟悉more命令的用户非常方便
-c   该参数定义了每次显示从屏幕的最顶部显示文件的内容，即不以滚动的方式显示文件内容，但要先清楚原来的行，然后再显示新的内容
-p   和-c类似，不同的是，先显示内容，再清空原有的行
+<起始行数>   从给定的起始行显示文件的内容，比如more：+90：file,则file的内容将从90行开始显示，该参数可以帮助用户迅速定位到查看文件的位置，省去逐页翻屏的麻烦
-<屏幕行数>	
该参数用设置屏幕大小，即一屏多少行：Linux系统默认的是一屏22行，用户可以根据自己的喜好设定屏幕的大小
-s   和cat命令一样，不输出多行空白
+/<关键字> 如果用户只关心文件中某关键字和词组，如果肉眼逐行观察，显示是低效的，但利用该参数定位要查询的关键字和词组，系统将跳过前面的行，直接从该关键字第一次出现的前两行显示的内容，若关键字位于前两行，则从前一行显示
每屏显示完，可以输入相应的参数来控制文件的范围或者退出more命令。例如输入i，可以面对从下屏的第i行开始显示，输入d，用来半屏半屏的显示文件的内容
[选项参数]
参数   说明
i      从下屏的第i行开始显示
Ctrl+d 半屏半屏的显示文件的内容
d	   同上
i+s    先输入行数i，然后输入s，系统跳过i行后再显示一屏
h      显示帮助文件
=      显示当前的行
q      退出more命令

Less
[功能说明]
less命令的作用与more命令十分相似，都可以用来浏览文件的内容。不同的是，less命令允许用户往来滚动浏览已经看过的内容
[语法格式]
Less[参数][文件名]
[选项参数]
参数       说明
-c         从顶部刷新屏幕，并显示文件内容，而不是通过底部滚动完成刷新
-f         强制打开文件，并且二进制文件在显示时不提示警告
-i         搜索时，忽略大小写，除非搜索串中包含大写字母
-I         搜索时，忽略大小写，除非搜索串中包含小写字母
-m         显示读取文件的百分比
-M         显示读取文件的百分比，行号及总行数
-N         在每行前输出行号
-p:pattern 用来搜索指出的字符串。例如，在/etc/passwd目录中搜索字符串userl，就用less -p userl  /etc/passwd,这样该文件中所有的字符串userl将反色显示
-s         把连续多个空白行作为一个空白行显示
-Q         在终端下不响铃
--help     获得在线帮助
和more命令一样，进入less后可输入相应的动作命令来控制文件的显示范围或者退出less命令。相对more命令，less命令参数相对丰富一些，不仅可以灵活地查看文件的内容，还可以调用vi编辑器对文本进行编辑，具体参数如下
-h或-H       显示这些命令的帮助信息
Enter        向下移动一行
y            向上移动一行
空格或^V或^F 向下滚动一屏
b            向上滚动一屏
d            向下滚动半屏
h            帮助信息
u            向上滚动半屏
w<n>         可以指定从哪行开始显示，即从指定数字的下一行显示，例如，若指定的是6，则从第七行显示
g            跳到第一行
G            跳到最后一行
pn           跳到n%处。例如，n为30，也就是说从整个文件内容的30%处开始显示
/pattern     搜索指定字符串，例如/root表示在文件中搜索root字符串
v            调用vi
q            退出less
!command     调用shell，可按任意键返回到显示文件的屏幕。例如！Ls显示当前目录下的所有文件。

Tail
[功能说明]
#tail和head命令相反，默认显示文件末10行，同样也可以设定显示的行数
[语法格式]
Tail[参数][文件名]
[选项参数]
参数               说明
--retry            当执行tail命令时，文件变的不可读，可利用此参数试图打开
-f或--follwe[{name|descriptor}] 随着文件的增长，显示文件新追加的内容，比如对于查看日志文件的内容，但是日志文件时动态增长的，利用该参数就可以显示改变的文件内容
-F                 其功能等同于--follow和--retry
-n<N>或--lines=<N> 显示目标文件的后N行，而不是系统默认的后10行
-c<N>或--bytes=<N> 显示目标文件的后N行内容
-<行数>            指定显示文件的末尾行数
+<行数>            从给定的行数进行显示，直到文件的末尾
/*******************************************************查看文件内容*******************************************************

/***********************************************nc在centos7上的安装和简单使用***********************************************
yum install nmap-ncat.x86_64

nc -lk 8888
/***********************************************nc在centos7上的安装和简单使用***********************************************

/****************************************shell 1>&2 2>&1 &>filename重定向的含义和区别****************************************
0 是一个文件描述符，表示标准输入(stdin)
1 是一个文件描述符，表示标准输出(stdout)
2 是一个文件描述符，表示标准错误(stderr)

在标准情况下, 这些FD分别跟如下设备关联:
stdin(0): keyboard 键盘输入,并返回在前端
stdout(1): monitor 正确返回值 输出到前端
stderr(2): monitor 错误返回值 输出到前端

举例说明
当前目录只有一个文件 a.txt.
[root@redhat box]# ls
a.txt
[root@redhat box]# ls a.txt b.txt
ls: b.txt: No such file or directory
a.txt
由于没有b.txt这个文件, 于是返回错误值, 【ls: b.txt: No such file or directory】就是所谓的2输出
而【a.txt】这个就是所谓的1输出

再接着看
[root@redhat box]# ls a.txt b.txt 1>file.out 2>file.err
执行后,没有任何返回值. 原因是, 返回值都重定向到相应的文件中了,而不再前端显示 
[root@redhat box]# cat file.out
a.txt 
[root@redhat box]# cat file.err
ls: b.txt: No such file or directory
一般来说, "1>" 通常可以省略成 ">".
即可以把如上命令写成: ls a.txt b.txt >file.out 2>file.err

有了这些认识才能理解 "1>&2" 和 "2>&1".
1>&2 正确返回值传递给2输出通道 &2表示2输出通道
如果此处错写成 1>2, 就表示把1输出重定向到文件2中.
2>&1 错误返回值传递给1输出通道, 同样&1表示1输出通道.
举个例子.
[root@redhat box]# ls a.txt b.txt 1>file.out 2>&1
[root@redhat box]# cat file.out
ls: b.txt: No such file or directory
a.txt
现在, 正确的输出和错误的输出都定向到了file.out这个文件中, 而不显示在前端.
补充下, 输出不只1和2, 还有其他的类型, 这两种只是最常用和最基本的.
/****************************************shell 1>&2 2>&1 &>filename重定向的含义和区别****************************************

####################################################文件描述符与socket连接####################################################
文件描述符与socket连接
每个进程开启一个soeket连接，都会占用一个文件描述符。

1. 概述
在Linux系统中一切皆可以看成是文件，文件又可分为：普通文件、目录文件、链接文件和设备文件。
文件描述符（file-descriptor）是内核为了高效管理已被打开的文件所创建的索引，其是一个非负整数（通常是小整数），用于指代被打开的文件，所有执行I/O操作(包括网络socket操作)的系统调用都通过文件描述符。
程序刚刚启动的时候，0是标准输入，1是标准输出，2是标准错误。如果此时去打开一个新的文件，它的文件描述符会是3。POSIX标准要求每次打开文件时（含socket）必须使用当前进程中最小可用的文件描述符号码，因此，在网络通信过程中稍不注意就有可能造成串话。标准文件描述符图如下：
文件描述符  用途      POSIX名称      stdio流
0           标准输入  STDIN_FILENO   stdin
1           标准输出  STDOUT_FILENO  stdout
2           标准错误  STDERR_FILENO  stderr

2. 文件描述限制
在编写文件操作的或者网络通信的软件时，初学者一般可能会遇到“Too-many-open-files”的问题。这主要是因为文件描述符是系统的一个重要资源，虽然说系统内存有多少就可以打开多少的文件描述符，但是在实际实现过程中内核是会做相应的处理的，一般最大打开文件数会是系统内存的10%（以KB来计算）（称之为系统级限制），查看系统级别的最大打开文件数可以使用sysctl -a | grep fs.file-max命令查看。
与此同时，内核为了不让某一个进程消耗掉所有的文件资源，其也会对单个进程最大打开文件数做默认值处理（称之为用户级限制），默认值一般是1024，使用ulimit -n命令可以查看用户级文件描述符。

3. 文件描述符表、文件表、索引结点表
进程打开一个文件，会与三个表发生关联，分别是：文件描述符表、文件表、索引结点表。他们的存放地点：
每个进程都有一个属于自己的文件描述符表。
文件表存放在内核空间，由系统里的所有进程共享。
索引结点表也存放在内核空间，由所有进程所共享。
三个表的作用：
文件描述符表：该表记录进程打开的文件。它的表项里面有一个指针，指向存放在内核空间的文件表中的一个表项。它向用户提供一个简单的文件描述符，使得用户可以通过方便地访问一个文件。当进程使用open打开一个文件时，内核就会在这个表中添加一个表项。如果对同一个文件打开多次，那么将有多个表项。
文件表：文件表保存了进程对文件读写的偏移量。该表还保存了进程对文件的存取权限。比如，进程以O_RDONLY方式打开文件，这将记录到对应的文件表表项中。
索引结点表：在文件系统中，也是有一个索引结点表的。这两个索引结点表有千丝万缕的关系。因为内存中的索引结点表的每一个表项都是从文件系统中读入的，并且两个索引结点表有一对一的关系。所以，内存中的索引结点表的每一个表项都对应一个具体的文件。
上面所说的三个表的功能，使得三个表紧密地联系在一起，文件描述符表项有一个指针指向文件表表项，文件表表项有一个指针指向索引结点表表项。
不同的进程打开同一个文件：
不同的进程打开同一个文件，那么他们应该有各自对应的文件表表项。因为文件表表项记录了进程读写文件时的偏移量和存取权限。多个进程不可能共享一个文件偏移量。另外他们各自打开文件的权限也可能是不同的，有的是为了读、有的为了写，有的为了读写。所以，他们应该有不同的文件表表项。此外，因为是同一个文件，所以，多个进程会共享同一个索引结点表项。即他们的文件表表项指针会指向同一个索引结点
使用dup函数复制一个文件描述符：
dup函数是用来复制一个文件描述符的。复制得到的文件描述符和原描述符共享文件偏移量和一些状态。所以dup的作用仅仅是复制一个文件描述符表项，而不会复制一个文件表表项。（dup函数是一个很重要的函数。平时我们在shell里面通过 >  来进行重定向，就是通过dup函数来实现的。）
同一个进程多次打开同一个文件：
每打开一次同一个文件，内核就会在文件表中增加一个表项。这是因为每次open文件时使用了不同的读写权限，而读写权限是保存在文件表表项里面的。
父进程使用fork创建子进程：
由于fork一个子进程，子进程将复制父进程的绝大部分东西（除了进程ID、进程的父进程ID、一些时间属性、文件锁）。所以子进程复制了父进程的整个文件描述符表。

####################################################文件描述符与socket连接####################################################

################################################一个服务端端口建立多个TCP连接################################################
客户端：
　　socket()---->创建出 active_socket_fd (client_socket_fd)
　　bind()--->把active_socket_fd与ip,port绑定起来
　　connect()--->client_socket_fd 主动请求服务端的 listen_socket_fd
　　read()/write()---->读/写 socket io
　　close()---->关闭socket_fd
服务端：
　　socket()---->创建出 active_socket_fd
　　bind()--->把active_socket_fd与ip,port绑定起来
　　listen()---->active_socket_fd--> listen_socket_fd 等待客户端的client_socket_fd来请求连接
　　accept()---->listen_socket_fd-->connec_socket_fd 把监听socket转变为连接socket,用于建立连接后的读写数据
　　read()/write()---->读/写 socket io
　　close()---->关闭socket_fd

linux内核中，socket函数不管在客户端还是服务端，创建的套接字都是主动socket，但是在服务端经过listen()，后把其转变为listen_socket_fd(被动监听socket)，经过accept()后转变为connect_socket_fd(已连接socket)。
在转变为connect_socket_fd之前，都是同一个socket，只不过socket的状态改变了，但是服务端经过accept()后返回的socket是新的socket，用于连接后的read()/write()。
一个tcp连接的唯一标识是一个四元组<clientIP,clientPort,serverIP,serverPort>，serverIP和serverPort是固定的，假定客户端也只有一个，即clientIP也是固定的，则描述不同的tcp连接就只剩下clientPort了。而实际上每当客户端调用connect()函数试图与服务端建立连接时，内核会为客户端分配一个临时端口作为源端口clientPort，服务端通过accept()函数感知到这个连接时，将返回一个全新的tcp连接的描述字（connect_socket_fd）。
所以，一个服务端端口是能建立多个连接的，因为每个连接中clientPort都是不同的，在进行通信时，操作系统接收到向serverPort发来的数据时，会在该端口产生的连接中查找到符合这个唯一标识并传递信息到对应的缓冲区。
扩展一下：
1）为什么服务端需要产生两个socket(listen_socket_fd和connect_socket_fd)
答：监听socket是服务器作为客户端连接请求的一个对端，只需创建一次即可，它存在于服务器的整个生命周期，可为成千上万的客户端服务，而一旦一个客户端和服务器连接成功，完成了TCP三次握手，操作系统内核就为这个客户端生成一个已连接套接字（connect_socket_fd），让应用服务器使用这个connect_socket_fd和客户端进行通信，如果应用服务器完成了对这个客户端的服务，那么关闭的就是已连接套接字，这样就完成了TCP连接的释放。请注意，这个时候释放的只是这一个客户端连接，其它被服务的客户端连接可能还存在。最重要的是，监听套接字一直都处于“监听”状态，等待新的客户请求到达并服务。若只使用一个listen_socket_fd完成从创建监听到被请求连接，处理请求，关闭socket的整个过程，那么这个socket就会一直被占用，而不能被其它的客户端请求，造成服务端性能低下。使用两个socket，按职责分工，listen_socket_fd专门负责响应客户端的请求，每个新的connect_socket_fd专门负责该次连接的数据交互，分层协作，提高服务端的性能。
2）一个端口能建立多个UDP连接么？
答：UDP本身是无连接的，所以不存在什么多个UDP连接。只是服务端接收UDP数据需要bind一个端口，一个socket只能绑定到一个端口。
################################################一个服务端端口建立多个TCP连接################################################

/*******************************************************linux 文件系统*******************************************************
Linux启动过程

Linux内核在初始化之后会执行init进程，而init进程会挂载根文件系统，但由于init程序也是在根文件系统上的，所以这就有了悖论。Linux采用两步走的方法来解决这个问题。

Linux2.6版以前的方法是：除了内核vmlinuz之外还有一个独立的initrd.img映像文件，其实它就是一个文件系统映像，linux内核在初始化后会mount             initrd.img作为一个临时的根文件系统（虚拟根文件系统），执行initrd上的特定脚本，待完成后，挂载了真正的根分区，再启动根分区中的 init  进程。负责加载内核访问根文件系统必须的驱动，以及加载根文件系统。这个initrd中的指定脚本通常称为/linuxrc，通过它，可以加载不同设备的驱动或运行其他程序，Live CD 的自动配置和Debian的安装程序都是以initrd来进行工作的。 

linux2.6 内核支持两种格式的 initrd，一种是前面第 3 部分介绍的 linux2.4 内核那种传统格式的文件系统镜像－image-initrd，它的制作方法同 Linux2.4 内核的 initrd 一样，其核心文件就是 /linuxrc。另外一种格式的 initrd 是 cpio 格式的，这种格式的 initrd 从 linux2.5 起开始引入，使用 cpio 工具生成，其核心文件不再是 /linuxrc，而是 /init，本文将这种 initrd 称为 cpio-initrd。尽管 linux2.6 内核对 cpio-initrd和 image-initrd 这两种格式的 initrd 均支持，但对其处理流程有着显著的区别，下面分别介绍 linux2.6 内核对这两种 initrd 的处理流程。
一、cpio-initrd的处理流程：
1． boot loader 把内核以及 initrd 文件加载到内存的特定位置。
2． 内核判断initrd的文件格式，如果是cpio格式。
3． 将initrd的内容释放到rootfs中。
4． 执行initrd中的/init文件，执行到这一点，内核的工作全部结束，完全交给/init文件处理。
二、传统image-initrd的处理流程：
1． boot loader把内核以及initrd文件加载到内存的特定位置。
2． 内核判断initrd的文件格式，如果不是cpio格式，将其作为image-initrd处理。
3． 内核将initrd的内容保存在rootfs下的/initrd.image文件中。
4． 内核将/initrd.image的内容读入/dev/ram0设备中，也就是读入了一个内存盘中。
5． 接着内核以可读写的方式把/dev/ram0设备挂载为原始的根文件系统。
6． 如果/dev/ram0被指定为真正的根文件系统，那么内核跳至最后一步正常启动。
7． 执行initrd上的/linuxrc文件，linuxrc通常是一个脚本文件，负责加载内核访问根文件系统必须的驱动， 以及加载根文件系统。
8． /linuxrc执行完毕，常规根文件系统被挂载
9． 如果常规根文件系统存在/initrd目录，那么/dev/ram0将从/移动到/initrd。否则如果/initrd目录不存在， /dev/ram0将被卸载。
10． 在常规根文件系统上进行正常启动过程 ，执行/sbin/init。

initrd和initramfs 都是载体，是在内核被引导程序启动之后首先可以访问到的部分，它没有内核那么严格的尺寸限制，可以包含很多在启动过程中可能需要用到的模块，比如硬盘控制器的驱动模块，对于需要引导不同硬件的发布版官方内核尤其有用。并且，它们不是内核的一部分，因此可以完成很多内核不能做的事情，比如内核必须尽量限制自己的行为，过多的功能会引入更多的问题，从而降低内核的代码质量，这样，很多内核被迫放弃的有用功能，如图形化的启动界面（bootsplash）和系统自动配置等都可以放在 initramfs/initrd 中来进行。 

initrd是init ram disk，initramfs是init ram file system，前者把内存模拟成磁盘，后者直接把内存模拟成文件系统
ramdisk，就是把一块内存（ram）当做磁盘（disk）去挂载，然后找到ram里的init进行执行。
ramfs，直接在ram上挂载文件系统，执行文件系统中的init。

http://www.infoq.com/cn/articles/how-to-read-linux-file-system-and-directory-structure#

访问原理
在Windows系统中，一切东西都是存放在硬盘上的。启动系统后，先确定硬盘，再确定硬盘上的分区以及每个分区所对应文件系统，最后是存放在某个分区特定的文件系统中的文件。也就是说，Windows是通过 “某个硬盘-硬盘上的某个分区-分区上的特定文件系统-特定文件系统中的文件” 这样的顺序来访问到一个文件的。

但是与Windows不同,Linux系统中的一切都是存放在唯一的虚拟文件系统中的，这个虚拟文件系统是树状的结构以一个根目录开始。启动系统后，先有这个虚拟文件系统，再识别出各个硬盘，再把某个硬盘的某个分区挂载到这个虚拟文件系统的某个子树上（即分区用某个子目录来表示），再确定分区对应的子目录文件系统，最后的文件就存放在这个特定的文件系统中。也就是说，Linux系统是通过“虚拟文件系统-硬盘-硬盘上的分区-分区上的特定文件系统-特定文件系统中的文件” 这样的顺序来访问一个文件的。

可能对习惯了使用Windows的用户来说，Linux的方式有些不适应，它的虚拟文件系统，实质就是一颗目录树，最开始的目录叫做根目录，根目录中又有每一级子目录，或者文件，子目录又有子子目录和文件，其中每个子目录都特定的功能这个功能

也许有人会问，没有这个虚拟文件系统就无法使用硬盘，可是最开始没有硬盘，那么这个虚拟文件系统以及相应的组织结构是怎么存放起来的呢？这个问题，就像先有鸡还是先有蛋这个问题一样看似简单实则……但是，在 Linux 中，很轻易地跳出了这个思维循环，问题的答案并没在虚拟文件系统和硬盘这两者之间徘徊，而是第三者—— 内存，Linux系统启动起来之后，整个虚拟文件系统的组织结构，都是随着每次内核系统的启动自动在内存中建立好了的，根本就不需要硬盘。

另外还要注意，就是在我们用户的角度上，无论在Windows还是Linux上面，都是使用路径来访问一个文件的。表示文件的路径由 “文件所在的目录+各级目录的分隔符+文件” 三个部分组成，这个策略在两者之间是一样的，所不同的是，Windows下面目录分隔符是\，Linux下面是/，也许这也是两者之间为了表示其各自立场不同的一个原因吧？^_^

系统组织

在Windows系统中，我们可以把文件大体分为两种： 系统文件和用户文件 。一般来说系统文件（例如Windows操作系统本身，一些系统程序，程序运行所需的库文件，以及一些系统配置文件等）存放的默认位置在 C 盘，当然也可以在安装时候指定在其他盘；其它用户文件，包含用户后来安装的程序以及一些数据文件等，用户可以把它们随意存放在任意的分区。

在 Linux 系统中，主要有两个概念： 虚拟文件系统中的文件和 Linux操作系统内核 本身。逻辑上可以认为前者属于上层，后者在下层，前者基于后者，后者依赖前者而存在。 Linux 把除了它本身（ Linux操作系统内核 ）以外的一切事物都看作是在 虚拟文件系统中的文件了。无论是键盘，鼠标，数据，程序，CPU，内存，网卡……无论是硬件、软件、数据还是内存中的东西，我们都可以在 虚拟文件系统中的相应子目录对他们进行访问和操作，操作统一。而实现这些管理的幕后就是 Linux操作系统内核 本身：启动 Linux 系统的时候，首先电脑把 Linux操作系统内核 加载到内存中，内核本身提供了文件管理，设备管理，内存管理，CPU进程调度管理，网络管理等功能，等内核运行起来之后，就在内存中建立起相应的 虚拟文件系统，最后就是内核利用它提供的那些功能，通过管理文件的方式，来管理 虚拟文件系统中的硬件软件等各种资源了。

Linux 把提供操作系统本身功能（管理计算机软硬件资源）的那些部分划给了 Linux操作系统内核 ，使得Linux操作系统内核 成为一个独立的部分，有它自己独立的开源代码；而其它的一切（软件应用，硬件驱动，数据）都根据其特性有自己的开源代码、或者自由地组织并且存放在那个 虚拟文件系统中由 Linux操作系统内核 来管理。这样，将系统本身和系统所管理的资源分开，并开放源代码，有助于对系统或者系统所管理的资源进行灵活的定制和扩展，还能按需快速建立起只适合自己使用的操作系统，也利于操作系统本身的发展。实际 Ubuntu ， Fedora ， RedHat 等各种不同的 Linux 操作系统发行版，简单来说就是不同厂商对其文件系统和内核进行了不同的配置而产生的 “大众化” 的操作系统。相比之下，Windows就显得非常地零乱复杂，将系统、软件、硬件、数据都混在了一起，其不同版本只能由Microsoft 一家公司发行。

举例说明

下面用直观的例子，来说明两者的不同，以加深理解。假设我们的机器上面有一个硬盘，硬盘分为三个区。

在Windows系统中， 我们启动系统之后就会看到 C, D, E, 盘符，它们分别对应硬盘上的三个分区，增加硬盘，或者分区，会导致盘符的增加（注意由于历史原因， A, B 用于表示软驱，硬盘分区盘符从 C 开始按字母递增），这里的每个分区都各自可以被格式化为不同的文件系统（这里的文件系统，包括例如 NTFS 格式， FAT32 格式等)，文件系统的基本功能就是为了存放文件的，不同文件系统区别一般在于管理其中存放的文件的功能的强弱，所以分区被格式化成指定格式的文件系统之后，就可以存放任何文件和目录了，我们看到的 C, D, E 内容也就对应了硬盘中相应分区的数据内容。

但是，与Windows中把硬盘分区看成 C, D, E 盘符不同， Linux 中最开始根本就没有硬盘的概念，就只有一个纯粹的 虚拟文件系统。如果想要使用哪个硬盘的某个分区，就把那个分区 “挂载” 到某个子目录之下，这样硬盘中的分区，文件系统，目录等内容就呈现到了那个子目录里面。也就是说，在 Linux 中，我们使用硬盘中的数据，实际是先把硬盘的某个分区 “挂载” 到某个子目录下，然后通过那个子目录来访问的。这个例子中， 通常硬盘会对应 虚拟文件系统中的/dev/sda （如有多个硬盘，则为 /dev/sda, /dev/sdb, ……， 按字母递增）, 其三个分区对应 /dev/sda1, /dev/sda2,/dev/sda3 （多个分区按数字递增，不同硬盘的分区，对应为 /dev/sdb1, /dev/sdb2 等等）, 默认硬盘各个分区会被挂载到 虚拟文件系统系统中类似 /mnt/sda1/, /mnt/sda2/, /mnt/sda3/ 的目录（在 Linux 又叫挂载点）中，在/etc/fstab 文件中，我们可以找到分区文件和挂载点的对应关系描述。这样，硬盘相应的分区就做为整个 虚拟文件系统根目录下的一颗子树，反映到了子目录（挂载点）上，子目录中的内容就对应分区中的数据。

假设访问上述硬盘第三个分区 dir1 目录中的文件 test.file

Window系统上的路径：E:\dir1\test.file
Linux系统上的路径：/mnt/sda3/dir1/test.file

再有，假设用户安装和卸载一个程序 firefox ：

Windows系统中
指定或不指定安装路径类似，程序的安装目录会在 C:\Program Files\Firefox 类似的目录中，或指定的安装路径中； 可执行文件一般在程序的安装路径；依赖的内部库、第三方库、和系统库可能在安装路径中，也可能在C:\Windows\System32, 或 C:\Windows\system 等类似的路径；而程序访问期间的系统和用户配置文件和产生的输入输出文件，可能会在安装路径配置中，或者在 C:\Windows\ 下的某些文件中（比如注册表数据库文件、用户目录等），这就不一定了。而且不同的系统版本，应用程序版本下，这些目录的具体名称和路径可能会有所不同。卸载的时候由于不确定哪些地方安装了什么内容，很容易造成文件删除补全，遗留系统垃圾等现象，造成系统越来越瘫肿。

Linux 系统中
如果不指定安装路径，所有程序的可执行文件在 /usr/bin 中， 全局配置文件在 /etc/firefox 类似的目录， 用户配置文件一般在用户主目录的 .firefox 的路径下(用户主目录路径名称统一格式为 /home/<username>) ，依赖的内部库和第三方库在 /usr/lib, 系统库在 /lib 下， 数据文件一般就在用户主目录下。 如果指定安装目录，那么所有内部库和可执行程序，全局配置文件，会在 <安装路径> 下的 bin, lib, etc 子目录下，其它文件一般和默认情况相同。卸载程序之时，只需在对应目录中，将可执行文件、内部库、配置文件、数据文件删除即可，基本没有不确定是否遗留垃圾文件的问题。这些都是大多数应用程序安装的和访问的默认策略，就像是不成文的业界标准，不排除有个别程序不安装这种策略部署应用，但是 Linux 用户带来 “麻烦“ 的应用，早晚也会被淘汰，不可能会流行在 Linux 系统中，这样，自然的，好的应用都保存在 Linux 系统中并逐渐流行起来，还不会破坏系统结构。

Linux 上面的虚拟文件系统目录组织(常用的重要目录)

/boot 引导程序，内核等存放的目录

这个目录，包括了在引导过程中所必需的文件，引导程序的相关文件（例如 grub ， lilo 以及相应的配置文件）以及 Linux 操作系统内核相关文件（例如 vmlinuz 等）一般都存放在这里。在最开始的启动阶段，通过引导程序将内核加载到内存，完成内核的启动（这个时候， 虚拟文件系统还不存在，加载的内核虽然是从硬盘读取的，但是没经过 Linux 的 虚拟文件系统，这是比较底层的东西来实现的）。然后内核自己创建好 虚拟文件系统，并且从 虚拟文件系统的其他子目录中（例如 /sbin 和 /etc ）加载需要在开机启动的其他程序或者服务或者特定的动作（部分可以由用户自己在相应的目录中修改相应的文件来配制）。如果我们的机器中包含多个操作系统，那么可以通过修改这个目录中的某个配置文件（例如 grub.conf ）来调整启动的默认操作系统，系统启动的择菜单，以及启动延迟等参数。

////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
Linux下没有盘符的概念，而是将各分区通过挂载到目录（挂载点）来访问实际的磁盘分区，有时候我们想知道某个文件或文件夹是在哪个分区上，
有如下几种方法：

1、最简单的，直接 df  <文件(夹)路径>
2、用df 或 fdisk -l查看分区挂载情况，直接输入mount或者也可以用cat /etc/mtab，然后pwd找最接近的挂载点信息
3、cat /proc/partitions
4、硬盘分区（2种方式）
  1) fdisk  /dev/sdx
  2) 可以输入m来看查看各种操作指令，如下：
     这里介绍几种常见的参数：
     d     删除分区
     l     列出分区类型
     m     列出help
     n     添加分区
     p     列出分区
     q     不保存退出
     t     改变分区类型
     w     保存后退出
  也可是使用parted分区
  1) parted /dev/sda
  2) 输入print free查看剩余空间
  3) 输入p,查看目前的分区情况
  4) 再输入mkpart开始分区
  5) Partition name：按顺序即可；File system type：默认；Start：上一个分区的End(单位支持:K,M,G,T)；End：在start的基础上增加这个分区的大小(单位支持:K,M,G,T)
  6) 再输入p,查看新增分区是否成功
  7) 然后输入：ll -ls /dev/sda 通过联想功能看新追加的分区是否成功
  8) 如果需要删除分区则输入：rm
5、格式化分区（df -T 可以查看已经挂载的分区和文件系统类型。）
  分区完成后，紧接着就要给每个分区分配一种文件系统，这里介绍较为常见的命令mkfs，命令格式如下：
  mkfs  [-V]  [-t  fstype]  [-options]  device
  -V：详细显示模式
  -t fstype：选择一种文件系统，Linux的预设值为ext2，可以指定为ext2,ext3,ext4,msdos,fat32,vfat等等
  -options：其他一些参数，
    如-c表示格式化过程中检查磁盘坏轨情况，-l bad_blocks_file表示将坏轨的block信息添加到bad_blocks_file文件中
  device：硬盘分区，如/dev/sda1
  例如：mkfs -t ext4 /dev/sda1
  例如：mkfs -t xfs /dev/sda1
  这句命令可写成mkfs.ext4 /dev/sda1或者mkfs.xfs /dev/sda1
6、挂载文件系统
  输入:mount /dev/sdb1    /mnt(把sdb1主分区挂载到mnt上)
  输入:mount /dev/sdb5    /mnt(把sdb5逻辑分区挂载到mnt上)

设置开机自动挂载
1、分区生成uuid，加入到/etc/fstab中：
[root@localhost home]# blkid /dev/sda4
/dev/sda4: UUID="5fb53eeb-e4cb-4283-b8c7-4c0121068a26" TYPE="xfs" PARTUUID="cc8233fc-4e5c-4e4c-89da-85f62e896583"
[root@localhost home]# blkid /dev/sda5
/dev/sda5: UUID="4bef8961-c90e-45f0-811d-8fd1e82a5691" TYPE="xfs" PARTUUID="e07d1e26-9373-4ff0-aebc-e5c15a05a3a2"
2、vi /etc/fstab追加两行
UUID=5fb53eeb-e4cb-4283-b8c7-4c0121068a26 /home xfs defaults,noatime,nodiratime 1 0
UUID=4bef8961-c90e-45f0-811d-8fd1e82a5691 /app xfs defaults,noatime,nodiratime 1 0
3、将/etc/fstab的所有内容重新加载
mount -a

Linux系统分区的三个简单案例
一个系统分区通常需要三个分区就可以了。1、一个/boot引导分区进行系统启动的引导操作。2、一个swap虚拟内存交换分区，数值为物理机实际内存的1.5倍，如果物理内存大于16G时，该分区最大设置为16G或者不设置该分区都是没问题的。3、一个/分区也就是根分区。
给出几个经常使用的系统分区方案供参考：
案例一：服务器集群架构中的节点服务器
/boot: 200M。----------------------------引导分区200MB完全够用。
swap: 物理内存的1.5倍。------------------当内存大于8G时，常配置在8-16G之间，大于16G就太浪费
/: 剩余硬盘空间大小。----------------------只作为服务节点不再单独分出一个数据分区，将数据放在根分区下可以充分利用资源
案例二: 存放数据库及存储角色的服务器
/boot: 200M。 ---------------------------通常都是这个数值。
/: 50~200G。-----------------------------只存放系统相关文件，网站等业务数据不放在这里。
swap: 物理内存的1.5倍。---------------当内存大于或等于8G时，配置为8-16G。
/data: 剩余硬盘空间大小。--------------单独分出一个数据分区便于对数据进行管理操作。
案例三: 作为大型网站或门户网站的服务器
/boot: 200M。--------------------------通常都是这个数值。
/:50~200G。----------------------------只存放系统相关文件，网站等业务数据不放在这里。
swap: 物理内存的1.5倍。---------------当内存大于或等于8G时，配置为8~16G即可。
保留剩余的磁盘空间，可根据今后的需求再进行具体分配。
/*******************************************************linux 文件系统*******************************************************

/*******************************************************linux应用程序******************************************************
如果说，你是想用yum来安装别的应用程序的话，就使用yum install 软件包名。
但是，不是每个linux系统操作系统都用yum来管理应用程序。比如ubuntu用的是apt-get，suse用的是zypper. 你如果是想提linux下的问题。最好说明是哪个发行版，然后还有版本号。
/*******************************************************linux应用程序******************************************************

/*******************************************************curl命令******************************************************
curl是基于URL语法在命令行方式下工作的文件传输工具，它支持FTP，FTPS，HTTP，HTTPS，GOPHER，TELNET，DICT，FILE及LDAP等协议。curl支持HTTPS认证，并且支持HTTP的POST,PUT等方法，FTP上传，kerberos认证，HTTP上传，代理服务器，cookies，用户名/密码认证，通过http代理服务器上传文件到FTP服务器等等，功能十分强大。

下载单个文件，默认将输出打印到标准输出中(STDOUT)中
curl http://www.centos.org

通过-o/-O选项保存下载的文件到指定的文件中：
-o：将文件保存为命令行中指定的文件名的文件中
-O：使用URL中默认的文件名保存文件到本地（后面的url要具体到某个文件，不然抓不下来。我们还可以用正则来抓取东西）
# 将文件下载到本地并命名为mygettext.html
curl -o mygettext.html http://www.gnu.org/software/gettext/manual/gettext.html
# 将文件保存到本地并命名为gettext.html
curl -O http://www.gnu.org/software/gettext/manual/gettext.html
同样可以使用转向字符">"对输出进行转向输出

同时获取多个文件
curl -O URL1 -O URL2
若同时从同一站点下载多个文件时，curl会尝试重用链接(connection)。

通过-L选项进行重定向
默认情况下CURL不会发送HTTP Location headers(重定向).当一个被请求页面移动到另一个站点时，会发送一个HTTP Loaction header作为请求，然后将请求重定向到新的地址上。
例如：访问google.com时，会自动将地址重定向到google.com.hk上。
curl http://www.google.com
<HTML>
	<HEAD>
		<meta http-equiv="content-type" content="text/html;charset=utf-8">
		<TITLE>302 Moved</TITLE>
	</HEAD>
	<BODY>
		<H1>302 Moved</H1>
		The document has moved
		<A HREF="http://www.google.com.hk/url?sa=p&amp;hl=zh-CN&amp;pref=hkredirect&amp;pval=yes&amp;q=http://www.google.com.hk/&amp;ust=1379402837567135amp;usg=AFQjCNF3o7umf3jyJpNDPuF7KTibavE4aA">here</A>.
	</BODY>
</HTML>
上述输出说明所请求的档案被转移到了http://www.google.com.hk。
这是可以通过使用-L选项进行强制重定向
# 让curl使用地址重定向，此时会查询google.com.hk站点
curl -L http://www.google.com

-I选项，只获得对方的响应首部信息；-i选项，显示完整的http response的头信息

-v选项，显示一次的http请求的通信过程

模拟POST请求：
curl -X POST -H "Content-type:application/json" --data '{"Body":{"question":"如何续卡"}}' http://182.180.31.104:8085/inference
/*******************************************************curl命令******************************************************

/*******************************************在Linux系统下，cat正常，vim打开乱码*******************************************
解决方法： 
方法一： 
在文件中设定

在vim的退出模式下  :set encoding=utf8

方法二： 
直接写入/etc/vim/vimrc文件,在/etc/vim/vimrc文件末尾加上

set fileencodings=utf-8,ucs-bom,gb18030,gbk,gb2312,cp936
set termencoding=utf-8
set encoding=utf-8

【vim知识扩展】 
一、存在3个变量：

1 encoding----该选项使用于缓冲的文本(你正在编辑的文件)，寄存器，Vim 脚本文件等等。\
2 这事可以把 'encoding' 选项当作是对 Vim 内部运行机制的设定。
3 fileencoding----该选项是vim写入文件时采用的编码类型。
4 termencoding----该选项代表输出到客户终端（Term）采用的编码类型。

二、此3个变量的默认值：

1 encoding----与系统当前locale相同，所以编辑文件的时候要考虑当前locale，否则要设置的东西就比较多了。
2 fileencoding----vim打开文件时自动辨认其编码，fileencoding就为辨认的值。\
3 为空则保存文件时采用encoding的编码，如果没有修改encoding，那值就是系统当前locale了。
4 termencoding----默认空值，也就是输出到终端不进行编码转换。
/*******************************************在Linux系统下，cat正常，vim打开乱码*******************************************

##########################################################【linux】升级glibc##############################################
https://blog.csdn.net/levy_cui/article/details/51251095
http://zrq.org.cn/?p=251
安装xz
linux 解压xz包
1.下载xz包
http://tukaani.org/xz/xz-4.999.9beta.tar.bz2
 
2.解压安装包
$tar -jxvf xz-4.999.9beta.tar.bz2
 
3.配置&安装
$./configure --prefix=/usr/local/xz
$make
$sudo make install
$ln -s /usr/local/xz/bin/xz /bin/xz
 
4.解压xz包
$xz -d ***.tar.xz
 
5.解压tar包
$tar -xvf  ***.tar

ImportError: /lib64/libc.so.6: version `GLIBC_2.17' not found
1) yum install gcc
2) 升级glibc至2.17
    wget http://ftp.gnu.org/pub/gnu/glibc/glibc-2.17.tar.xz
    xz -d glibc-2.17.tar.xz
	tar -xvf glibc-2.17.tar
	cd glibc-2.17
	mkdir build
	cd build
	../configure --prefix=/usr --disable-profile --enable-add-ons --with-headers=/usr/include --with-binutils=/usr/bin
	make && make install
3) 输入strings /lib64/libc.so.6|grep GLIBC发现已经更新 
GLIBC_2.2.5
GLIBC_2.2.6
GLIBC_2.3
GLIBC_2.3.2
GLIBC_2.3.3
GLIBC_2.3.4
GLIBC_2.4
GLIBC_2.5
GLIBC_2.6
GLIBC_2.7
GLIBC_2.8
GLIBC_2.9
GLIBC_2.10
GLIBC_2.11
GLIBC_2.12
GLIBC_2.13
GLIBC_2.14
GLIBC_2.15
GLIBC_2.16
GLIBC_2.17
GLIBC_PRIVATE

ImportError: /usr/lib64/libstdc++.so.6: version `GLIBCXX_3.4.14' not found
没有GLIBCXX_3.4.14版本支持，继续安装(注意：libstdc++6_4.7.2-5_amd64.deb这是64位，libstdc++6_4.7.2-5_i386.deb这个是32位)
1) wget http://ftp.de.debian.org/debian/pool/main/g/gcc-4.7/libstdc++6_4.7.2-5_amd64.deb
2) ar -x libstdc++6_4.7.2-5_amd64.deb && tar xvf data.tar.gz
3) cd /apps/usr/lib/x86_64-linux-gnu （进入解压文件的目录中，我这里是下/apps目录下解压的）
4) ll 
    lrwxrwxrwx 1 root root     19 Mar 24 23:01 libstdc++.so.6 -> libstdc++.so.6.0.17
    -rw-r--r-- 1 root root 991600 Jan  6  2013 libstdc++.so.6.0.17
5) find / -name libstdc++.so.6
    /usr/lib64/libstdc++.so.6
    /apps/usr/lib/x86_64-linux-gnu/libstdc++.so.6
6) mv /usr/lib64/libstdc++.so.6 /usr/lib64/libstdc++.so.6.bak
7) cp /apps/usr/lib/x86_64-linux-gnu/libstdc++.so.6.0.17 /usr/lib64/
9) cd /usr/lib64/
    chmod +x libstdc++.so.6.0.17
	ln -s libstdc++.so.6.0.17 libstdc++.so.6
10) strings /usr/lib64/libstdc++.so.6 | grep GLIBCXX
GLIBCXX_3.4
GLIBCXX_3.4.1
GLIBCXX_3.4.2
GLIBCXX_3.4.3
GLIBCXX_3.4.4
GLIBCXX_3.4.5
GLIBCXX_3.4.6
GLIBCXX_3.4.7
GLIBCXX_3.4.8
GLIBCXX_3.4.9
GLIBCXX_3.4.10
GLIBCXX_3.4.11
GLIBCXX_3.4.12
GLIBCXX_3.4.13
GLIBCXX_3.4.14
GLIBCXX_3.4.15
GLIBCXX_3.4.16
GLIBCXX_3.4.17
GLIBCXX_DEBUG_MESSAGE_LENGTH

ImportError: /usr/lib/libstdc++.so.6: version `GLIBCXX_3.4.20′ not found
1) wget http://ftp.de.debian.org/debian/pool/main/g/gcc-4.9/libstdc++6_4.9.2-10_amd64.deb
2) ar -x libstdc++6_4.9.2-10_amd64.deb && tar xvf data.tar.xz
3) cd /apps/usr/lib/x86_64-linux-gnu （进入解压文件的目录中，我这里是下/apps目录下解压的）
4) cp /apps/usr/lib/x86_64-linux-gnu/libstdc++.so.6.0.20 /usr/lib64/
5) rm libstdc++.so.6 （删除原来的链接）
6) ln -s libstdc++.so.6.0.20 libstdc++.so.6
7) strings /usr/lib64/libstdc++.so.6 | grep GLIBCXX
GLIBCXX_3.4
GLIBCXX_3.4.1
GLIBCXX_3.4.2
GLIBCXX_3.4.3
GLIBCXX_3.4.4
GLIBCXX_3.4.5
GLIBCXX_3.4.6
GLIBCXX_3.4.7
GLIBCXX_3.4.8
GLIBCXX_3.4.9
GLIBCXX_3.4.10
GLIBCXX_3.4.11
GLIBCXX_3.4.12
GLIBCXX_3.4.13
GLIBCXX_3.4.14
GLIBCXX_3.4.15
GLIBCXX_3.4.16
GLIBCXX_3.4.17
GLIBCXX_3.4.18
GLIBCXX_3.4.19
GLIBCXX_3.4.20
GLIBCXX_FORCE_NEW
GLIBCXX_DEBUG_MESSAGE_LENGTH

cd /home/tensorflow-models/chinese-ocr
/usr/local/python2/bin/python2.7 demo.py

opencv
/usr/local/python2/bin/pip install opencv-python
如报错：ImportError: libSM.so.6: cannot open shared object file: No such file or directory
报错原因： 缺少共享库
使用如下命令查看缺少得共享库
yum whatprovides libSM.so.6
[root@host chinese-ocr]# yum whatprovides libSM.so.6
Loaded plugins: fastestmirror
Loading mirror speeds from cached hostfile
 * base: mirrors.vpsie.com
 * elrepo-kernel: repos.lax-noc.com
 * extras: repos.lax.quadranet.com
 * updates: mirror.pac-12.org
libSM-1.2.1-2.el6.i686 : X.Org X11 SM runtime library
Repo        : base
Matched from:
Other       : libSM.so.6
使用以下命令解决：
yum install libSM-1.2.1-2.el6.i686 --setopt=protected_multilib=false
yum install libSM-1.2.1-2.el6.x86_64 --setopt=protected_multilib=false

如果报错
ImportError: libXrender.so.1: cannot open shared object file: No such file or directory
报错原因： 缺少共享库
使用如下命令查看缺少得共享库
yum whatprovides libXrender.so.1
[root@host chinese-ocr]# yum whatprovides libXrender.so.1
Loaded plugins: fastestmirror
Loading mirror speeds from cached hostfile
 * base: mirrors.vpsie.com
 * elrepo-kernel: repos.lax-noc.com
 * extras: repos.lax.quadranet.com
 * updates: mirror.pac-12.org
libXrender-0.9.10-1.el6.i686 : X.Org X11 libXrender runtime library
Repo        : base
Matched from:
Other       : libXrender.so.1
libXrender-0.9.10-1.el6.i686 : X.Org X11 libXrender runtime library
Repo        : installed
Matched from:
Other       : Provides-match: libXrender.so.1
使用以下命令解决：
yum install libXrender-0.9.10-1.el6.i686 --setopt=protected_multilib=false
yum install libXrender-0.9.10-1.el6.x86_64 --setopt=protected_multilib=false

如果报错
ImportError: libXext.so.6: cannot open shared object file: No such file or directory
报错原因： 缺少共享库
使用如下命令查看缺少得共享库
yum whatprovides libXext.so.6
[root@host chinese-ocr]# yum whatprovides libXext.so.6
Loaded plugins: fastestmirror
Loading mirror speeds from cached hostfile
 * base: mirrors.vpsie.com
 * elrepo-kernel: repos.lax-noc.com
 * extras: repos.lax.quadranet.com
 * updates: mirror.pac-12.org
libXext-1.3.3-1.el6.i686 : X.Org X11 libXext runtime library
Repo        : base
Matched from:
Other       : libXext.so.6
使用以下命令解决：
yum install libXext-1.3.3-1.el6.i686 --setopt=protected_multilib=false
yum install libXext-1.3.3-1.el6.x86_64 --setopt=protected_multilib=false

ImportError: No module named PIL
/usr/local/python2/bin/pip install pillow

ImportError: No module named keras.layers
/usr/local/python2/bin/pip install keras

ImportError: No module named torch
http://pytorch.org/
##########################################################【linux】升级glibc##############################################

##########################################################【linux】升级glibc##############################################
shell常见通配符
字符 	含义 	实例
* 	匹配 0 或多个字符 	a*b  a与b之间可以有任意长度的任意字符, 也可以一个也没有, 如aabcb, axyzb, a012b, ab。
? 	匹配任意一个字符 	a?b  a与b之间必须也只能有一个字符, 可以是任意字符, 如aab, abb, acb, a0b。
[list]  	匹配 list 中的任意单一字符 	a[xyz]b a与b之间必须也只能有一个字符, 但只能是 x 或 y 或 z, 如: axb, ayb, azb。
[!list]  	匹配 除list 中的任意单一字符 	a[!0-9]b  a与b之间必须也只能有一个字符, 但不能是阿拉伯数字, 如axb, aab, a-b。
[c1-c2] 	匹配 c1-c2 中的任意单一字符 如：[0-9] [a-z] 	a[0-9]b  0与9之间必须也只能有一个字符 如a0b, a1b... a9b。
{string1,string2,...} 	匹配 sring1 或 string2 (或更多)其一字符串 	a{abc,xyz,123}b    a与b之间只能是abc或xyz或123这三个字符串之一。
shell元字符（特殊字符 Meta）
shell 除了有通配符之外，由shell 负责预先先解析后，将处理结果传给命令行之外，shell还有一系列自己的其他特殊字符。
字符 	说明
IFS 	由 <space> 或 <tab> 或 <enter> 三者之一组成(我们常用 space )。
CR 	    由 <enter> 产生。
= 	    设定变量。
$ 	    作变量或运算替换(请不要与 shell prompt 搞混了)。
> 	    重导向 stdout。 *
< 	    重导向 stdin。 *
| 	    命令管线。 *
& 	    重导向 file descriptor ，或将命令置于背境执行。 *
( ) 	将其内的命令置于 nested subshell 执行，或用于运算或命令替换。 *
{ } 	将其内的命令置于 non-named function 中执行，或用在变量替换的界定范围。
; 	    在前一个命令结束时，而忽略其返回值，继续执行下一个命令。 *
&& 	    在前一个命令结束时，若返回值为 true，继续执行下一个命令。 *
|| 	    在前一个命令结束时，若返回值为 false，继续执行下一个命令。 *
! 	    执行 history 列表中的命令。*

shell转义符
有时候，我们想让通配符，或者元字符变成普通字符，不需要使用它。那么这里我们就需要用到转义符了。 shell提供转义符有三种。
字符 	    说明
‘’(单引号) 	又叫硬转义，其内部所有的shell 元字符、通配符都会被关掉。注意，硬转义中不允许出现’(单引号)。
“”(双引号) 	又叫软转义，其内部只允许出现特定的shell 元字符：$用于参数代换 `用于命令代替
\(反斜杠) 	又叫转义，去除其后紧跟的元字符或通配符的特殊意义。

实例:

[chengmo@localhost ~/shell]$ls \*.txt
ls: 无法访问 *.txt: 没有那个文件或目录
[chengmo@localhost ~/shell]$ls '*.txt'
ls: 无法访问 *.txt: 没有那个文件或目录
[chengmo@localhost ~/shell]$ls 'a.txt'
a.txt
[chengmo@localhost ~/shell]$ls *.txt
a.txt  b.txt
可以看到，加入了转义符 “*”已经失去了通配符意义了

例如： name= hello
       echo "$name"
       输出:hello
	   
       name=hello
       echo '$name'
       输出:$name

但是如果是正则表达式中的转义字符使用单引号或者双引号是不行的，比如 grep "1*" test
这里会搜索1,11,111等模式串，如果要想搜索模式串为1*的行，则需要如下 grep "1\*" test
这里才是搜索模式串1*

linux 中grep匹配制表符和换行符的命令
[root@dhcp-9-79 ~]# ls
anaconda-ks.cfg log.txt mno.txt original-ks.cfg
[root@dhcp-9-79 ~]# cat log.txt 
  ok
[root@dhcp-9-79 ~]# grep $'\n' log.txt 
  ok
[root@dhcp-9-79 ~]# grep $'\t' log.txt 
  ok
##########################################################【linux】升级glibc##############################################

##############################################################【linux】网络####################################################
Linux系统中可以使用netstat -tlnp命令查看端口号占用情况
netstat命令的4个选项t、l、n、p分别表示查看tcp协议、查看监听服务、不解析名称以及显示进程名和PID。

lsof -i:$PORT查看应用该端口的程序（$PORT指对应的端口号）。或者你也可以查看文件/etc/services，从里面可以找出端口所对应的服务。

centos7查看防火墙状态
systemctl status firewalld.service

为什么称为ip"tables"呢？因为这个防火墙软件里面有多个表格(table)，每个表格都定义出自己的默认策略与规则，且每个表格的用途都不相同。Linux的iptables至少就有三个表格，包括管理本机进出的filter、管理后端主机(防火墙内部的其他计算机)的nat、管理特殊旗标使用的mangle(较少使用)。更有甚者，我们还可以自定义额外的链呢！真是很神奇吧！每个表格与其中链的用途分别是这样的：
filter(过滤器)：主要跟进入Linux本机的封包有关，这个是默认的table喔！
INPUT：主要与想要进入我们Linux本机的封包有关；
OUTPUT：主要与我们Linux本机所要送出的封包有关；
FORWARD：这个咚咚与Linux本机比较没有关系，他可以『转递封包』到后端的计算机中，与下列nat table相关性较高。
nat(地址转换)：是Network Address Translation的缩写，主要进行来源与目的的IP或port的转换，与Linux本机无关，与Linux主机后的局域网内计算机较为相关。
PREROUTING：在进行路由判断之前所要进行的规则(DNAT/REDIRECT)
POSTROUTING：在进行路由判断之后所要进行的规则(SNAT/MASQUERADE)
OUTPUT：与发送出去的封包有关
mangle(破坏者)：这个表格主要是与特殊的封包的路由旗标有关，早期仅有PREROUTING及OUTPUT链，不过从kernel2.4.18之后加入了INPUT及FORWARD链。由于这个表格与特殊旗标相关性较高，所以像咱们这种单纯的环境当中，较少使用mangle这个表

规则的查询与清除
[root@www ~]# iptables [-t tables] [-L] [-nv]
	选项与参数：
	-t ：后面接 table ，例如 nat 或 filter ，若省略此项目，则使用默认的filter
	-L ：列出目前的 table 的规则
	-n ：不进行 IP 与 HOSTNAME 的反查，显示讯息的速度会快很多！
	-v ：列出更多的信息，包括通过该规则的封包总位数、相关的网络接口等
	范例：列出 filter table 三条链的规则
[root@www ~]# iptables -L -n
例：列出 nat table 三条链的规则
[root@www ~]# iptables -t nat -L -n
Chain PREROUTING (policy ACCEPT)
target prot opt source destination

Chain POSTROUTING (policy ACCEPT)
target prot opt source destination

Chain OUTPUT (policy ACCEPT)
target prot opt source destination
在上表中，每一个Chain就是前面提到的每个链，Chain那一行里面括号的policy就是默认的策略，那底下的target,prot代表什么呢？
 target：代表进行的动作，ACCEPT是放行，而REJECT则是拒绝，此外，尚有DROP(丢弃)的项目！
 prot：代表使用的封包协议，主要有tcp,udp及icmp三种封包格式；
 opt：额外的选项说明
 source：代表此规则是针对哪个『来源IP』进行限制？
 destination：代表此规则是针对哪个『目标IP』进行限制？

建议使用iptables-save这个指令来观察防火墙规则，因为iptables-save会列出完整的防火墙规则，只是并没有规格化输出而已。
[root@www ~]# iptables-save [-t table]
	选项与参数：
	-t ：可以仅针对某些表格来输出，例如仅针对 nat 或 filter 等等
	
[root@www ~]# iptables [-t tables] [-FXZ]
	选项与参数：
	-F ：清除所有的已订定的规则；iptables删除一条规则
	-X ：杀掉所有使用者"自定义"的chain(应该说的是tables）
	-Z ：将所有的chain的计数与流量统计都归零
例：清除本机防火墙 (filter) 的所有规则
[root@www ~]# iptables -F
[root@www ~]# iptables -X
[root@www ~]# iptables -Z
由于这三个指令会将本机防火墙的所有规则都清除，但却不会改变默认策略(policy)，

-- 查找所有规则
iptables -t filter -L INPUT --line-numbers
-- 删除一条规则
iptables -t filter -D INPUT 11
（注意，这个11是行号，是iptables -t filter -L INPUT --line-numbers 所打印出来的行号）

定义默认策略
默认策略的意思是当你的封包不在你设定的规则之内时，则该封包的通过与否，是以Policy的设定为准
[root@www ~]# iptables [-t nat] -P [INPUT,OUTPUT,FORWARD] [ACCEPT,DROP]
	选项与参数：
	-P ：定义策略(Policy)。注意，这个P为大写！！！
	ACCEPT ：该封包可接受
	DROP ：该封包直接丢弃，不会让client端知道为何被丢弃。

开放本机的web服务（80）
iptables -I INPUT -p tcp --dport 80 -j ACCEPT

开放本机的web服务（80）、FTP(20、21、20450-20480)，放行外部主机发往服务器其它端口的应答数据包，将其他入站数据包均予以丢弃处理。
iptables -I INPUT -p tcp -m multiport --dport 20,21,80 -j ACCEPT 
iptables -I INPUT -p tcp --dport 20450:20480 -j ACCEPT 

NAT、SNAT、DNAT
内部LAN有任何一部主机想要传送封包出去时，这个封包是这样透过Linux主机而传送出去：
1. 先经过NAT table的PREROUTING链；
2. 经由路由判断确定这个封包是要进入本机与否，若不进入本机，则下一步；
3. 再经过Filter table的FORWARD链；
4. 通过NAT table的POSTROUTING链，最后传送出去。
NAT服务器的重点就在于上面流程的第1,4步骤，也就是NAT table的两条重要的链：PREROUTING与POSTROUTING。那这两条链有什么重要的功能呢？重点在于修改IP！但是这两条链修改的IP是不一样的！POSTROUTING在修改来源IP，PREROUTING则在修改目标IP。由于修改的IP不一样，所以就称为来源NAT(Source NAT,SNAT)及目标NAT(Destination NAT,DNAT)。我们先来谈一谈IP分享器功能的SNAT吧！

上述操作只是临时生效并没有保存，系统重启或iptables服务重启后会恢复原来的规则，如需保存到防火墙规则中，则执行以下命令：
service iptables save
执行这个命令的时候有时候可能会报错：The service command supports only basic LSB actions (start, stop, restart, try-restart, reload, force-reload, status). For other actions, please try to use systemctl.
这是因为没有安装iptables服务，直接使用yum安装iptables服务即可.
yum install iptables-services
安装完成后，重新执行 service iptables save 命令即可保存成功。
保存后重启依然没有生效，需要设置iptables开机自启才可使配置生效。
执行如下命令（老版本命令为：service iptables on），设置iptables开机自启
systemctl enable iptables.service

iptables -t nat -S  // 显示目前类型为nat下的所有规则
例：
-P PREROUTING ACCEPT
-P INPUT ACCEPT
-P OUTPUT ACCEPT
-P POSTROUTING ACCEPT
-N DOCKER
-A PREROUTING -m addrtype --dst-type LOCAL -j DOCKER
-A OUTPUT ! -d 127.0.0.0/8 -m addrtype --dst-type LOCAL -j DOCKER
-A POSTROUTING -s 172.17.0.0/16 ! -o docker0 -j MASQUERADE
-A POSTROUTING -s 172.17.0.2/32 -d 172.17.0.2/32 -p tcp -m tcp --dport 10000 -j MASQUERADE
-A POSTROUTING -s 172.17.0.2/32 -d 172.17.0.2/32 -p tcp -m tcp --dport 9999 -j MASQUERADE
-A DOCKER -i docker0 -j RETURN
-A DOCKER ! -i docker0 -p tcp -m tcp --dport 9000 -j DNAT --to-destination 172.17.0.2:10000
-A DOCKER ! -i docker0 -p tcp -m tcp --dport 8085 -j DNAT --to-destination 172.17.0.2:9999
在上述命令打印出的规则前面加iptables -t nat可以增加相应的规则
例：
iptables -t nat -A POSTROUTING -s 172.17.0.0/16 ! -o docker0 -j MASQUERADE
iptables -t nat -A OUTPUT ! -d 127.0.0.0/8 -m addrtype --dst-type LOCAL -j DOCKER
将上述命令中的-A改成-D即可删除相应的规则
例：
iptables -t nat -D POSTROUTING -s 172.17.0.0/16 ! -o docker0 -j MASQUERADE
iptables -t nat -D OUTPUT ! -d 127.0.0.0/8 -m addrtype --dst-type LOCAL -j DOCKER

netstat命令是一个监控TCP/IP网络的非常有用的工具，它可以显示路由表、实际的网络连接以及每一个网络接口设备的状态信息。
-a或--all：显示所有连线中的Socket（所有状态）； 
-A<网络类型>或--<网络类型>：列出该网络类型连线中的相关地址； 
-c或--continuous：持续列出网络状态； 
-C或--cache：显示路由器配置的快取信息； 
-e或--extend：显示网络其他相关信息； 
-F或--fib：显示FIB； 
-g或--groups：显示多重广播功能群组组员名单； 
-h或--help：在线帮助； 
-i或--interfaces：显示网络界面信息表单； 
-l或--listening：显示监控中的服务器的Socket； 
-M或--masquerade：显示伪装的网络连线； 
-n或--numeric：直接使用ip地址，而不通过域名服务器； 
-N或--netlink或--symbolic：显示网络硬件外围设备的符号连接名称； 
-o或--timers：显示计时器； 
-p或--programs：显示正在使用Socket的程序识别码和程序名称； 
-r或--route：显示Routing Table； 
-s或--statistice：显示网络工作信息统计表； 
-t或--tcp：显示TCP传输协议的连线状况； 
-u或--udp：显示UDP传输协议的连线状况； 
-v或--verbose：显示指令执行过程； 
-V或--version：显示版本信息； 
-w或--raw：显示RAW传输协议的连线状况； 
-x或--unix：此参数的效果和指定"-A unix"参数相同； 
--ip或--inet：此参数的效果和指定"-A inet"参数相同。

netstat -nat|grep -i "80"|wc -l
netstat -an会打印系统当前网络链接状态，而grep -i "80"是用来提取与80端口有关的连接的，wc -l进行连接数统计。最终返回的数字就是当前所有80端口的请求总数。
watch -n 1 -d 'netstat -an | grep "21" | wc -l'

ss简介
ss是Socker-Statistics的缩写，是一款非常适用、快速、跟踪显示的网络套接字的新工具。它和netstat显示的内容类似，但它比netstat更加强大。当服务器的socket连接数量变得非常大时，无论是使用netstat命令还是直接cat/proc/net/tcp，执行速度都会很慢。而用ss可以快速、有效的执行并得到结果。ss利用到了TCP协议栈中tcp_diag。tcp_diag是一个用于分析统计的模块，可以获得Linux内核中第一手的信息，这就确保了ss的快捷高效。当然，如果你的系统中没有tcp_diag，ss也可以正常运行，只是效率会变得稍慢。

yum install iproute iproute-doc

语法格式
ss [OPTION]... [FILTER]

常用选项
-t: tcp协议相关；
-u: udp协议相关；
-w: 裸套接字相关；
-x： unix sock相关；
-l: listen状态的连接；
-a: 显示所有sockets信息；
-n: 数字格式；
-p: 相关的程序及PID；
-e: 扩展的信息；
-m：内存用量；
-o：计时器信息；
-s：显示当前sockets的统计信息的摘要；
-i：显示系统内部tcp连接；
-r：解析主机名；
-4：仅显示IPv4的sockets连接；
-6：仅显示IPv6的sockets连接；

常用选项示例
[root@CentOS7.3 ~]#ss -an               #列出所有的sockets连接。   
[root@CentOS7.3 ~]#ss -tnl              #列出和tcp相关的sockets连接。
[root@CentOS7.3 ~]#ss -unl              #列出和udp相关的sockets连接。

匹配过滤本机ip地址和端口
[root@centos7.3 ~]#ss src :22               #匹配本机端口为22的连接
Netid State      Recv-Q Send-Q  Local Address:Port                   Peer Address:Port                
tcp   ESTAB      0      0      192.168.xxx.xxx:ssh                   192.168.166.1:63892                
tcp   ESTAB      0      52     192.168.xxx.xxx:ssh                   192.168.166.1:63076  
[root@centos7.3 ~]#ss src :ssh              #匹配所有ssh协议的连接
Netid State      Recv-Q Send-Q  Local Address:Port                   Peer Address:Port                
tcp   ESTAB      0      0      192.168.166.137:ssh                   192.168.166.1:63892                
tcp   ESTAB      0      52     192.168.166.137:ssh                   192.168.166.1:63076                
[root@centos7.4-1 ~]#ss src 192.168.1.2:ssh     #匹配单个IP地址的ssh协议连接
Netid State      Recv-Q Send-Q  Local Address:Port                   Peer Address:Port                
tcp   ESTAB      0      0      192.168.166.137:ssh                   192.168.166.1:63892                
tcp   ESTAB      0      52     192.168.166.137:ssh                   192.168.166.1:63076 

匹配过滤远程ip地址和端口
[root@centos7.4-1 ~]#ss dst 119.75.213.61           #匹配单个远程IP的所有连接
Netid State      Recv-Q Send-Q  Local Address:Port                   Peer Address:Port                
tcp   ESTAB      0      0        192.168.0.25:59484                 119.75.213.61:http                 
[root@centos7.4-1 ~]#ss dst 119.75.213.61:80        #只匹配单个IP地址的80端口
Netid State      Recv-Q Send-Q  Local Address:Port                   Peer Address:Port                
tcp   ESTAB      0      0        192.168.0.25:59484                 119.75.213.61:http

将本地或者远程端口和一个数比较
[root@centos7.3 ~]# ss  sport = :http 
[root@centos7.3 ~]# ss  dport = :http 
[root@centos7.3 ~]# ss  dport \> :1024 
[root@centos7.3 ~]# ss  sport \> :1024 
[root@centos7.3 ~]# ss sport \< :32000 
[root@centos7.3 ~]# ss  sport eq :22 
[root@centos7.3 ~]# ss  dport != :22 

使用state 过滤sockets信息
显示所有状态为established的http连接
[root@CentOS7.3 ~]#ss -o state established '( dport = :smtp or sport = :http )' 
Netid Recv-Q Send-Q       Local Address:Port                        Peer Address:Port 
显示处于 FIN-WAIT-1状态的源端口为 80或者 443，目标网络为 192.168.1/24所有 tcp套接字
ss -o state fin-wait-1 '( sport = :http or sport = :https )' dst 192.168.1/24
使用tcp连接的状态进行过滤
ss -4 state FILTER-NAME-HERE
ss -6 state FILTER-NAME-HERE
FILTER-NAME-HERE 可用状态：
established
syn-sent
syn-recv
fin-wait-1
fin-wait-2
time-wait
closed
close-wait
last-ack
closing
all             #所有以上状态。
connected       #除了listen and closed的所有状态。
synchronized    #所有已连接的状态除了syn-sent。
bucket          #显示状态为maintained as minisockets,如：time-wait和syn-recv。
big             #和bucket相反。
[root@CentOS7.3 ~]#ss -4 state closed
Netid Recv-Q Send-Q       Local Address:Port                        Peer Address:Port                
udp   0      0                        *:mdns                                   *:*                    
udp   0      0                        *:25506                                  *:*                    
udp   0      0            192.168.xxx.1:domain                                 *:*                    
udp   0      0                 *%virbr0:bootps                                 *:*                    
udp   0      0                        *:bootpc                                 *:*                    
udp   0      0                        *:53379                                  *:*

注意：
如果不添加选项 ss 命令默认输出所有建立的连接(不包含监听的端口)，包括 tcp, udp, and unix socket 三种类型的连接：
显示一个所有的有效连接信息列表，包括已建立的连接（ESTABLISHED），也包括监听连接请求（LISTENING）的那些连接。
LISTEN和LISTENING的状态只有用 -a 或者 -l 才能看到
显示所有已建立的有效连接。命令：netstat -n、或者ss -n（-n,--numeric 不解析服务名称，ss -t和ss -nt显示的结果应该完全一致：）
ss -t：解析服务名称：显示的结果中以【IP:服务名】的形式展示；
ss -nt：不解析服务名称：显示的结果中以【IP:Port】的形式展示；
显示所有已建立的所有连接。命令：netstat -a、或者ss -a
参数组合说明：
显示当前TCP连接状况。命令：netstat -nt、或者ss -nt
列出所有TCP端口。命令：netstat -at、或者ss -at
-t、-u显示的是已建立的TCP或者UDP连接（即State为ESTAB的连接）


linux查看某一个进程的socket连接数
ls /proc/18709/fd -l | grep socket: | wc -l     18709是进程ID

linux中， 每一个进程在内核中，都对应有一个“打开文件”数组，存放指向文件对象的指针，而 fd是这个数组的下标。我们对文件进行操作时，系统调用，将fd传入内核，内核通过fd找到文件，对文件进行操作。
既然是数组下标，fd的类型为int， < 0 为非法值， >=0 为合法值。
在linux中，一个进程默认可以打开的文件数为1024个，fd的范围为0~1023。可以通过设置，改变最大值。在linux中，值为0、1、2的fd，分别代表标准输入、标准输出、标准错误输出。在上一篇文章中，使用重定向 2>/dev/null 就是把标准错误输出重定向到位桶中去，不显示出来。因为 0 1 2已经被linux使用了，通常在程序中打开的fd，是从3开始的。但我们在判断一个fd是否合法时，依然要使用>=0的判断标准。fd的分配原则，是从小到大，找到第一个不用的进行分配。除了open之外， socket编程的socket()/accept()等函数，也会返回一个fd值。
    1）Linux系统下，所有进程允许打开的最大fd数量。查询语句：
        /proc/sys/fs/file-max
    2）Linux系统下，所有进程已经打开的fd数量及允许的最大数量。查询语句：
        /proc/sys/fs/file-nr
    3）单个进程允许打开的最大fd数量.查询语句：
        ulimit -n
    4)单个进程（例如进程id为5454）已经打开的fd.查询语句：
        ls -l /proc/5454/fd/
Linux的文件机制就相当于面向对象里面的多态，拿到一个文件描述符都可以进行read或者write。但是具体的read和write却跟对应文件描述符的具体实现不同。比如socket的就是走网络，普通文件的就是走磁盘IO。
##############################################################【linux】网络####################################################

##############################################################【linux】lsof####################################################
lsof（list open files）是一个列出当前系统打开文件的工具。在linux环境下，任何事物都以文件的形式存在，通过文件不仅仅可以访问常规数据，还可以访问网络连接和硬件,所以如传输控制协议(TCP)和用户数据报协议(UDP)套接字等，系统在后台都为该应用程序分配了一个文件描述符，无论这个文件的本质如何，该文件描述符为应用程序与基础操作系统之间的交互提供了通用接口。因为应用程序打开文件的描述符列表提供了大量关于这个应用程序本身的信息，因此通过lsof工具能够查看这个列表对系统监测以及排错将是很有帮助的。

1．命令格式：
lsof [参数][文件]

2．命令功能：
用于查看你进程开打的文件，打开文件的进程，进程打开的端口(TCP、UDP)。找回/恢复删除的文件。是十分方便的系统监视工具，因为 lsof 需要访问核心内存和各种文件，所以需要root用户执行。
lsof打开的文件可以是：
1.普通文件
2.目录
3.网络文件系统的文件
4.字符或设备文件
5.(函数)共享库
6.管道，命名管道
7.符号链接
8.网络文件（例如：NFS file、网络socket，unix域名socket）
9.还有其它类型的文件，等等
3．命令参数：
-a 列出打开文件存在的进程
-c<进程名> 列出指定进程所打开的文件
-g  列出GID号进程详情
-d<文件号> 列出占用该文件号的进程
+d<目录>  列出目录下被打开的文件
+D<目录>  递归列出目录下被打开的文件
-n<目录>  列出使用NFS的文件
-i<条件>  列出符合条件的进程。（4、6、协议、:端口、 @ip ）
-p<进程号> 列出指定进程号所打开的文件
-u  列出UID号进程详情
-h 显示帮助信息
-v 显示版本信息
##############################################################【linux】lsof####################################################

######################################################【linux】大文件切割命令split############################################
按照行数分割，如下：
split -l 10000 test.txt test
会在test.txt当前目录下生成以test前缀的一系列文件
按照字节数分割，如下：
split -b 100m test.txt test
如果要切割文件指定命名，参考如下：
split -l 2000 test.txt -d -a 2 lim_
-l：按行分割，上面表示将urls.txt文件按2000行一个文件分割为多个文件
-d：添加数字后缀，如00、01、02
-a 2：表示用两位数据来顺序命名
lim_：用来定义分割后的文件名前面的部分。
######################################################【linux】大文件切割命令split############################################

######################################################【linux】vmstat############################################
1.说明
vmstat命令是最常见的Linux/Unix监控工具，属于sysstat包。可以展现给定时间间隔的服务器的状态值,包括服务器的CPU使用率，内存使用，虚拟内存交换情况,IO读写情况。这个命令是我查看Linux/Unix最喜爱的命令，一个是Linux/Unix都支持，二是相比top，我可以看到整个机器的CPU,内存,IO的使用情况，而不是单单看到各个进程的CPU使用率和内存使用率(使用场景不一样)。
2.安装
yum install -y sysstat

一般vmstat工具的使用是通过两个数字参数来完成的，第一个参数是采样的时间间隔数，单位是秒，第二个参数是采样的次数，如:
root@local:~# vmstat 2 1
procs -----------memory---------- ---swap-- -----io---- -system-- ----cpu----
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa
 1  0      0 3498472 315836 3819540    0    0     0     1    2    0  0  0 100  0
2表示每个两秒采集一次服务器状态，1表示只采集一次。

实际上，在应用过程中，我们会在一段时间内一直监控，不想监控直接结束vmstat就行了,例如:
root@local:~# vmstat 2  
procs -----------memory---------- ---swap-- -----io---- -system-- ----cpu----
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa
 1  0      0 3499840 315836 3819660    0    0     0     1    2    0  0  0 100  0
 0  0      0 3499584 315836 3819660    0    0     0     0   88  158  0  0 100  0
 0  0      0 3499708 315836 3819660    0    0     0     2   86  162  0  0 100  0
 0  0      0 3499708 315836 3819660    0    0     0    10   81  151  0  0 100  0
 1  0      0 3499732 315836 3819660    0    0     0     2   83  154  0  0 100  0
这表示vmstat每2秒采集数据，一直采集，直到我结束程序，这里采集了5次数据我就结束了程序。

3.字段含义说明：
Procs（进程）
r:等待执行的任务数
展示了正在执行和等待cpu资源的任务个数。当这个值超过了cpu个数，就会出现cpu瓶颈。
b:等待IO的进程数量
Memory(内存)
swpd:正在使用虚拟的内存大小，单位k
free:空闲内存大小
如free的值很低，基于接近于0，也不一定就是系统内存已经耗尽，还需要结合buffer和cache的使用量，如果buffer和cache占用了很多内存资源，则代表没有问题，说明系统把空闲的内存都用于缓存，反而是提升了I/O性能，当系统需要内存时，buffer和cache可以随时被回收回来。
buff:已用的buff大小，对块设备的读写进行缓冲
cache:已用的cache大小，文件系统的cache
如果cache的值比较大，则说明系统缓存了比较多的磁盘数据，有利于磁盘I/O性能的提升，此时，bi会相对较小，因为很多读写磁盘的操作都由cache来承担了。
inact:非活跃内存大小，即被标明可回收的内存，区别于free和active（当使用-a选项时显示）
active:活跃的内存大小（当使用-a选项时显示）
Swap
si:每秒从交换区写入内存的大小（单位：kb/s）
so:每秒从内存写到交换区的大小
si和so则代表读写SWAP的数量，这两个值如果长期大于0，则表示系统需要经常读写交换分区，这样会消耗CPU资源和磁盘I/O性能。如能确定物理内存存在瓶颈，则需要进行扩容或迁移了。
IO
bi:每秒读取的块数（读磁盘）
bo:每秒写入的块数（写磁盘）
如果bi和bo值很大，则说明系统正在进行大量的磁盘读写操作。如果是用户正在进行的操作，则没有问题，否则需要进行排查哪个设备或分区在进行大量读写操作。
system
in:每秒中断数，包括时钟中断
cs:每秒上下文切换数
这两个值越大，会看到由内核消耗的cpu时间sy会越。
秒上下文切换次数：例如我们调用系统函数，就要进行上下文切换，线程的切换，也要进程上下文切换，这个值要越小越好，太大了，要考虑调低线程或者进程的数目
CPU（以百分比表示）
us:用户进程执行消耗cpu时间(user time)
sy:系统进程消耗cpu时间(system time)
Id:空闲时间(包括IO等待时间)一般来说 us+sy+id=100
wa:等待IO时间
us的值比较高时，说明用户进程消耗的cpu时间多，但是如果长期超过50%的使用，那么我们就该考虑优化程序算法或其他措施了
sys的值过高时，说明系统内核消耗的cpu资源多，这个不是良性的表现，我们应该检查原因。这里us + sy的参考值为80%，如果us+sy 大于 80%说明可能存在CPU不足
wa过高时，说明io等待比较严重，这可能是由于磁盘大量随机访问造成的，也有可能是磁盘的带宽出现瓶颈。

在Linux系统中，为了提高文件系统性能，内核利用一部分物理内存分配出缓冲区，用于缓存系统操作和数据文件，当内核收到读写的请求时，内核先去缓存区找是否有请求的数据，有就直接返回，如果没有则通过驱动程序直接操作磁盘。
缓存机制优点：减少系统调用次数，降低CPU上下文切换和磁盘访问频率。
CPU上下文切换：CPU给每个进程一定的服务时间，当时间片用完后，内核从正在运行的进程中收回处理器，同时把进程当前运行状态保存下来，然后加载下一个任务，这个过程叫做上下文切换。实质上就是被终止运行进程与待运行进程的进程切换。
Swap用途：Swap意思是交换分区，通常我们说的虚拟内存，是从硬盘中划分出的一个分区。当物理内存不够用的时候，内核就会释放缓存区（buffers/cache）里一些长时间不用的程序，然后将这些程序临时放到Swap中，也就是说如果物理内存和缓存区内存不够用的时候，才会用到Swap。

buffers和cached解释
cached是cpu与内存间的，buffer是内存与磁盘间的；两者都是RAM中的数据，buffer是即将要被写入磁盘的，而cache是被从磁盘中读出来的。
缓存（cached）是把读取过的数据保存起来，重新读取时若命中（找到需要的数据）就不要去读硬盘了，若没有命中就读硬盘。其中的数据会根据读取频率进行组织，把最频繁读取的内容放在最容易找到的位置，把不再读的内容不断往后排，直至从中删除
缓冲（buffers）是根据磁盘的读写设计的，把分散的写操作集中进行，减少磁盘碎片和硬盘的反复寻道，从而提高系统性能。linux有一个守护进程定期 清空缓冲内容（即写入磁盘），也可以通过sync命令手动清空缓冲。

Cache（缓存），为了调高CPU和内存之间数据交换而设计，Buffer（缓冲）为了提高内存和硬盘（或其他I/O设备的数据交换而设计）。
CPU ---> Cache ---> 内存 ---> Buffer ---> 硬盘
Cache：缓冲区，高速缓存，是位于CPU与主内存间的一种容量较小但速度很高的存储器。由于CPU的速度远高于主内存，CPU直接从内存中存取数据要等待一定时间周期，Cache中保存着CPU刚用过或循环使用的一部分数据，当CPU再次使用该部分数据时可从Cache中直接调用,这样就减少了CPU的等待时间,提高了系统的效率。Cache又分为一级Cache(L1 Cache)和二级Cache(L2 Cache)，L1 Cache集成在CPU内部，L2 Cache早期一般是焊在主板上,现在也都集成在CPU内部，常见的容量有256KB或512KB L2 Cache。它是根据程序的局部性原理而设计的，就是cpu执行的指令和访问的数据往往在集中的某一块，所以把这块内容放入cache后，cpu就不用在访问内存了，这就提高了访问速度。当然若cache中没有cpu所需要的内容，还是要访问内存的。从内存读取与磁盘读取角度考虑，cache可以理解为操作系统为了更高的读取效率，更多的使用内存来缓存可能被再次访问的数据。Cache并不是缓存文件的，而是缓存块的(块是I/O读写最小的单元)；Cache一般会用在I/O请求上，如果多个进程要访问某个文件，可以把此文件读入Cache中，这样下一个进程获取CPU控制权并访问此文件直接从Cache读取，提高系统性能。
Buffer：缓冲区，一个用于存储速度不同步的设备或优先级不同的设备之间传输数据的区域。通过buffer可以减少进程间通信需要等待的时间，当存储速度快的设备与存储速度慢的设备进行通信时，存储慢的数据先把数据存放到buffer，达到一定程度存储快的设备再读取buffer的数据，在此期间存储快的设备CPU可以干其他的事情。Buffer：一般是用在写入磁盘的，例如：某个进程要求多个字段被读入，当所有要求的字段被读入之前已经读入的字段会先放到buffer中。Buffer是根据磁盘的读写设计的，把分散的写操作集中进行，减少磁盘碎片和硬盘的反复寻道，从而提高系统性能。linux有一个守护进程定期清空缓冲内容（即写入磁盘），也可以通过sync命令手动清空缓冲。
cache是高速缓存，用于CPU和内存之间的缓冲；
buffer是I/O缓存，用于内存和硬盘的缓冲
######################################################【linux】vmstat############################################

######################################################【linux】tmpfs############################################
linux下面VM的大小由RM(Real Memory)和swap组成,RM的大小就是物理内存的大小，而Swap的大小是由你自己决定的。
swap空间是由磁盘空间转换成虚拟内存空间的，
tmpfs是由虚拟内存空间转换成文件系统使用的，正如这个定义它最大的特点就是它的存储空间在VM里面，所以tmpfs最大的存储空间可达（The size of RM + The size of Swap）
默认的Linux发行版中的内核配置都会开启tmpfs，映射到了/dev/下的shm目录。可以通过df命令查看结果。/dev/shm/是linux下一个非常有用的目录，因为这个目录不在硬盘上，而是在内存里。
tmpfs有以下特点：
1。动态文件系统的大小，/dev/shm/需要注意的一个是容量问题，在linux下，它默认最大为内存的一半大小，使用df -h命令可以看到。但它并不会真正的占用这块内存，如果/dev/shm/下没有任何文件，它占用的内存实际上就是0字节；如果它最大为1G，里头放有 100M文件，那剩余的900M仍然可为其它应用程序所使用，但它所占用的100M内存，是绝不会被系统回收重新划分的
2。tmpfs 的另一个主要的好处是它闪电般的速度。因为典型的 tmpfs 文件系统会完全驻留在RAM中，读写几乎可以是瞬间的。
3。tmpfs 数据在重新启动之后不会保留，因为虚拟内存本质上就是易失的。所以有必要做一些脚本做诸如加载，绑定的操作。

总结：
看出来/dev/shm是一个设备文件, 可以把/dev/shm看作是系统内存的入口, 可以把它看做是一块物理存储设备，一个tmp filesystem, 你可以通过这个设备向内存中读写文件, 以加快某些I/O高的操作，比如对一个大型文件频繁的open, write, read，
据说oracle就利用了/dev/shm(shitou没用过oracle), 可以通过mount命令列出当前的/dev/shm的挂载的文件系统,
你可以直接对/dev/shm进行读写操作, 例如:
#touch /dev/shm/file1
既然是基于内存的文件系统，系统重启后/dev/shm下的文件就不存在了。Linux默认(CentOS)/dev/shm分区的大小是系统物理内存的50%, 虽说使用/dev/shm对文件操作的效率会高很多。但是目前各发行软件中却很少有使用它的(除了前面提到的Oracle), 可以通过ls /dev/shm查看下面是否有文件, 如果没有就说明当前系统并没有使用该设备。
######################################################【linux】tmpfs############################################

######################################################【linux】lvm############################################
一、基础概念
使用df -hl命令看到/dev/mapper/vg_*-lv_*这样的一些挂载点映射，
LVM是Logical Volume Manager(逻辑卷管理)的简写，是Linux环境下对磁盘分区进行管理的一种机制度，LVM将一个或多个硬盘的分区在逻辑上集合，相当于一个大硬盘来使 用，当硬盘的空间不够使用的时候，可以继续将其它的硬盘的分区加入其中，这样可以实现磁盘空间的动态管理，相对于普通的磁盘分区有很大的灵活性。
在使用LVM对磁盘进行动态管理以后，我们是以逻辑卷的方式呈现给上层的服务的,完整过程是：磁盘物理分区-物理卷-卷组-逻辑卷-挂载到目录
物理拓展(Physical Extend，PE)：卷的最小单位，可配置，默认4M大小，就像我们的数据是以页的形式存储一样，类比为raid的chunk，文件系统的block，卷就是以PE的形式存储。
物理卷（Physical Volume,PV）：物理卷，如果要使用逻辑卷，首先第一步操作就是将磁盘格式化成PV，从上图可以看出PV是保护PE的，PV内PE的数量取决于这块磁盘的容量/4M。
卷组（Volume Group,VG）：VG就是将很多PE组合在一起生成一个卷组，当然PE是可以跨磁盘的，如果当前服务器磁盘空间不足就可以增加一个新磁盘对当前系统不会产生任何影响。
      1、可动态扩展或缩减VG中PV的数量
      2、类似于扩展分区，不能直接格式化使用
      3、PE只有在VG创建后才会出现在PV中，其大小由创建时指定。默认为4M
逻辑卷（Logical Volume,LV）：逻辑卷最终是给用户使用的，前面几个都是为创建逻辑卷做的准备，创建逻辑卷的大小只要不超过VG剩余空间就可以。
    　1、可动态扩展或缩减LV的大小，或 LV中PE的数量，即可跨越多个PV。
    　2、可以直接格式化并挂载使用。
      3、LE只有在LV创建后才会出现在VG中，其大小由创建时指定。默认为1280

二、创建LVM
2.1 pv管理（物理卷管理）
pvcreate    # 创建pv
pvscan      # 扫描并列出所有的pv
pvs         # 显示与pvscan相似
pvdisplay   # 列出pv属性信息
pvremove    # 移除pv
pvmove      # 移除pv中的数据
pvcreate  /dev/sdc1 /dev/sdd1  /dev/sdb1  /dev/sdc2  -y  # 对已经划分好的几块分区创建pv；-y选项用于自动回答yes
  Wiping ext4 signature on /dev/sdc1.
  Physical volume "/dev/sdc1" successfully created.
  Physical volume "/dev/sdd1" successfully created.
  Physical volume "/dev/sdb1" successfully created.
  Physical volume "/dev/sdc2" successfully created.

pvscan  # 扫描并列出所有的pv
  PV /dev/sdc2                      lvm2 [10.00 GiB]
  PV /dev/sdd1                      lvm2 [15.00 GiB]
  PV /dev/sdb1                      lvm2 [15.00 GiB]
  PV /dev/sdc1                      lvm2 [15.00 GiB]
  Total: 4 [55.00 GiB] / in use: 0 [0   ] / in no VG: 4 [55.00 GiB]   # 

pvs   
  PV         VG Fmt  Attr PSize  PFree 
  /dev/sdb1     lvm2 ---  15.00g 15.00g
  /dev/sdc1     lvm2 ---  15.00g 15.00g
  /dev/sdc2     lvm2 ---  10.00g 10.00g
  /dev/sdd1     lvm2 ---  15.00g 15.00g

pvdisplay /dev/sdb1  # pvdisplay 可以列出更详细的pv信息
  "/dev/sdb1" is a new physical volume of "15.00 GiB"
  --- NEW Physical volume ---
  PV Name               /dev/sdb1
  VG Name               
  PV Size               15.00 GiB
  Allocatable           NO
  PE Size               0   
  Total PE              0
  Free PE               0
  Allocated PE          0
  PV UUID               OBSoTj-YcyL-XPGh-wsTt-9zcj-qXSp-YC9YZY

2.2 管理vg
vgcreate       # 创建VG
vgscan         # 扫描并列出所有的vg
vgdisplay      # 列出vg属性信息
vgremove       # 移除vg，即删除vg
vgreduce       # 从vg中移除pv，vg减小
vgextend       # 将pv添加到vg中,vg扩容
vgchange       # 修改vg属性，

vgcreate -s 6M  vggroup  /dev/sdb1 /dev/sdc1 /dev/sdc2 /dev/sdd1   # -s设定pe大小，默认为4M；vggroup为设置的vg名称；后边跟的4个文件为要创建vg的组员
  Volume group "vggroup" successfully created  

[root@CentOS7 ~]#vgscan 
  Reading volume groups from cache.
  Found volume group "vggroup" using metadata type lvm2

[root@CentOS7 ~]#vgdisplay 
  --- Volume group ---
  VG Name               vggroup
  System ID             
  Format                lvm2   # 格式分为lvm1 和lvm2
  Metadata Areas        4
  Metadata Sequence No  1
  VG Access             read/write
  VG Status             resizable
  MAX LV                0
  Cur LV                0
  Open LV               0
  Max PV                0
  Cur PV                4
  Act PV                4
  VG Size               <54.98 GiB
  PE Size               6.00 MiB
  Total PE              9383
  Alloc PE / Size       0 / 0   
  Free  PE / Size       9383 / <54.98 GiB
  VG UUID               flmx2S-0LT9-hgCZ-HcfL-TT6n-jkna-jSIWbp

[root@CentOS7 ~]#vgreduce vggroup  /dev/sdd1
  Removed "/dev/sdd1" from volume group "vggroup"

[root@CentOS7 ~]#vgdisplay 
  --- Volume group ---
  VG Name               vggroup
  System ID             
  Format                lvm2
  Metadata Areas        3
  Metadata Sequence No  2
  VG Access             read/write
  VG Status             resizable
  MAX LV                0
  Cur LV                0
  Open LV               0
  Max PV                0
  Cur PV                3
  Act PV                3
  VG Size               39.98 GiB
  PE Size               6.00 MiB
  Total PE              6824
  Alloc PE / Size       0 / 0   
  Free  PE / Size       6824 / 39.98 GiB
  VG UUID               flmx2S-0LT9-hgCZ-HcfL-TT6n-jkna-jSIWbp

# 可见，减掉sdd1后vg里的数量变为3，容量也减少了；
[root@CentOS7 ~]#vgextend vggroup  /dev/sdd1  # 在vggroup中再添加一块pv；
  Volume group "vggroup" successfully extended

vgchange用于设置卷组的活动状态，卷组的激活状态主要影响的是lv。使用-a选项来设置。
vgchange -a  y  vggroup  # 将vggroup设置为活动状态(active yes)
vgchange -a  y  vggroup  # 将vggroup设置为非激活状态(active no)

2.3 管理lv
lvcreate   # 创建lv
lvscan     # 扫描并列出所有的lv
lvdisplay  # 列出lv属性信息
lvremove   # 移除lv，即删除lv
lvreduce(lvresize)  # 缩小lv容量
lvextend(lvresize)  # 增大lv容量
lvresize   # 改变lv容量

格式：lvcreate {-L size(M/G)  |  -l PEnum}  -n  lv_name  vg_name
选项说明：
-L：根据大小来创建lv，即分配多大空间给此lv
-l：根据PE的数量来创建lv，即分配多少个pe给此lv
-n：指定lv的名称
示例：
[root@CentOS7 ~]#lvcreate -L 20G -n lv1 vggroup   
  Rounding up size to full physical extent 20.00 GiB
  Logical volume "lv1" created.

[root@CentOS7 ~]#lvscan 
  ACTIVE            '/dev/vggroup/lv1' [20.00 GiB] inherit

[root@CentOS7 ~]#lvdisplay   # 一般后边跟lv1的绝对流经，/dev/vggroup/lv1
  --- Logical volume ---
  LV Path                /dev/vggroup/lv1
  LV Name                lv1
  VG Name                vggroup
  LV UUID                4Wnt9z-T8OP-cJL3-ViL8-QIAE-2vMC-UzNaOf
  LV Write Access        read/write
  LV Creation host, time CentOS7.songtai, 2018-12-19 18:41:23 +0800
  LV Status              available
  # open                 0
  LV Size                20.00 GiB
  Current LE             3414
  Segments               2
  Allocation             inherit
  Read ahead sectors     auto
  - currently set to     8192
  Block device           253:0
 
注意：创建lv后，将在/dev/vggroup目录中创建对应lv名称的软链接文件，同时也在/dev/mapper目录下创建链接文件，它们都指向/dev/dm设备。
[root@CentOS7 ~]#ll /dev/vggroup/lv1  /dev/mapper/vggroup-lv1 
lrwxrwxrwx. 1 root root 7 Dec 19 18:41 /dev/mapper/vggroup-lv1 -> ../dm-0
lrwxrwxrwx. 1 root root 7 Dec 19 18:41 /dev/vggroup/lv1 -> ../dm-0

[root@CentOS7 ~]#ll -d /dev/dm-0 
brw-rw----. 1 root disk 253, 0 Dec 19 18:41 /dev/dm-0

2.4 格式化lv；挂载
mke2fs -t ext4 /dev/vggroup/lv1 
mount /dev/vggroup/lv1   /data/lvmnt/       # 也可以
mount /dev/mapper/vggroup-lv1  /data/lvmnt

三、扩容lvm
在对LV(逻辑卷)进行容量扩充之前先查看VG（卷组）中剩余空间有多少，扩充的大小不能超过VG剩余的空间大小；即使vg中没有空余的空间，也可以往vg中添加pv来扩容。
扩容的两个关键步骤如下：
(1).使用lvextend或者lvresize添加更多的pe或容量到lv中
(2).使用resize2fs命令(xfs则使用xfs_growfs)将lv增加后的容量增加到对应的文件系统中(此过程是修改文件系统而非LVM内容)
注意：扩容前须将挂载的逻辑卷卸载再进行扩容！
扩容前先看看还有多少空心啊的pe可以扩充：
vgdisplay    # 查看有多少空闲空间或空闲pe
vgdisplay | grep  -i pe    # 精确查找
  PE Size               4.00 MiB
  Total PE              15364
  Alloc PE / Size       6400 / 25.00 GiB
  Free  PE / Size       8964 / 35.02 GiB                            # 还有8964个pe，35.02G的空间未使用
lvextend  -L +10g  /dev/vg1/lv1    #  按大小扩容10G
lvextend  -l +2500  /dev/vg1/lv1   # 按pe数量扩容2500个pe
lvresize  -L +10G /dev/vg1/lv1 
lvreduce  -L -10G /dev/vg1/lv1      # 缩小容量
lvresize  -L -10G /dev/vg1/lv1

将扩容好的lv重新挂载后，df -h 发现容量并未变化，还需要resize2fs工具来改变ext文件系统的大小.(xfs_growfs)
resize2fs  /dev/vg1/lv1 
df -h
Filesystem           Size  Used Avail Use% Mounted on
/dev/sda2             48G  4.9G   41G  11% /
/dev/sda1            976M   40M  886M   5% /boot
/dev/sda3             29G  113M   28G   1% /data
/dev/mapper/vg1-lv1   34G   48M   32G   1% /data/lvmnt    # 总容量已变化

实验：不卸载直接扩容全部剩余空间
lvresize  -l  +100%FREE  /dev/vg1/lv1  # 将vg1剩余的全部pe扩容至lv1
vgdisplay  | grep -i pe
  Open LV               1
  PE Size               4.00 MiB
  Total PE              15364
  Alloc PE / Size       15364 / 60.02 GiB
  Free  PE / Size       0 / 0                    # 已全部扩容，无空闲空间
resize2fs  /dev/vg1/lv1 
df -h
Filesystem           Size  Used Avail Use% Mounted on
/dev/sda2             48G  4.9G   41G  11% /
/dev/sda1            976M   40M  886M   5% /boot
/dev/sda3             29G  113M   28G   1% /data
/dev/mapper/vg1-lv1   59G   52M   56G   1% /data/lvmnt    # 在未卸载逻辑卷的情况下，resize2fs这个命令也成功了

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
创建：pv
pvcreate /dev/sda4 /dev/sdb1
将pv添加到vg中，vg扩容
vgextend cl /dev/sda4 /dev/sdb1

增大lv容量
lvextend /dev/cl/root -L +500G
将lv增加后的容量增加到对应的文件系统中
xfs_growfs /dev/mapper/cl-root

lvextend  /dev/vg0/lv_root -L +200G /dev/sda3
resize2fs /dev/mapper/vg0-lv_root (xfs则使用xfs_growfs)
lvextend  /dev/vg0/lv_var -L +500G /dev/sda3
resize2fs /dev/mapper/vg0-lv_var  (xfs则使用xfs_growfs)

查看文件系统格式：
df -T /dev/mapper/cl-root
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

四、缩减lvm
与扩容的步骤相反，我们倒着来一步一步操作，先卸载挂载点，具体全部操作如下：
umount  /data/lvmnt   # 卸载挂载点
[root@CentOS6 ~]#resize2fs   /dev/vg1/lv1  45G  # 现将文件系统直接缩减至45G，但提示要先e2fsck 检查
resize2fs 1.41.12 (17-May-2010)
Please run 'e2fsck -f /dev/vg1/lv1' first.               # 提示 先运行 'e2fsck -f /dev/vg1/lv1'  保障数据安全完整
[root@CentOS6 ~]#e2fsck -f /dev/vg1/lv1        
e2fsck 1.41.12 (17-May-2010)
Pass 1: Checking inodes, blocks, and sizes
Pass 2: Checking directory structure
Pass 3: Checking directory connectivity
Pass 4: Checking reference counts
Pass 5: Checking group summary information
/dev/vg1/lv1: 11/3940352 files (0.0% non-contiguous), 293333/15732736 blocks
resize2fs   /dev/vg1/lv1  45G      
resize2fs 1.41.12 (17-May-2010)
Resizing the filesystem on /dev/vg1/lv1 to 11796480 (4k) blocks.
The filesystem on /dev/vg1/lv1 is now 11796480 blocks long.        # 成功将lvm的文件系统的容量缩减至45G
lvresize -L 45G /dev/vg1/lv1           # 将lv的容量缩减至45G
  WARNING: Reducing active logical volume to 45.00 GiB.
  THIS MAY DESTROY YOUR DATA (filesystem etc.)
Do you really want to reduce vg1/lv1? [y/n]: y
  Size of logical volume vg1/lv1 changed from 60.02 GiB (15364 extents) to 45.00 GiB (11520 extents).
  Logical volume lv1 successfully resized.                                # 会有提示减少lvm容量会摧毁数据，y 同意缩减。

此时已经成功将lvm由60G缩减至45G ，至于减少的这15G是属于哪块设备的，我们通过检查pv来判断，毕竟PE --> PV --> VG --> LV ,哪些PE空闲直接查看PV即可。
[root@CentOS6 ~]#pvdisplay 
  --- Physical volume ---
  PV Name               /dev/sdd1
  VG Name               vg1
  PV Size               15.01 GiB / not usable 2.83 MiB
  Allocatable           yes 
  PE Size               4.00 MiB
  Total PE              3841
  Free PE               3
  Allocated PE          3838
  PV UUID               7xbtSO-sJ5P-F8h3-xPcd-FT5d-D9Zt-bHGp34
  --- Physical volume ---
  PV Name               /dev/sde1
  VG Name               vg1
  PV Size               15.01 GiB / not usable 2.83 MiB
  Allocatable           yes 
  PE Size               4.00 MiB
  Total PE              3841
  Free PE               3841
  Allocated PE          0
  PV UUID               bZsiMZ-ZhbM-szh1-EDBZ-YyOP-xfQX-S12UDH
# 可见 dev/sde1这块设备是完全空闲的,sdd1上空闲3个PE
补充：如果lvm有dev/sd{a,b,c,d,e}5块磁盘组成，我们在缩减容量是要指定空出sdb磁盘，怎么操作？
上面的操作完成后，已经空出了一块sde，那么我们只需将sdb中的数据（即PE）全部挪进sde即可，操作如下
pvdisplay   /dev/sdb           # 可见全部的PE都占用了
 PV Name               /dev/sdb1
  VG Name               vg1
  PV Size               15.01 GiB / not usable 2.83 MiB
  Allocatable           yes (but full)
  PE Size               4.00 MiB
  Total PE              3841
  Free PE               0
  Allocated PE          3841
  PV UUID               mdC964-Odex-JZKg-AiV0-4l2u-I3e4-ixWvtR
pvmove  /dev/sdb1:0-3841   /dev/sde     # 将/dev/sdb上0-3841编号的PE全部移动到/dev/sde
然后，再将这个空出的pv从vg中移出，最后再移出该pv即可，操作如下：
vgreduce  vg1 /dev/sde1   # 从vg1 中移出/dev/sde1;注意不是vgremove，该命令是删除vg的。
pvremove  /dev/sde1  # 移出该pv
pvdisplay   # 列表中已经没有了/dev/sde1
######################################################【linux】lvm############################################

######################################################【linux】DNS############################################
bind-utils是bind软件提供的一组DNS工具包，里面有一些DNS相关的工具。主要：dig，host，nslookup，nsupdate。使用这些工具可以进行域名解析和DNS调试工作。
yum install -y bind-utils

nslookup是name server lookup的缩写，顾名思义，nslookup就是用来查询DNS的。假如你想知道www.baidu.com对应的ip的话，就可以使用nslookup命令
nslookup命令有两种工作模式，一种是交互模式，另一种则是非交互模式。
交互模式：
[root@server01 ~]# nslookup
> www.baidu.com
Server:         172.20.10.1
Address:        172.20.10.1#53

Non-authoritative answer:
www.baidu.com   canonical name = www.a.shifen.com.
Name:   www.a.shifen.com
Address: 180.101.49.11
Name:   www.a.shifen.com
Address: 180.101.49.12
非交互模式：
[root@server01 ~]# nslookup www.baidu.com
Server:         172.20.10.1
Address:        172.20.10.1#53

Non-authoritative answer:
www.baidu.com   canonical name = www.a.shifen.com.
Name:   www.a.shifen.com
Address: 180.101.49.11
Name:   www.a.shifen.com
Address: 180.101.49.12

也可以指定一个DNS服务器地址，nslookup的第一个参数为域名，第二个参数为要连接的DNS服务器IP地址。
如果要在交互模式下指定DNS服务只需设置第一个参数为"-"
交互模式：nslookup - 8.8.8.8
非交互模式：nslookup www.baidu.com 8.8.8.8
######################################################【linux】DNS############################################

######################################################【linux】traceroute############################################
traceroute指令让你追踪网络数据包的路由途径，预设数据包大小是40Bytes，用户可另行设置。
traceroute -n -m 5 -q 4 -w 3 www.baidu.com
说明： -n 显示IP地址，不查主机名，  -m 设置跳数  
       -q 4每个网关发送4个数据包    -w 把对外发探测包的等待响应时间设置为3秒
探测包使用的基本UDP端口设置6888
traceroute -p 6888 www.baidu.com 
绕过正常的路由表，直接发送到网络相连的主机
traceroute -r www.baidu.com 
######################################################【linux】traceroute############################################

######################################################【linux】firewall############################################
1、开放端口
firewall-cmd --zone=public --add-port=5672/tcp --permanent   # 开放5672端口 --permanent 是永久配置 机子重启依然有效
firewall-cmd --zone=public --remove-port=5672/tcp --permanent  #关闭5672端口 --permanent 是永久配置 机子重启依然有效
firewall-cmd --reload   # 配置立即生效
 
2、查看防火墙所有开放的端口
firewall-cmd --zone=public --list-ports

3、开放或限制IP
firewall-cmd --permanent --add-rich-rule="rule family="ipv4" source address="192.168.56.110" port protocol="tcp" port="80" reject"
firewall-cmd --permanent --add-rich-rule="rule family="ipv4" source address="192.168.56.110" port protocol="tcp" port="80" accept"

firewall-cmd --permanent --remove-rich-rule="rule family="ipv4" source address="192.168.56.110" port protocol="tcp" port="80" reject"
firewall-cmd --permanent --remove-rich-rule="rule family="ipv4" source address="192.168.56.110" port protocol="tcp" port="80" accept"

4、查看防火墙所有开放的IP
firewall-cmd --zone=public --list-rich-rules

5、关闭防火墙
如果要开放的端口太多，嫌麻烦，可以关闭防火墙，安全性自行评估
systemctl stop firewalld.service

6、查看防火墙状态
firewall-cmd --state

允许或禁止root用户ssh远程登录，修改22端口
vim /etc/ssh/sshd_config，将PermitRootLogin的值改成no，并保存 #禁止root用户ssh远程登录
vim /etc/ssh/sshd_config，将Port修改为10022，#默认是22号端口，所以即时被注释依旧可以连接到。
firewall-cmd --zone=public --add-port=10022/tcp --permanent 
firewall-cmd --reload 
重启ssh
systemctl restart sshd

telnet server01 23
telnet使用root登陆报“Login incorrect”
应该修改目标主机/etc/pam.d/目录下的remote文件第一行
[root@ pam.d]# cat remote 
#%PAM-1.0
auth       required     pam_securetty.so
把第一行给注释掉再试试
[root@ pam.d]# cat remote 
#%PAM-1.0
#auth       required     pam_securetty.so

===============================================>>>centos7上通过firewalld配置网关服务器<<<===============================================
使用场景：有多台内网服务器，其中只有一台能够访问外网，但其他内网服务器也希望访问外网
假设内网网段为：192.168.56.0/24
可访问外网的内网服务器的内网IP为：192.168.56.111
可访问外网的内网服务器的内网网络接口为：enp0s3

在可以访问外网的服务器上做如下配置：
1) 开启ip_forward转发
# 在/etc/sysctl.conf中添加
net.ipv4.ip_forward=1
# 然后让其生效
sysctl -p
2) 转发内网段的流量
执行如下firewalld命令：
firewall-cmd --permanent --direct --passthrough ipv4 -t nat -I POSTROUTING -o enp0s3 -j MASQUERADE -s 192.168.56.0/24
firewall-cmd --reload
//查看规则：
firewall-cmd --direct --get-all-passthroughs
//删除规则：
firewall-cmd --permanent --direct --remove-passthrough ipv4 -t nat -I POSTROUTING -o enp0s3 -j MASQUERADE -s 192.168.56.0/24
//也可以再关闭防火墙的情况下直接添加iptables规则
iptables -t nat -I POSTROUTING -o enp0s3 -j MASQUERADE -s 192.168.56.0/24

之后，在需要访问外网的内网服务器上添加到192.168.56.111的网关即可访问外网了：
route add default gw 192.168.56.111 dev enp0s8 
如果希望永久有效，可将网关加到网络的配置文件里(/etc/sysconfig/network-scripts/ifcfg-enp0s8中的GATEWAY)

在配置网关服务器的时候注意以下几点：
1) 能ping通ip，ping不通域名。解决方案：
  a) 在网关服务器上安装named服务：
    yum install bind-chroot -y
	yum install bind-utils -y
  b) 修改配置文件：vim /etc/named.conf，
    修改listen-on为any，允许监听所有IP；
	修改localhost为any，允许任何主机查询。
  c) systemctl restart named   #重启服务
2) 域名解析正常后使用curl无法访问：
  a) 现象：
    源主机上的错误信息：没有到主机的路由，
    网关服务器上使用tcpdump抓包后发现错误信息：
    15:35:21.177409 IP 192.168.56.111 > 192.168.56.110: ICMP host 101.226.26.232 unreachable - admin prohibited, length 68
	192.168.56.110尝试与192.168.56.111建立连接但是192.168.56.111服务器以 ICMP 错误响应。错误代码 (unreachable - admin prohibited) 指出，由于防火墙规则 (-admin prohibited)，无法访问 TCP SYN 网段。
  b) 解决方案：关闭防火墙，直接通过iptables添加SNAT规则
    systemctl stop firewalld.service
	iptables -t nat -I POSTROUTING -o enp0s3 -j MASQUERADE -s 192.168.56.0/24

===============================================>>>centos7上通过firewalld配置网关服务器<<<===============================================

######################################################【linux】firewall############################################

######################################################【linux】hostname############################################
hostname 命令获取主机名
通过man hostname我们看到：
When called without any arguments, the program displays the current names: 
hostname will print the name of the system as returned by the gethostname(2) function.
意思是当我们执行hostname命令时，它会打印出系统主机名，而这个系统主机名是系统的gethostname(2)函数返回的。

hostname 命令临时修改主机名
这个临时修改实际上是修改了Linux-Kernel中一个同为hostname的内核参数。hostname是Linux系统的一个内核参数，它保存在/proc/sys/kernel/hostname下，它的值是Linux启动时从rc.sysinit读取的。

/etc/sysconfig/network配置文件永久修改主机名
CentOS 系统在启动时执行/etc/rc.d/rc.sysinit脚本，
它首先读取/etc/sysconfig/network中HOSTNAME参数，然后将系统主机名配置成获取的HOSTNAME。 脚本中相关代码如下：
if [ -f /etc/sysconfig/network ]; then
    . /etc/sysconfig/network
fi
if [ -z "$HOSTNAME" -o "$HOSTNAME" = "(none)" ]; then
    HOSTNAME=localhost
fi
结论：
/etc/sysconfig/network确实是hostname的配置文件，hostname的值跟该配置文件中的HOSTNAME有一定的关联关系，但是没有必然关系，hostname的值来自内核参数/proc/sys/kernel/hostname，
如果我通过命令sysctl kernel.hostname=Test修改了内核参数，那么hostname就变为了Test了。

hostname与/etc/hosts的关系
一般来说hostname并不是从/etc/hosts中获取的，而是从/ect/sysconfig/network中获取的，
但是在/etc/rc.d/rc.sysinit中，有如下逻辑判断，当hostname为localhost或localhost.localdomain时，将会使用接口IP地址对应的hostname来重新设置系统的hostname。
\# In theory there should be no more than one network interface active
\# this early in the boot process -- the one we're booting from.
\# Use the network address to set the hostname of the client.  This
\# must be done even if we have local storage.
ipaddr=
if [ "$HOSTNAME" = "localhost" -o "$HOSTNAME" = "localhost.localdomain" ]; then
        ipaddr=$(ip addr show to 0.0.0.0/0 scope global | awk '/[[:space:]]inet / { print gensub("/.*","","g",$2) }')
        for ip in $ipaddr ; do
                HOSTNAME=
                eval $(ipcalc -h $ip 2>/dev/null)
                [ -n "$HOSTNAME" ] && { hostname ${HOSTNAME} ; break; }
        done
fi
上面代码的意思就是如果从/ect/sysconfig/network中获取的HOSTNAME为localhost或localhost.localdomain时，就会获取接口的IP地址，根据这个IP地址在查找/etc/hosts文件对应的主机名（ipcalc命令的作用），然后将其设置为最终的hostname。

HOSTNAME存放的目录根据Linux的版本不同而不同：
例如Ubuntu、CentoOS 7，主机名存放在/etc/hostname文件中，而Fedora将主机名存放在/etc/sysconfig/network文件中。
所以，修改主机名时应注意区分是哪种linux发行版。

验证Linux主机名存放的目录（以centos7为例，在centos7中提供了一个新的命令, hostnamectl可以用来修改主机的名字。）：
# 先查看一个主机名
cat /etc/hostname
iz2ze2jkgn61mtv7csy6bgz
# 永久性的修改主机名后再查看
hostnamectl set-hostname senlin
cat /etc/hostname
senlin
可以看到通过hostnamectl set-hostname senlin实际上是修改了配置文件/etc/hostname，永久性的修改，需要重新启动服务器才有效果。

关于Hosts与network的异同之处：
1、hosts文件，路径：/etc/hosts,此文间是在网络上使用的，用于解析计算机名称和IP地址的映射关系，功能相当于windows下面的c:\windows\system32\drivers\etc\hosts文件，如果想使用计算机名称来访问对方的主机，需要把对方计算机的名称和IP地址写到本机的hosts文件中

2、network文件，路径：/etc/sysconfig/network,此文件是针对本计算机的，是给计算机起的一个名字，是计算机的一个标识。可以使用uname -n 命令来查看本地计算机的计算机名称。　/etc/sysconfig/network用于设置HOSTNAME与启动NETWORKING的，主机名称在重启后生效

######################################################【linux】hostname############################################

######################################################【linux】性能监控工具############################################
sysstat提供了Linux性能监控的工具集，包括sar、sadf、mpstat、iostat、pidstat等，这些工具可以监控系统性能和使用情况
yum install -y sysstat
######################################################【linux】性能监控工具############################################

######################################################【linux】sysctl命令############################################
Linux系统中sysctl命令详解
sysctl命令用于运行时配置内核参数，这些参数位于/proc/sys目录下。sysctl配置与显示在/proc/sys目录中的内核参数．可以用sysctl来设置或重新设置联网功能，如IP转发、IP碎片去除以及源路由检查等。用户只需要编辑/etc/sysctl.conf文件，即可手工或自动执行由sysctl控制的功能。

命令格式：
sysctl [-n] [-e] -w variable=value
sysctl [-n] [-e] -p <filename> (default /etc/sysctl.conf)
sysctl [-n] [-e] -a

常用参数的意义：
-w   临时改变某个指定参数的值，如
	sysctl -w net.ipv4.ip_forward=1
-a   显示所有的系统参数
-p   从指定的文件加载系统参数，如不指定即从/etc/sysctl.conf中加载

如果仅仅是想临时改变某个系统参数的值，可以用两种方法来实现,例如想启用IP路由转发功能：
1) #echo 1 > /proc/sys/net/ipv4/ip_forward
2) #sysctl -w net.ipv4.ip_forward=1
以上两种方法都可能立即开启路由功能，但如果系统重启，或执行了 service network restart命令，所设置的值即会丢失，

如果想永久保留配置，可以修改/etc/sysctl.conf文件
 将 net.ipv4.ip_forward=0改为net.ipv4.ip_forward=1 
 #重新加载系统参数
 sysctl -p  
######################################################【linux】sysctl命令############################################

####################################################【linux】CPU频率控制####################################################
Linux内部共有五种对频率的管理策略userspace，conservative，ondemand，powersave和performance。
1)performance：CPU会固定工作在其支持的最高运行频率上；
2)powersave：CPU会固定工作在其支持的最低运行频率上。因此这两种governors都属于静态governor，即在使用它们时CPU的运行频率不会根据系统运行时负载的变化动态作出调整。这两种governors对应的是两种极端的应用场景，使用performancegovernor体现的是对系统高性能的最大追求，而使用powersavegovernor则是对系统低功耗的最大追求。
3)Userspace：最早的cpufreq子系统通过userspacegovernor为用户提供了这种灵活性。系统将变频策略的决策权交给了用户态应用程序，并提供了相应的接口供用户态应用程序调节CPU运行频率使用。（可以使用Dominik等人开发了cpufrequtils工具包）
4)ondemand：userspace是内核态的检测，效率低。而ondemand正是人们长期以来希望看到的一个完全在内核态下工作并且能够以更加细粒度的时间间隔对系统负载情况进行采样分析的governor。
5)conservative：ondemandgovernor的最初实现是在可选的频率范围内调低至下一个可用频率。这种降频策略的主导思想是尽量减小对系统性能的负面影响，从而不会使得系统性能在短时间内迅速降低以影响用户体验。但是在ondemandgovernor的这种最初实现版本在社区发布后，大量用户的使用结果表明这种担心实际上是多余的，ondemandgovernor在降频时对于目标频率的选择完全可以更加激进。因此最新的ondemandgovernor在降频时会在所有可选频率中一次性选择出可以保证CPU工作在80%以上负荷的频率，当然如果没有任何一个可选频率满足要求的话则会选择CPU支持的最低运行频率。大量用户的测试结果表明这种新的算法可以在不影响系统性能的前提下做到更高效的节能。在算法改进后，ondemandgovernor的名字并没有改变，而ondemandgovernor最初的实现也保存了下来，并且由于其算法的保守性而得名conservative。Ondemand降频更加激进，conservative降频比较缓慢保守，事实使用ondemand的效果也是比较好的。

查看所有cpu的频率管理策略
cpupower -c all  frequency-info

设置所有cpu的频率管理策略为performance模式
cpupower -c all frequency-set -g performance
禁用所有空闲状态，其延迟等于或等于<LATENCY>（因为此处的LATENCY为0，所以CPU会一直处于performance状态）
cpupower idle-set -D 0

查看运行的cpu的主频
cat /proc/cupinfo | grep MHz
####################################################【linux】CPU频率控制####################################################

####################################################【linux】超线程####################################################
linux查看是否开启超线程
在linux系统中，我们不能直接查看到是否开启了超线程，但是可以通过几个相关参数来判断。他们分别是，物理CPU数，每个CPU的逻辑核数，CPU线程数。
物理CPU数
$ cat /proc/cpuinfo | grep "physical id" | sort | uniq
physical id : 0
physical id : 1
以上输出信息，代表当前的机器拥有两个物理CPU
单个CPU的逻辑核心数量
$ cat /proc/cpuinfo | fgrep "cores" | uniq
cpu cores       : 6
以上输出信息，代表当前机器的每个CPU拥有6个逻辑核心，如果物理CPU的逻辑核心数量不同，则会显示多行
系统CPU线程数
$ cat /proc/cpuinfo | grep "processor" | wc -l
12
以上输出信息，代表当前机器拥有12个CPU线程
通过综合以上信息，可以发现，这台机器拥有2和物理CPU，每个CPU有6个逻辑核心，系统一共拥有12个CPU线程。显然没有开启超线程

另外一种查询是否开启超线程的方式：
cat /proc/cpuinfo | grep -e "cpu cores" -e "siblings" | sort | uniq
输出结果：
cpu cores : 8
siblings : 16
看到cpu cores数量是siblings数量一半，说明启动了超线程。
如果cpu cores数量和siblings数量一致，则没有启用超线程。
####################################################【linux】超线程####################################################

###############################################【linux】通过PID查看进程完整信息###############################################
通过ps及top命令查看进程信息时，只能查到相对路径，查不到的进程的详细信息，如绝对路径等。
这时，我们需要通过以下的方法来查看进程的详细信息：
Linux在启动一个进程时，系统会在/proc下创建一个以PID命名的文件夹，在该文件夹下会有我们的进程的信息，其中包括一个名为exe的文件即记录了绝对路径，通过ll或ls –l命令即可查看。
ll /proc/PID
cwd符号链接的是进程运行目录；
exe符号连接就是执行程序的绝对路径；
cmdline就是程序运行时输入的命令行命令；
environ记录了进程运行时的环境变量；
fd目录下是进程打开或使用的文件的符号连接。
###############################################【linux】通过PID查看进程完整信息###############################################


###############################################【linux】yum本地源创建###############################################
1) 修改/etc/yum.conf文件，将keepcache设置为1 (修改完之后通过yum install安装的rpm包将放在yum.conf文件中cachedir指向的目录)
$releasever的值,这个表示当前系统的发行版本，$basearch是我们的系统硬件架构(CPU指令集),就是我们常说的i386\i486\i586\i686\...
可以通过如下命令查看：
rpm -qi centos-release
其中的Version     : 7就是我们系统的版本号，Architecture: x86_64就是系统硬件架构(CPU指令集)
2) yum install createrepo (createrepo 命令用于创建yum源（软件仓库），即为存放于本地特定位置的众多rpm包建立索引，描述各包所需依赖信息，并形成元数据。)
3) 将cachedir目录下，base和updates目录下packages里面的rpm包统一复制至指定文件夹
查找并删除*.so文件
find . -name "*.so" | xargs rm
查找并拷贝*.so文件
find . -name "*.so" | xargs -i cp {} ./tmp/
拷贝当前目录下所有*.so文件到./tmp/下
ls *.so | xargs -i cp {} ./tmp/
4) 通过：createrepo /rpm依赖包集合创建索引
5) 在/etc/yum.repos.d下创建一个自定义的源文件，例如：customize.repo
[customize_packages]
name=customize_repo
baseurl=file:///data/repo
gpgcheck=0

显示历史版本
yum --showduplicates list nfs-utils

非root用户使用docker
https://yeasy.gitbooks.io/docker_practice/install/fedora.html

https://docs.docker.com/install/linux/docker-ce/centos/
yum install -y yum-utils device-mapper-persistent-data lvm2
yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo
yum-config-manager --enable docker-ce-nightly
yum-config-manager --enable docker-ce-test
Install the latest version of Docker Engine - Community and containerd, or go to the next step to install a specific version:
yum install docker-ce docker-ce-cli containerd.io

To install a specific version of Docker Engine - Community, list the available versions in the repo, then select and install:
a. List and sort the versions available in your repo. This example sorts results by version number, highest to lowest, and is truncated:
$ yum list docker-ce --showduplicates | sort -r

docker-ce.x86_64  3:18.09.1-3.el7                     docker-ce-stable
docker-ce.x86_64  3:18.09.0-3.el7                     docker-ce-stable
docker-ce.x86_64  18.06.1.ce-3.el7                    docker-ce-stable
docker-ce.x86_64  18.06.0.ce-3.el7                    docker-ce-stable

$ yum list docker-ce-cli --showduplicates | sort -r

The list returned depends on which repositories are enabled, and is specific to your version of CentOS (indicated by the .el7 suffix in this example).
b. Install a specific version by its fully qualified package name, which is the package name (docker-ce) plus the version string (2nd column) starting at the first colon (:), up to the first hyphen, separated by a hyphen (-). For example, docker-ce-18.09.1.
$ sudo yum install docker-ce-<VERSION_STRING> docker-ce-cli-<VERSION_STRING> containerd.io
$ sudo yum install docker-ce-18.09.0 docker-ce-cli-18.09.6 containerd.io-1.2.5
Docker is installed but not started. The docker group is created, but no users are added to the group.

https://github.com/NVIDIA/nvidia-docker
https://github.com/NVIDIA/nvidia-docker/wiki/Installation-(version-2.0)
distribution=$(. /etc/os-release;echo $ID$VERSION_ID)
curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.repo | sudo tee /etc/yum.repos.d/nvidia-docker.repo

# Install nvidia-docker2 and reload the Docker daemon configuration
yum install -y nvidia-docker2
pkill -SIGHUP dockerd

Older versions of Docker
You must pin the versions of both nvidia-docker2 and nvidia-container-runtime when installing, for instance:
sudo apt-get install -y nvidia-docker2=2.0.1+docker1.12.6-1 nvidia-container-runtime=1.1.0+docker1.12.6-1
Use apt-cache madison nvidia-docker2 nvidia-container-runtime or yum search --showduplicates nvidia-docker2 nvidia-container-runtime to list the available versions.
yum install nvidia-docker2-2.0.3-1.docker18.09.0.ce.noarch nvidia-container-runtime-2.0.0-1.docker18.09.0.x86_64

[root@aistation003 ~]# rpm -qa | grep nvidia-docker2
nvidia-docker2-2.0.3-1.docker18.09.0.ce.noarch
[root@aistation003 ~]# rpm -qa | grep nvidia-container-runtime
nvidia-container-runtime-hook-1.4.0-2.x86_64
nvidia-container-runtime-2.0.0-1.docker18.09.0.x86_64


nvidia-cuda镜像
https://gitlab.com/nvidia/container-images/cuda/tree/master/dist/centos7/10.1

docker build -t cuda:10.1.243 -f /home/10.1/base/Dockerfile /home/10.1/base/
docker build -t cuda_nvml:10.1.243 -f /home/10.1/devel/Dockerfile /home/10.1/devel/
docker build -t cuda:10.1.243-devel-centos7 -f /home/10.1/devel/cudnn7/Dockerfile /home/10.1/devel/cudnn7

注意在nvidia-cuda镜像制作过程中设置了如下一些链接和环境变量
ENV CUDA_VERSION 10.1.243
ENV CUDA_PKG_VERSION 10-1-$CUDA_VERSION-1
ln -s cuda-10.1 /usr/local/cuda
# nvidia-docker 1.0
RUN echo "/usr/local/nvidia/lib" >> /etc/ld.so.conf.d/nvidia.conf && \
    echo "/usr/local/nvidia/lib64" >> /etc/ld.so.conf.d/nvidia.conf
ENV PATH /usr/local/nvidia/bin:/usr/local/cuda/bin:${PATH}
ENV LD_LIBRARY_PATH /usr/local/nvidia/lib:/usr/local/nvidia/lib64
# nvidia-container-runtime
ENV NVIDIA_VISIBLE_DEVICES all
ENV NVIDIA_DRIVER_CAPABILITIES compute,utility
ENV NVIDIA_REQUIRE_CUDA "cuda>=10.1 brand=tesla,driver>=384,driver<385 brand=tesla,driver>=396,driver<397 brand=tesla,driver>=410,driver<411"
ENV LIBRARY_PATH /usr/local/cuda/lib64/stubs
ENV CUDNN_VERSION 7.6.4.38
###############################################【linux】yum本地源创建###############################################

###############################################【linux】xargs###############################################
find ./source_folder / -name '*.txt' | xargs -i cp {} ./res_folder/
###############################################【linux】xargs###############################################

###############################################【linux】软链接的创建、删除、修改###############################################
一、软链接创建
ln -s 【目标目录】 【软链接地址】
1、【目标目录】指软连接指向的目标目录下，【软链接地址】指“快捷键”文件名称，该文件是被指令创建的。
2、软链接创建需要同级目录下没有同名的文件。就像你在windows系统桌面创建快捷键时，不能有同名的文件。

二、删除
rm -rf 【软链接地址】
1、上述指令中，软链接地址最后不能含有“/”，当含有“/”时，删除的是软链接目标目录下的资源，而不是软链接本身。

三、修改
ln -snf 【新目标目录】 【软链接地址】
###############################################【linux】软链接的创建、删除、修改###############################################

###############################################CentOS7上的系统管理之：Systemd和systemctl###############################################
早期的CentOS5系统上，使用的init系统是SysVinit。这套系统运行稳定，使用shell脚本的形式，串行地一个个启动进程，当前一个进程启动完毕后，再启动后一个。这种方式带来的缺点是：
计算机的启动速度很慢，后面的进程必须等待前面的进程依次串行地启动完毕方可启动。
有的服务可能在启动后很长的一段时间或者几乎不会使用到，例如服务器中的打印服务。
发展到CentOS6的时候，init系统换成了Upstart，这个系统有效的解决了上述的缺点，实现了并行启动和按需启动。
而到了CentOS7的时候，则出现了Systemd这套init系统，它更加完善了并行启动和按需启动，使得启动的速度更上一层楼。这里的按需启动，指的是某个服务被设置为开机启动，当开机时该服务并没有真正的启动，只是注册好了socket占用，等待第一次有请求进来的时候，Systemd悬挂该请求然后启动服务，服务启动完毕后就恢复该请求，从而实现按需启动，这种方式也变相加速了系统的启动速度。

Unit
在Systemd中使用配置文件来进行管理，这些配置文件叫做unit。unit有许许多多的类型，如下。
Unit        类型 	文件扩展名 	描述
Service     unit 	.service 	用于管理系统的服务unit，最常用，一般由所安装的服务所提供（httpd、MySQL等）
Target      unit 	.target 	target unit表示的是期望系统运行于哪个状态下，用户的目标是什么。
Automount   unit 	.automount 	文件系统自动挂载点。
Device      unit 	.device 	一个被内核所识别的设备文件。
Mount       unit 	.mount 	    一个文件系统的挂载点。
Path        unit 	.path 	    文件系统中的一个文件或目录。
Scope       unit 	.scope 	    一个外部创建的进程。
Slice       unit 	.slice 	    一组用于管理系统进程的分层组织的单元。
Snapshot    unit 	.snapshop 	Systemd管理器所保存的一个状态，因此称之为快照。
Socket      unit 	.socket 	一个进程间通信（IPC）socket。
Swap        unit 	.swap 	    一个swap设备或者swap文件。
Timer       unit    .timer 	    一个Systemd timer。

Unit配置文件
unit文件存在于三个位置：
/usr/lib/systemd/system/：软件程序包所提供的unit文件。例如httpd程序包提供了httpd.service文件。
/run/systemd/system/：运行时所创建的unit文件。优先级高于已安装的服务unit文件所在的目录。
/etc/systemd/system/：通过systemctl enable所创建的和用于扩展一个服务所添加的unit文件目录。优先级高于运行时unit文件。
优先级：/etc/systemd/system/ --> /run/systemd/system/ --> /usr/lib/systemd/system/。

管理服务
在SysVinit和Upstart中，使用【/etc/rc.d/init.d/】下的shell脚本（一般是bash）来管理服务，使用的命令是service和chkconfig。在Systemd中使用service类型的unit文件（.service文件）来管理，使用的命令统一为systemctl。
由于向后兼容的特性的存在，旧命令依然可用，但是官方并不建议。新旧命令的对应关系如下。
service命令和systemctl命令对照表，service命令用于管理一个服务的启动和停止。
service  	             systemctl  	描述 
service name start 	     systemctl start name.service 	             启动一个服务
service name stop 	     systemctl stop name.service 	             停止一个服务
service name restart 	 systemctl restart name.service 	         重启一个服务
service name condrestart systemctl try-restart name.serivce          只有当服务处于运行状态时才重启服务
service name reload 	 systemctl reload name.service 	             重载服务，一般用于配置文件的修改后执行
serivce name status 	 systemctl status name.service               查看服务的运行状态
                         systemctl is-active name.service
service --status-all 	 systemctl list-units --type service --all 	 查看所有服务的运行状态
在书写unit名称的时候，一般是建议写全名，这样比较能顾名思义，例如“httpd.service”。不过简写，不写unit类型后缀，那么systemctl也是可以识别的，如下2个命令的效果是一样的，systemctl会自动识别unit类型。
~]# systemctl stop nfs-server.service
~]# systemctl stop nfs-server
unit的名称如果比较长，可以定义一个简短的别名，想查看别名的话使用如下命令。show子命令可以查看很多unit的信息。
[root@c7-server ~]# systemctl show httpd.service -p Names
Names=httpd.service

列出服务

列出所有当前已载入的服务。
[root@c7-server ~]# systemctl list-units --type service
  UNIT                               LOAD   ACTIVE SUB     DESCRIPTION
  abrt-ccpp.service                  loaded active exited  Install ABRT coredump hook
  abrt-oops.service                  loaded active running ABRT kernel log watcher
  abrt-xorg.service                  loaded active running ABRT Xorg log watcher
...
● kdump.service                      loaded failed failed  Crash recovery kernel arming
...

显示服务状态
[root@c7-server ~]# systemctl status httpd.service
服务处于启动或停止的状态时，有不同的状态信息显示。使用root用户执行此命令，还可以显示日志信息。
如果仅希望查看服务是否启动，是否开机启动的话，可使用如下命令。
[root@c7-server ~]# systemctl is-active httpd.service
active
[root@c7-server ~]# systemctl is-enabled httpd.service
disabled

启动、停止和重启等
~]# systemctl start httpd.service
~]# systemctl stop httpd.service
~]# systemctl restart httpd.service
如果服务原本是停止的状态，则执行restart会启用该服务。如果我们希望只有当服务当前是启动的状态才重启的话，那么应该执行try-restart。
~]# systemctl try-restart httpd.service
某些服务支持在不打断运行状态的情况下重载服务从而读取配置文件。
~]# systemctl reload httpd.service
如果服务不支持重载的话，服务会忽略systemd的reload操作。为了方便，确保修改的配置文件一定会生效，可以执行如下2个子命令。
reload-or-restart：尝试reload，如果服务不支持就restart。
reload-or-try-restart：尝试reload，如果服务不支持就try-restart。如果服务本身没启动，那么再执行了此命令后应该也不会启动，需要手工启动。启动时，服务就会去读取配置文件了。
~]# systemctl reload-or-restart httpd.service
~]# systemctl reload-or-try-restart httpd.service

开机启动
~]# systemctl enable httpd.service
~]# systemctl disable httpd.service
当我们设置开机启动的时候，systemd会读取服务的配置文件（/usr/lib/systemd/system/httpd.service）中的[Install]部分。
[Install]
WantedBy=multi-user.target
根据此部分的内容创建字符链接。
Created symlink from /etc/systemd/system/multi-user.target.wants/httpd.service to /usr/lib/systemd/system/httpd.service.
如果服务本身是开机启动的，那么再执行一次enable的话并不会创建字符链接文件。想确保其一定创建的话，可使用reenable。
~]# systemctl reenable httpd.service
Removed symlink /etc/systemd/system/multi-user.target.wants/httpd.service.
Created symlink from /etc/systemd/system/multi-user.target.wants/httpd.service to /usr/lib/systemd/system/httpd.service.
关闭开机启动，就是删除字符链接了。
~]# systemctl disable httpd.service
Removed symlink /etc/systemd/system/multi-user.target.wants/httpd.service.
systemd支持mask操作，如果一个服务被mask了，那么它无法被手动启动或者被其他服务所启动，也无法被设置为开机启动。
[root@c7-server ~]# systemctl mask httpd.service
Created symlink from /etc/systemd/system/httpd.service to /dev/null.
[root@c7-server ~]# systemctl start httpd.service
Failed to start httpd.service: Unit is masked.
[root@c7-server ~]# systemctl enable httpd.service
Failed to execute operation: Cannot send after transport endpoint shutdown
可使用unmask来取消mask。
~]# systemctl unmask httpd.service
Removed symlink /etc/systemd/system/httpd.service.

创建和修改unit文件
创建和修改unit文件是理解systemd工作的重点和难点，对于服务的开发人员来说，应该是必备的技能。对于我目前的运维阶段来说，只要达到会看即可，因此这里先暂时留白，感兴趣的可以直接看开头参考资料中的红帽文档。
Unit文件存在于文章开头处提到的三个目录，其中“/etc/systemd/system/”目录是留给管理员自定义的，因此我们自定义的unit文件建议放该目录下。
Unit文件的文件名：
unit_name.type_extension
unit名和类型都是可替换的，合在一起叫做完整（full）的unit文件名。
例如sshd有两个常见的unit文件：sshd.service和sshd.socket。
如果我们想对一个unit做选项补充的话，可以新增一个“.d”目录并在其下创建补充的配置文件。例如当我们想为sshd.service增加自定义的配置选项时，可以创建sshd.service.d/custom.conf配置文件。
另外，还可以存在“sshd.service.wants/”和“sshd.service.requires/”目录，这些目录下都是字符链接文件，链接到其他的unit文件，以此来决定sshd.service的依赖关系。字符链接会自动产生，也可人为创建。
了解unit文件的结构
Unit文件由典型的三部分构成：
    [Unit]：包含通用的选项，不受unit类型所影响。这部分主要提供了unit的简单描述信息，指定其行为，定义其依赖关系。
    [unit type]：这部分的选项，是和unit类型相关的。即如果是.service类的unit，就有其相关的特定选项。
    [Install]：在通过systemctl enable或者disable的时候，所涉及到的选项。
[Unit]和[Install]的选项的完整参考手册，可见systemd.unit(5)；[unit type]的选项，则需要根据unit的类型来确定。可通过以下命令查找对应的man手册。
~]# man -k systemd
...
systemd.scope (5)    - Scope unit configuration
systemd.service (5)  - Service unit configuration
systemd.slice (5)    - Slice unit configuration
systemd.snapshot (5) - Snapshot unit configuration
systemd.socket (5)   - Socket unit configuration
...
systemd.swap (5)     - Swap unit configuration
systemd.target (5)   - Target unit configuration
...
当编辑或者新建了unit的文件，需要使用该命令重载systemd，使其知晓。
~]# systemctl daemon-reload

###############################################CentOS7上的系统管理之：Systemd和systemctl###############################################

###############################################CentOS7 sysctl###############################################
sysctl命令用于运行时配置内核参数。
vim /etc/sysctl.conf

//-a 显示所有的系统参数
//error
sysctl -a | grep kernel.core_pipe_limit
kernel.core_pipe_limit = 0
sysctl -a | grep kernel.hung_task_panic
kernel.hung_task_panic = 1
sysctl -a | grep kernel.numa_balancing
kernel.numa_balancing = 1
sysctl -a | grep kernel.panic
kernel.panic = 5

//ok
kernel.core_pipe_limit = 4
kernel.hung_task_panic = 0
kernel.numa_balancing = 0
kernel.panic = 0

//-w 临时改变某个指定参数的值
sysctl -w kernel.core_pipe_limit=4 无效
sysctl -w kernel.hung_task_panic=0 无效
sysctl -w kernel.numa_balancing=0 有效
sysctl -w kernel.panic=0 无效

//-p 从指定的文件加载系统参数的值，如不指定即从/etc/sysctl.conf中加载
sysctl -p /etc/sysctl.conf
sysctl -p命令，所设置的值在系统重启后即会丢失，如果想永久保留配置，可以修改/etc/sysctl.conf文件

numa 总结

离线install numactl
numactl-libs-2.0.9-6.el7_2.x86_64.rpm
numactl-2.0.9-6.el7_2.x86_64.rpm

查看numa相关信息，包括每个node内存大小，每个node中的逻辑cpu
numactl --hardware

验证系统是否支持numa
dmesg | grep -i numa查看输出结果：
如果输出结果为：
No NUMA configuration found
说明numa为disable，如果不是上面的内容说明numa为enable

查看numa的状态：numastat
numa_hit是打算在该节点上分配内存，最后从这个节点分配的次数;
num_miss是打算在该节点分配内存，最后却从其他节点分配的次数;
num_foregin是打算在其他节点分配内存，最后却从这个节点分配的次数;
interleave_hit是采用interleave策略最后从该节点分配的次数;
local_node该节点上的进程在该节点上分配的次数
other_node是其他节点进程在该节点上分配的次数


###############################################CentOS7 sysctl###############################################

###############################################修改yum源为国内镜像###############################################
centos7 修改yum源为阿里源
首先是到yum源设置文件夹里
1. 查看yum源信息:
    yum repolist
2. 定位到base reop源位置
     cd /etc/yum.repos.d
3. 接着备份旧的配置文件
   sudo mv CentOS-Base.repo CentOS-Base.repo.bak
4. 下载阿里源的文件
 sudo wget -O CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo
---------------------------红帽版本一样的安装------------------------------
# 安装epel repo源：
epel(RHEL 7) 红帽7
   wget -O /etc/yum.repos.d/epel.repo http://mirrors.aliyun.com/repo/epel-7.repo
epel(RHEL 6) 红帽6
    wget -O /etc/yum.repos.d/epel.repo http://mirrors.aliyun.com/repo/epel-6.repo
epel(RHEL 5) 红帽5
    wget -O /etc/yum.repos.d/epel.repo http://mirrors.aliyun.com/repo/epel-5.repo
------------------------------------------------------------------------------    
5.清理缓存
    yum clean all
6.重新生成缓存
    yum makecache
7. 再次查看yum源信息
   yum repolist
###############################################修改yum源为国内镜像###############################################

###############################################df、du、fdisk、lsblk区别###############################################
df主要是检查文件系统磁盘占用情况，所以这里可以看到文件系统
du主要是检查磁盘空间占用情况，统计目录或者文件大小的，和ll功能有相同之处。
fdisk一般用来磁盘分区，也可以用来查看磁盘分区情况。
lsblk命令用于列出所有可用块设备的信息，而且还能显示他们之间的依赖关系，这个命令很好用，因为可以让电脑上的磁盘和分区信息很清晰。
###############################################df、du、fdisk、lsblk区别###############################################

###############################################设置Linux打开文件句柄数###############################################
max-file 表示系统级别的能够打开的文件句柄的数量。是对整个系统的限制，并不是针对用户的。
ulimit -n 控制进程级别能够打开的文件句柄的数量。提供对shell及其启动的进程的可用文件句柄的控制。这是进程级别的。
对于服务器来说，file-max和ulimit都需要设置，否则会出现文件描述符耗尽的问题。

系统级打开最大文件句柄的数量永久生效的修改方法，修改文件
vim /etc/sysctl.conf
文件末尾加入配置内容：
fs.file-max = 640000
然后执行命令，使修改配置立即生效：
sysctl -p

查看用户进程级的能够打开文件句柄的数量
ulimit -a
设置的是当前shell的当前用户的打开的最大限制
修改linux最大文件句柄数
ulimit -n 65535
进程级打开文件句柄数量永久生效的修改方法，修改文件，文件末尾加入配置内容：
# vim /etc/security/limits.conf
* soft nofile 65535
* hard nofile 65535
修改以后，需要重新登录才能生效。
说明：如果只是修改了root用户下每个进程可以同时打开的最大文件数。则按照如下格式：
root soft nofile 65536
root hard nofile 65536
domino type item value
domino是用户名（ *表示所有用户）；
type设置为hard or soft；
item指定想限制的资源，如cpu,core nofile nproc or maxlogins；
###############################################设置Linux打开文件句柄数###############################################

#####################################Cannot assign requested address出现的原因及解决方案#####################################
解决办法：执行命令修改如下内核参数
表示如果套接字由本端要求关闭，这个参数决定了它保持在FIN-WAIT-2状态的时间（可改为30，一般来说FIN-WAIT-2的连接也极少）
默认为60s，修改为15~30s：
sysctl -w net.ipv4.tcp_fin_timeout=15
控制timestamp选项开启/关闭。tcp_tw_recycle/tcp_timestamps都开启的条件下，60s内同一源ip主机的socketconnect请求中的timestamp必须是递增的。
sysctl -w net.ipv4.tcp_timestamps=1
表示开启TCP连接中TIME-WAIT sockets的快速回收，默认为0，表示关闭（这个参数默认2.4的内核就禁用了。能不开启就不要开启）
sysctl -w net.ipv4.tcp_tw_recycle=0
表示开启重用。允许将TIME-WAIT sockets重新用于新的TCP连接，默认为0，表示关闭：
sysctl -w net.ipv4.tcp_tw_reuse=1

注意点
1.tcp_tw_reuse，tcp_tw_recycle必须在客户端和服务端tcp_timestamps开启时才管用（默认打开），其实意思就是假如服务端和客户端两边有一边timestamps没开启。tw_reuse和tw_recycle都没啥作用
2.tcp_tw_reuse只对客户端起作用，开启后客户端在1s内回收。reuse就是重用time_wait的socket连接。服务端同一个端口被连接理论上是没限制的。
3.tcp_tw_recycle对客户端和服务器同时起作用，开启后在3.5*RTO内回收，RTO200ms~120s具体时间视网络状况。

对于客户端
1.作为客户端因为有端口65535问题，TIME_OUT过多直接影响处理能力，打开tcp_tw_reuse即可解决，不建议同时打开tcp_tw_recycle，帮助不大。
2. tcp_tw_reuse 帮助客户端1s完成连接回收，基本可实现单机6w/s请求，需要再高就增加IP数量吧。
3. 如果内网压测场景，且客户端不需要接收连接，同时tcp_tw_recycle会有一点点好处。

对于服务端
1.打开tcp_tw_reuse无效，因为是客户端连接web服务器，服务端肯定不会重用socket去主动连接客户端。这个参数服务器一般用不到，除非web服务器又作为客户端去连接后端数据库才用到。但是web服务器作为客户端连接数据库达到6万端口的限制时你的数据库早承受不了压力瘫痪了。一般数据库5000连接数就已经很高了。
tcp_tw_resue这个参数，只有客户端用得到。意思就是重用处于time_wait的socket连接。

2.线上环境tcp_tw_recycle不要打开
服务器处于NAT负载后，或者客户端处于NAT后（这是一定的事情，基本公司家庭网络都走NAT）；公网服务打开就可能造成部分连接失败，内网的话到时可以视情况打开；有些负载均衡设备会把timestamp都给清空，后端web服务器开启不开启tcp_tw_recycle都无所谓了。

3.服务器TIME_WAIT高怎么办
服务器time_wait不用担心，因为我是服务端，是客户端很多IP和端口主动连接我的一个端口，比如连接我的80端口。很可能出现一种情况就是虽然我机器上有10万个time_wait连接。但是我的端口才用到一个80端口。不像客户端有端口限制，处理大量TIME_WAITLinux已经优化很好了，每个处于TIME_WAIT 状态下连接内存消耗很少，而且也能通过tcp_max_tw_buckets = 262144 配置最大上限，现代机器一般也不缺这点内存。

总之，生产中，服务器不管有没有在nat设备后面.
tcp_tw_recycle不开启就行了。默认就是不开启的状态，值为0
tcp_timestamps保持默认开启就行了，值为1
tcp_tw_reuse客户端最好开启。负载均衡设备连接web服务器时，辅助均衡设备也尽量开启
#####################################Cannot assign requested address出现的原因及解决方案#####################################

linux使用vi中文乱码的解决办法 在~/.vimrc文件中添加如下两行即：
set encoding=utf-8
set fileencoding=utf-8
/etc/vim/vimrc
/usr/share/vim/vimrc

/bin/bash^M: 坏的解释器: 没有那个文件或目录
执行shell脚本是报错：/bin/bash^M: 坏的解释器: 没有那个文件或目录
是因为该文件在windows系统上打开过，关闭后其中的空格符号和Linux的不同，导致这个报错，我们可以通过sed命令与正则的配合将文件中的空格符号替换成linux的空格：
sed -i 's/\r$//' mocha.sh

在CentOS的最小化安装中，默认是不会安装lspci工具的，需要自己手动安装。
安装步骤：1、yum  whatprovides lspci /*查找lspci是通过哪个安装包来提供的
          2、yum install pciutils
完成安装！